{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebooks_CNN_HFO_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PYXlwVnXKhOJ",
        "CVtiFO19ymk_",
        "fzh5PNccJ28-",
        "gcdrh-r9JRdS",
        "2pQEA9LADkBP",
        "J5uoUeQBDq5Q",
        "vMCxn-8P5tsH",
        "UwH_nXJZDz2T",
        "NNNnI_mU6LN5"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schatz06/Thesis/blob/main/Notebooks_CNN_HFO_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJHXZcSlNqL9"
      },
      "source": [
        "ds_num=0 \n",
        "# dataset=\"PISCES\" \n",
        "dataset=\"CB513\"\n",
        "USE_HFO=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYXlwVnXKhOJ"
      },
      "source": [
        "## Imports ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCuZCtMgg5ns"
      },
      "source": [
        "# Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.\n",
        "%load_ext autoreload \n",
        "%autoreload 2\n",
        "# matplotlib graphs will be included in your notebook, next to the code. \n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKDaAU3F5Bgs"
      },
      "source": [
        "# install hdf5storage package \r\n",
        "!pip install hdf5storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjrANRzOFauh"
      },
      "source": [
        "import pdb # python debugger\n",
        "import numpy as np # import numpy \n",
        "import tensorflow as tf # import tensorflow  \n",
        "tf.compat.v1.disable_eager_execution() # disable eager execution\n",
        "import time # import time\n",
        "import math # import math\n",
        "import argparse # import argparse\n",
        "import os # import os\n",
        "import scipy.io as sio # import scipy.io \n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() # makes different behaviors betweem tf_v1 & tf_v2 behave the same \n",
        "from tensorflow.python.client import device_lib # package to find available gpus\n",
        "import pandas as pd # import padas\n",
        "import hdf5storage # import hdf5storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVtiFO19ymk_"
      },
      "source": [
        "## Get data ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfOssHbYEh-W"
      },
      "source": [
        "valid_url=\"https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/{0}/plus{1}_{2}_mat/plus{3}_{2}_test_fold{4}.mat\".format(\n",
        "    dataset, str(plus_var), dataset.lower(), str(plus_var), str(ds_num))\n",
        "train_url=\"https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/{0}/plus{1}_{2}_mat/plus{3}_{2}_train_fold{4}.mat\".format(\n",
        "    dataset, str(plus_var), dataset.lower(), str(plus_var), str(ds_num))\n",
        "test_url=\"https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/CASP13/plus{0}_casp13_mat/plus{0}_casp13_sorted.mat\".format(str(plus_var))\n",
        "VALID_FILE=\"plus{0}_{1}_test_fold{2}.mat\".format(str(plus_var), dataset.lower(), str(ds_num))  \n",
        "TRAIN_FILE=\"plus{0}_{1}_train_fold{2}.mat\".format(str(plus_var), dataset.lower(), str(ds_num))\n",
        "TEST_FILE=\"plus{0}_casp13_sorted.mat\".format(str(plus_var))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7dvoRA1LKTZ"
      },
      "source": [
        "# !echo \"$valid_url\"\n",
        "# !echo \"$train_url\"\n",
        "# !echo \"$test_url\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brKV8aQYb_GQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "outputId": "55f33c02-51a2-4c47-dd18-c88745754635"
      },
      "source": [
        "![ -f \"$VALID_FILE\" ] && echo \"$VALID_FILE exists\" || wget \"$valid_url\"\n",
        "![ -f \"$TRAIN_FILE\" ] && echo \"$TRAIN_FILE exists\" || wget \"$train_url\"\n",
        "![ -f \"$TEST_FILE\" ] && echo \"$TEST_FILE exists\" || wget \"$test_url\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-28 12:28:32--  https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/CB513/plus7_cb513_mat/plus7_cb513_test_fold0.mat\n",
            "Resolving gitlab.com (gitlab.com)... 172.65.251.78, 2606:4700:90:0:f22e:fbec:5bed:a9b9\n",
            "Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 952613 (930K) [application/octet-stream]\n",
            "Saving to: ‘plus7_cb513_test_fold0.mat’\n",
            "\n",
            "\r          plus7_cb5   0%[                    ]       0  --.-KB/s               \rplus7_cb513_test_fo 100%[===================>] 930.29K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-07-28 12:28:32 (7.54 MB/s) - ‘plus7_cb513_test_fold0.mat’ saved [952613/952613]\n",
            "\n",
            "--2020-07-28 12:28:33--  https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/CB513/plus7_cb513_mat/plus7_cb513_train_fold0.mat\n",
            "Resolving gitlab.com (gitlab.com)... 172.65.251.78, 2606:4700:90:0:f22e:fbec:5bed:a9b9\n",
            "Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8537829 (8.1M) [application/octet-stream]\n",
            "Saving to: ‘plus7_cb513_train_fold0.mat’\n",
            "\n",
            "plus7_cb513_train_f 100%[===================>]   8.14M  38.6MB/s    in 0.2s    \n",
            "\n",
            "2020-07-28 12:28:34 (38.6 MB/s) - ‘plus7_cb513_train_fold0.mat’ saved [8537829/8537829]\n",
            "\n",
            "--2020-07-28 12:28:35--  https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/CASP13/plus7_casp13_mat/plus7_casp13_sorted.mat\n",
            "Resolving gitlab.com (gitlab.com)... 172.65.251.78, 2606:4700:90:0:f22e:fbec:5bed:a9b9\n",
            "Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1165218 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘plus7_casp13_sorted.mat’\n",
            "\n",
            "plus7_casp13_sorted 100%[===================>]   1.11M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-07-28 12:28:36 (8.46 MB/s) - ‘plus7_casp13_sorted.mat’ saved [1165218/1165218]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZg_ZHc_Lfdw"
      },
      "source": [
        "# !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKVIpZww1-dw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c09ecb2c-9c67-444d-8aa2-eaf67756373c"
      },
      "source": [
        "NEIGHBOURS = plus_var # number of amino-acids to add left and right \n",
        "AMINO_ACID_LEN = 20\n",
        "WINDOW = 2 * NEIGHBOURS + 1\n",
        "TOTAL_AMINO_ACIDS = WINDOW * AMINO_ACID_LEN\n",
        "TOTAL_COLS = TOTAL_AMINO_ACIDS + 1 # plus the secondary structure category\n",
        "CATEGORIES = 3 # number of different classification categories\n",
        "TOTAL_COLS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzh5PNccJ28-"
      },
      "source": [
        "## VGG ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwaNt8clJ5Vu"
      },
      "source": [
        "\"\"\"\n",
        "Codes are modifeid from PyTorch and Tensorflow Versions of VGG: \n",
        "https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py, and\n",
        "https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg16.py\n",
        "\"\"\"\n",
        "\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "# import numpy as np \n",
        "# import pdb\n",
        "from tensorflow.keras.applications.vgg16 import VGG16 as vgg16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19 as vgg19\n",
        "\n",
        "__all__ = ['VGG11', 'VGG13', 'VGG16','VGG19']\n",
        "\n",
        "def VGG(feature, num_cls):\n",
        "\n",
        "\twith tf.variable_scope('fully_connected') as scope:\n",
        "\t\tdim =np.prod(feature.shape[1:])\n",
        "\t\tx = tf.reshape(feature, [-1, dim])\n",
        "\n",
        "\t\tx = tf.keras.layers.Dense(units=4096, activation='relu', name=scope.name)(x)\n",
        "\t\tx = tf.keras.layers.Dense(units=4096, activation='relu', name=scope.name)(x)\n",
        "\t\tx = tf.keras.layers.Dense(units=num_cls, name=scope.name)(x)\n",
        "\n",
        "\treturn x\n",
        "\n",
        "def make_layers(x, cfg):\n",
        "\tfor v in cfg:\n",
        "\t\tif v == 'M':\n",
        "\t\t\tx = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(x)\n",
        "\t\telse:\n",
        "\t\t\tx = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=v,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t\t)(x)\n",
        "\treturn x\n",
        "\n",
        "cfg = {\n",
        "\t'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "\t'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "\t'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "\t'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
        "\t\t  512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "def VGG11(x_images, num_cls):\n",
        "\tfeature = make_layers(x_images, cfg['A'])\n",
        "\treturn VGG(feature, num_cls)\n",
        "\n",
        "def VGG13(x_images, num_cls):\n",
        "\tfeature = make_layers(x_images, cfg['B'])\n",
        "\treturn VGG(feature, num_cls)\n",
        "\n",
        "def VGG16(x_images, num_cls):\n",
        "\tfeature = make_layers(x_images, cfg['D'])\n",
        "\treturn VGG(feature, num_cls)\n",
        "\n",
        "def VGG19(x_images, num_cls):\n",
        "\tfeature = make_layers(x_images, cfg['E'])\n",
        "\treturn VGG(feature, num_cls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcdrh-r9JRdS"
      },
      "source": [
        "## Net ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHA5zxK1JRtg"
      },
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "# import math\n",
        "# import pdb\n",
        "# from tensorflow.python.client import device_lib\n",
        "# import numpy as np\n",
        "# from net.vgg import *\n",
        "\n",
        "def CNN_4layers(x_image, num_cls, reuse=False):\n",
        "\t_NUM_CLASSES = num_cls\n",
        "\twith tf.variable_scope('conv1', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(x_image)\n",
        "\n",
        "\twith tf.variable_scope('conv2', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\t\t\n",
        "\twith tf.variable_scope('conv3', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\n",
        "\twith tf.variable_scope('fully_connected', reuse=reuse) as scope:\n",
        "\t\tdim =np.prod(conv.shape[1:])\n",
        "\t\tflat = tf.reshape(conv, [-1, dim])\n",
        "\t\toutputs = tf.keras.layers.Dense(units=_NUM_CLASSES, name=scope.name)(flat)\n",
        "\n",
        "\treturn outputs\n",
        "\n",
        "\n",
        "\t# with tf.variable_scope('conv1', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=32,\n",
        "\t# \t\tkernel_size=[5, 5],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(x_image)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 16 x 16 x 32\n",
        "\n",
        "\t# with tf.variable_scope('conv2', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(pool)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 8 x 8 x 64\n",
        "\t\t\n",
        "\t# with tf.variable_scope('conv3', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(pool)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 4 x 4 x 64\n",
        "\n",
        "\t# with tf.variable_scope('fully_connected', reuse=reuse) as scope:\n",
        "\t# \tdim =np.prod(pool.shape[1:])\n",
        "\t# \tflat = tf.reshape(pool, [-1, dim])\n",
        "\t# \toutputs = tf.keras.layers.Dense(units=_NUM_CLASSES, name=scope.name)(flat)\n",
        "\n",
        "\t# return outputs\n",
        "\n",
        "def CNN_7layers(x_image, num_cls, reuse=False):\n",
        "\t_NUM_CLASSES = num_cls\n",
        "\twith tf.variable_scope('conv1', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(x_image)\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\n",
        "\twith tf.variable_scope('conv2', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\n",
        "\twith tf.variable_scope('conv3', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\n",
        "\twith tf.variable_scope('fully_connected', reuse=reuse) as scope:\n",
        "\t\tdim = np.prod(conv.shape[1:])\n",
        "\t\tflat = tf.reshape(conv, [-1, dim])\n",
        "\t\toutputs = tf.keras.layers.Dense(units=_NUM_CLASSES, name=scope.name)(flat)\n",
        "\n",
        "\treturn outputs\n",
        "\n",
        "\t# with tf.variable_scope('conv1', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=32,\n",
        "\t# \t\tkernel_size=[5, 5],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(x_image)\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=32,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(conv)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 16 x 16 x 32\n",
        "\n",
        "\t# with tf.variable_scope('conv2', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(pool)\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(conv)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 8 x 8 x 64\n",
        "\n",
        "\t# with tf.variable_scope('conv3', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(pool)\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=128,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(conv)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# pool = tf.layers.dropout(pool, rate=0.25, name=scope.name)\n",
        "\t# \t# N x 4 x 4 x 128\n",
        "\n",
        "\t# with tf.variable_scope('fully_connected', reuse=reuse) as scope:\n",
        "\t# \tdim = np.prod(pool.shape[1:])\n",
        "\t# \tflat = tf.reshape(pool, [-1, dim])\n",
        "\t# \toutputs = tf.keras.layers.Dense(units=_NUM_CLASSES, name=scope.name)(flat)\n",
        "\n",
        "\t# return outputs\n",
        "\n",
        "def CNN(net, num_cls, dim):\n",
        "\n",
        "\t_NUM_CLASSES = num_cls\n",
        "\t_IMAGE_HEIGHT, _IMAGE_WIDTH, _IMAGE_CHANNELS = dim\n",
        "\n",
        "\twith tf.name_scope('main_params'):\n",
        "\t\tx = tf.placeholder(tf.float32, shape=[None, _IMAGE_HEIGHT, _IMAGE_WIDTH, _IMAGE_CHANNELS], name='input_of_net')\n",
        "\t\ty = tf.placeholder(tf.float32, shape=[None, _NUM_CLASSES], name='labels')\n",
        "\n",
        "\t# call CNN structure according to string net\n",
        "\toutputs = globals()[net](x, _NUM_CLASSES)\n",
        "\toutputs = tf.identity(outputs, name='output_of_net')\n",
        "\n",
        "\treturn (x, y, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pQEA9LADkBP"
      },
      "source": [
        "## Utilities ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxQzW-93DIdN"
      },
      "source": [
        "# import numpy as np\n",
        "# import math\n",
        "# import scipy.io as sio\n",
        "# import os\n",
        "# import math\n",
        "# import pdb\n",
        "\n",
        "class ConfigClass(object):\n",
        "\tdef __init__(self, args, num_data, num_cls):\n",
        "\t\tsuper(ConfigClass, self).__init__()\n",
        "\t\tself.args = args\n",
        "\t\tself.iter_max = args.iter_max\n",
        "\t\t\n",
        "\t\t# Different notations of regularization term:\n",
        "\t\t# In SGD, weight decay:\n",
        "\t\t# \tweight_decay <- lr/(C*num_of_training_samples)\n",
        "\t\t# In Newton method:\n",
        "\t\t# \tC <- C * num_of_training_samples\n",
        "\n",
        "\t\tself.seed = args.seed\n",
        "\n",
        "\t\tif self.seed is None:\n",
        "\t\t\tprint('You choose not to specify a random seed.'+\\\n",
        "\t\t\t\t'A different result is produced after each run.')\n",
        "\t\telif isinstance(self.seed, int) and self.seed >= 0:\n",
        "\t\t\tprint('You specify random seed {}.'.format(self.seed))\n",
        "\t\telse:\n",
        "\t\t\traise ValueError('Only accept None type or nonnegative integers for'+\\\n",
        "\t\t\t\t\t' random seed argument!')\n",
        "\n",
        "\t\tself.train_set = args.train_set\n",
        "\t\tself.val_set = args.val_set\n",
        "\t\tself.num_cls = num_cls\n",
        "\t\tself.dim = args.dim\n",
        "\n",
        "\t\tself.num_data = num_data\n",
        "\t\tself.GNsize = min(args.GNsize, self.num_data)\n",
        "\t\tself.C = args.C * self.num_data\n",
        "\t\tself.net = args.net\n",
        "\n",
        "\t\tself.xi = 0.1\n",
        "\t\tself.CGmax = args.CGmax\n",
        "\t\tself._lambda = args._lambda\n",
        "\t\tself.drop = args.drop\n",
        "\t\tself.boost = args.boost\n",
        "\t\tself.eta = args.eta\n",
        "\t\tself.lr = args.lr\n",
        "\t\tself.lr_decay = args.lr_decay\n",
        "\n",
        "\t\tself.bsize = args.bsize\n",
        "\t\tif args.momentum < 0:\n",
        "\t\t\traise ValueError('Momentum needs to be larger than 0!')\n",
        "\t\tself.momentum = args.momentum\n",
        "\n",
        "\t\tself.loss = args.loss\n",
        "\t\tif self.loss not in ('MSELoss', 'CrossEntropy'):\n",
        "\t\t\traise ValueError('Unrecognized loss type!')\n",
        "\t\tself.optim = args.optim\n",
        "\t\tif self.optim not in ('SGD', 'NewtonCG', 'Adam'):\n",
        "\t\t\traise ValueError('Only support SGD, Adam & NewtonCG optimizer!')\n",
        "\t\t\n",
        "\t\tself.log_file = args.log_file\n",
        "\t\tself.model_file = args.model_file\n",
        "\t\tself.screen_log_only = args.screen_log_only\n",
        "\n",
        "\t\tif self.screen_log_only:\n",
        "\t\t\tprint('You choose not to store running log. Only store model to {}'.format(self.log_file))\n",
        "\t\telse:\n",
        "\t\t\tprint('Saving log to: {}'.format(self.log_file))\n",
        "\t\t\tdir_name, _ = os.path.split(self.log_file)\n",
        "\t\t\tif not os.path.isdir(dir_name):\n",
        "\t\t\t\tos.makedirs(dir_name, exist_ok=True)\n",
        "\n",
        "\t\tdir_name, _ = os.path.split(self.model_file)\n",
        "\t\tif not os.path.isdir(dir_name):\n",
        "\t\t\tos.makedirs(dir_name, exist_ok=True)\n",
        "\t\t\n",
        "\t\tself.elapsed_time = 0.0\n",
        "\n",
        "def read_data(filename, dim, label_enum=None):\n",
        "\t\"\"\"\n",
        "\targs:\n",
        "\t\tfilename: the path where .mat files are stored\n",
        "\t\tlabel_enum (default None): the list that stores the original labels. \n",
        "\t\t\tIf label_enum is None, the function will generate a new list which stores the \n",
        "\t\t\toriginal labels in a sequence, and map original labels to [0, 1, ... number_of_classes-1]. \n",
        "\t\t\tIf label_enum is a list, the function will use it to convert \n",
        "\t\t\toriginal labels to [0, 1,..., number_of_classes-1].\n",
        "\t\"\"\"\n",
        "\n",
        "\t# mat_contents = sio.loadmat(filename)\n",
        "\tmat_contents = hdf5storage.loadmat(filename)\n",
        "\timages, labels = mat_contents['Z'], mat_contents['y']\n",
        "\t\n",
        "\tlabels = labels.reshape(-1)\n",
        "\timages = images.reshape(images.shape[0], -1)\n",
        "\n",
        "\t_IMAGE_HEIGHT, _IMAGE_WIDTH, _IMAGE_CHANNELS = dim\n",
        "\tzero_to_append = np.zeros((images.shape[0],\n",
        "\t\t\t_IMAGE_CHANNELS*_IMAGE_HEIGHT*_IMAGE_WIDTH-np.prod(images.shape[1:])))\n",
        "\timages = np.append(images, zero_to_append, axis=1)\n",
        "\n",
        "\t# check data validity\n",
        "\tif label_enum is None:\n",
        "\t\tlabel_enum, labels = np.unique(labels, return_inverse=True)\n",
        "\t\tnum_cls = labels.max() + 1\n",
        "\n",
        "\t\tif len(label_enum) != num_cls:\n",
        "\t\t\traise ValueError('The number of classes is not equal to the number of\\\n",
        "\t\t\t\t\t\t\tlabels in dataset. Please verify them.')\n",
        "\telse:\n",
        "\t\tnum_cls = len(label_enum)\n",
        "\t\tforward_map = dict(zip(label_enum, np.arange(num_cls)))\n",
        "\t\tlabels = np.expand_dims(labels, axis=1)\n",
        "\t\tlabels = np.apply_along_axis(lambda x:forward_map[x[0]], axis=1, arr=labels)\n",
        "\t\t\n",
        "\n",
        "\t# convert groundtruth to one-hot encoding\n",
        "\tlabels = np.eye(num_cls)[labels]\n",
        "\tlabels = labels.astype('float32')\n",
        "\n",
        "\treturn [images, labels], num_cls, label_enum\n",
        "\n",
        "def normalize_and_reshape(images, dim, mean_tr=None):\n",
        "\t_IMAGE_HEIGHT, _IMAGE_WIDTH, _IMAGE_CHANNELS = dim\n",
        "\timages_shape = [images.shape[0], _IMAGE_CHANNELS, _IMAGE_HEIGHT, _IMAGE_WIDTH]\n",
        "\n",
        "\t# images normalization and zero centering\n",
        "\timages = images.reshape(images_shape[0], -1)\n",
        "\n",
        "\timages = images/255.0\n",
        "\n",
        "\tif mean_tr is None:\n",
        "\t\tprint('No mean of data provided! Normalize images by their own mean.')\n",
        "\t\t# if no mean_tr is provided, we calculate it according to the current data\n",
        "\t\tmean_tr = images.mean(axis=0) \n",
        "\telse:\n",
        "\t\tprint('Normalize images according to the provided mean.')\n",
        "\t\tif np.prod(mean_tr.shape) != np.prod(dim):\n",
        "\t\t\traise ValueError('Dimension of provided mean does not agree with the data! Please verify them!')\n",
        "\n",
        "\timages = images - mean_tr\n",
        "\n",
        "\timages = images.reshape(images_shape)\n",
        "\t# Tensorflow accepts data shape: B x H x W x C\n",
        "\timages = np.transpose(images, (0, 2, 3, 1))\n",
        "\treturn images, mean_tr\n",
        "\n",
        "\n",
        "def predict(sess, network, test_batch, bsize):\n",
        "\tx, y, loss, outputs = network\n",
        "\n",
        "\ttest_inputs, test_labels = test_batch\n",
        "\tbatch_size = bsize\n",
        "\n",
        "\tnum_data = test_labels.shape[0]\n",
        "\tnum_batches = math.ceil(num_data/batch_size)\n",
        "\n",
        "\tresults = np.zeros(shape=num_data, dtype=np.int)\n",
        "\tinfer_loss = 0.0\n",
        "\n",
        "\tfor i in range(num_batches):\n",
        "\t\tbatch_idx = np.arange(i*batch_size, min((i+1)*batch_size, num_data))\n",
        "\n",
        "\t\tbatch_input = test_inputs[batch_idx]\n",
        "\t\tbatch_labels = test_labels[batch_idx]\n",
        "\n",
        "\t\tnet_outputs, _loss = sess.run(\n",
        "\t\t\t[outputs, loss], feed_dict={x: batch_input, y: batch_labels}\n",
        "\t\t\t)\n",
        "\t\t\n",
        "\t\tresults[batch_idx] = np.argmax(net_outputs, axis=1)\n",
        "\t\t# note that _loss was summed over batches\n",
        "\t\tinfer_loss = infer_loss + _loss\n",
        "\n",
        "\tavg_acc = (np.argmax(test_labels, axis=1) == results).mean()\n",
        "\tavg_loss = infer_loss/num_data\n",
        "\t\n",
        "\treturn avg_loss, avg_acc, results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5uoUeQBDq5Q"
      },
      "source": [
        "## Newton - CG ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDug0aiKCqeG"
      },
      "source": [
        "# import pdb\n",
        "# import tensorflow as tf\n",
        "# import time\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import math\n",
        "# from utilities import predict\n",
        "\n",
        "def Rop(f, weights, v):\n",
        "\t\"\"\"Implementation of R operator\n",
        "\tArgs:\n",
        "\t\tf: any function of weights\n",
        "\t\tweights: list of tensors.\n",
        "\t\tv: vector for right multiplication\n",
        "\tReturns:\n",
        "\t\tJv: Jaccobian vector product, length same as\n",
        "\t\t\tthe number of output of f\n",
        "\t\"\"\"\n",
        "\tif type(f) == list:\n",
        "\t\tu = [tf.zeros_like(ff) for ff in f]\n",
        "\telse:\n",
        "\t\tu = tf.zeros_like(f)  # dummy variable\n",
        "\tg = tf.gradients(ys=f, xs=weights, grad_ys=u)\n",
        "\treturn tf.gradients(ys=g, xs=u, grad_ys=v)\n",
        "\n",
        "def Gauss_Newton_vec(outputs, loss, weights, v):\n",
        "\t\"\"\"Implements Gauss-Newton vector product.\n",
        "\tArgs:\n",
        "\t\tloss: Loss function.\n",
        "\t\toutputs: outputs of the last layer (pre-softmax).\n",
        "\t\tweights: Weights, list of tensors.\n",
        "\t\tv: vector to be multiplied with Gauss Newton matrix\n",
        "\tReturns:\n",
        "\t\tJ'BJv: Guass-Newton vector product.\n",
        "\t\"\"\"\n",
        "\t# Validate the input\n",
        "\tif type(weights) == list:\n",
        "\t\tif len(v) != len(weights):\n",
        "\t\t\traise ValueError(\"weights and v must have the same length.\")\n",
        "\n",
        "\tgrads_outputs = tf.gradients(ys=loss, xs=outputs)\n",
        "\tBJv = Rop(grads_outputs, weights, v)\n",
        "\tJBJv = tf.gradients(ys=outputs, xs=weights, grad_ys=BJv)\n",
        "\treturn JBJv\n",
        "\t\n",
        "\n",
        "class newton_cg(object):\n",
        "\tdef __init__(self, config, sess, outputs, loss):\n",
        "\t\t\"\"\"\n",
        "\t\tinitialize operations and vairables that will be used in newton\n",
        "\t\targs:\n",
        "\t\t\tsess: tensorflow session\n",
        "\t\t\toutputs: output of the neural network (pre-softmax layer)\n",
        "\t\t\tloss: function to calculate loss\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(newton_cg, self).__init__()\n",
        "\t\tself.sess = sess\n",
        "\t\tself.config = config\n",
        "\t\tself.outputs = outputs\n",
        "\t\tself.loss = loss\n",
        "\t\tself.param = tf.compat.v1.trainable_variables()\n",
        "\n",
        "\t\tself.CGiter = 0\n",
        "\t\tFLOAT = tf.float32\n",
        "\t\tmodel_weight = self.vectorize(self.param)\n",
        "\t\t\n",
        "\t\t# initial variable used in CG\n",
        "\t\tzeros = tf.zeros(model_weight.get_shape(), dtype=FLOAT)\n",
        "\t\tself.r = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\tself.v = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\tself.s = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\tself.g = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\t# initial Gv, f for method minibatch\n",
        "\t\tself.Gv = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\tself.f = tf.Variable(0., dtype=FLOAT, trainable=False)\n",
        "\n",
        "\t\t# rTr, cgtol and beta to be used in CG\n",
        "\t\tself.rTr = tf.Variable(0., dtype=FLOAT, trainable=False)\n",
        "\t\tself.cgtol = tf.Variable(0., dtype=FLOAT, trainable=False)\n",
        "\t\tself.beta = tf.Variable(0., dtype=FLOAT, trainable=False)\n",
        "\n",
        "\t\t# placeholder alpha, old_alpha and lambda\n",
        "\t\tself.alpha = tf.compat.v1.placeholder(FLOAT, shape=[])\n",
        "\t\tself.old_alpha = tf.compat.v1.placeholder(FLOAT, shape=[])\n",
        "\t\tself._lambda = tf.compat.v1.placeholder(FLOAT, shape=[])\n",
        "\n",
        "\t\tself.num_grad_segment = math.ceil(self.config.num_data/self.config.bsize)\n",
        "\t\tself.num_Gv_segment = math.ceil(self.config.GNsize/self.config.bsize)\n",
        "\n",
        "\t\tcal_loss, cal_lossgrad, cal_lossGv, \\\n",
        "\t\tadd_reg_avg_loss, add_reg_avg_grad, add_reg_avg_Gv, \\\n",
        "\t\tzero_loss, zero_grad, zero_Gv = self._ops_in_minibatch()\n",
        "\n",
        "\t\t# initial operations that will be used in minibatch and newton\n",
        "\t\tself.cal_loss = cal_loss\n",
        "\t\tself.cal_lossgrad = cal_lossgrad\n",
        "\t\tself.cal_lossGv = cal_lossGv\n",
        "\t\tself.add_reg_avg_loss = add_reg_avg_loss\n",
        "\t\tself.add_reg_avg_grad = add_reg_avg_grad\n",
        "\t\tself.add_reg_avg_Gv = add_reg_avg_Gv\n",
        "\t\tself.zero_loss = zero_loss\n",
        "\t\tself.zero_grad = zero_grad\n",
        "\t\tself.zero_Gv = zero_Gv\n",
        "\n",
        "\t\tself.CG, self.update_v = self._CG()\n",
        "\t\tself.init_cg_vars = self._init_cg_vars()\n",
        "\t\tself.update_gs = tf.tensordot(self.s, self.g, axes=1)\n",
        "\t\tself.update_sGs = 0.5*tf.tensordot(self.s, -self.g-self.r-self._lambda*self.s, axes=1)\n",
        "\t\tself.update_model = self._update_model()\n",
        "\t\tself.gnorm = self.calc_norm(self.g)\n",
        "\n",
        "\n",
        "\tdef vectorize(self, tensors):\n",
        "\t\tif isinstance(tensors, list) or isinstance(tensors, tuple):\n",
        "\t\t\tvector = [tf.reshape(tensor, [-1]) for tensor in tensors]\n",
        "\t\t\treturn tf.concat(vector, 0) \n",
        "\t\telse:\n",
        "\t\t\treturn tensors \n",
        "\t\n",
        "\tdef inverse_vectorize(self, vector, param):\n",
        "\t\tif isinstance(vector, list):\n",
        "\t\t\treturn vector\n",
        "\t\telse:\n",
        "\t\t\ttensors = []\n",
        "\t\t\toffset = 0\n",
        "\t\t\tnum_total_param = np.sum([np.prod(p.shape.as_list()) for p in param])\n",
        "\t\t\tfor p in param:\n",
        "\t\t\t\tnumel = np.prod(p.shape.as_list())\n",
        "\t\t\t\ttensors.append(tf.reshape(vector[offset: offset+numel], p.shape))\n",
        "\t\t\t\toffset += numel\n",
        "\n",
        "\t\t\tassert offset == num_total_param\n",
        "\t\t\treturn tensors\n",
        "\n",
        "\tdef calc_norm(self, v):\n",
        "\t\t# default: frobenius norm\n",
        "\t\tif isinstance(v, list):\n",
        "\t\t\tnorm = 0.\n",
        "\t\t\tfor p in v:\n",
        "\t\t\t\tnorm = norm + tf.norm(tensor=p)**2\n",
        "\t\t\treturn norm**0.5\n",
        "\t\telse:\n",
        "\t\t\treturn tf.norm(tensor=v)\n",
        "\n",
        "\tdef _ops_in_minibatch(self):\n",
        "\t\t\"\"\"\n",
        "\t\tDefine operations that will be used in method minibatch\n",
        "\t\tVectorization is already a deep copy operation.\n",
        "\t\tBefore using newton method, loss needs to be summed over training samples\n",
        "\t\tto make results consistent.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tdef cal_loss():\n",
        "\t\t\treturn tf.compat.v1.assign(self.f, self.f + self.loss)\n",
        "\n",
        "\t\tdef cal_lossgrad():\n",
        "\t\t\tupdate_f = tf.compat.v1.assign(self.f, self.f + self.loss)\n",
        "\n",
        "\t\t\tgrad = tf.gradients(ys=self.loss, xs=self.param)\n",
        "\t\t\tgrad = self.vectorize(grad)\n",
        "\t\t\tupdate_grad = tf.compat.v1.assign(self.g, self.g + grad)\n",
        "\n",
        "\t\t\treturn tf.group(*[update_f, update_grad])\n",
        "\n",
        "\t\tdef cal_lossGv():\n",
        "\t\t\tv = self.inverse_vectorize(self.v, self.param)\n",
        "\t\t\tGv = Gauss_Newton_vec(self.outputs, self.loss, self.param, v)\n",
        "\t\t\tGv = self.vectorize(Gv)\n",
        "\t\t\treturn tf.compat.v1.assign(self.Gv, self.Gv + Gv) \n",
        "\n",
        "\t\t# add regularization term to loss, gradient and Gv and further average over batches \n",
        "\t\tdef add_reg_avg_loss():\n",
        "\t\t\tmodel_weight = self.vectorize(self.param)\n",
        "\t\t\treg = (self.calc_norm(model_weight))**2\n",
        "\t\t\treg = 1.0/(2*self.config.C) * reg\n",
        "\t\t\treturn tf.compat.v1.assign(self.f, reg + self.f/self.config.num_data)\n",
        "\n",
        "\t\tdef add_reg_avg_lossgrad():\n",
        "\t\t\tmodel_weight = self.vectorize(self.param)\n",
        "\t\t\treg_grad = model_weight/self.config.C\n",
        "\t\t\treturn tf.compat.v1.assign(self.g, reg_grad + self.g/self.config.num_data)\n",
        "\n",
        "\t\tdef add_reg_avg_lossGv():\n",
        "\t\t\treturn tf.compat.v1.assign(self.Gv, (self._lambda + 1/self.config.C)*self.v\n",
        "\t\t\t + self.Gv/self.config.GNsize) \n",
        "\n",
        "\t\t# zero out loss, grad and Gv \n",
        "\t\tdef zero_loss():\n",
        "\t\t\treturn tf.compat.v1.assign(self.f, tf.zeros_like(self.f))\n",
        "\t\tdef zero_grad():\n",
        "\t\t\treturn tf.compat.v1.assign(self.g, tf.zeros_like(self.g))\n",
        "\t\tdef zero_Gv():\n",
        "\t\t\treturn tf.compat.v1.assign(self.Gv, tf.zeros_like(self.Gv))\n",
        "\n",
        "\t\treturn (cal_loss(), cal_lossgrad(), cal_lossGv(),\n",
        "\t\t\t\tadd_reg_avg_loss(), add_reg_avg_lossgrad(), add_reg_avg_lossGv(),\n",
        "\t\t\t\tzero_loss(), zero_grad(), zero_Gv())\n",
        "\n",
        "\tdef minibatch(self, data_batch, place_holder_x, place_holder_y, mode):\n",
        "\t\t\"\"\"\n",
        "\t\tA function to evaluate either function value, global gradient or sub-sampled Gv\n",
        "\t\t\"\"\"\n",
        "\t\tif mode not in ('funonly', 'fungrad', 'Gv'):\n",
        "\t\t\traise ValueError('Unknown mode other than funonly & fungrad & Gv!')\n",
        "\n",
        "\t\tinputs, labels = data_batch\n",
        "\t\tnum_data = labels.shape[0]\n",
        "\t\tnum_segment = math.ceil(num_data/self.config.bsize)\n",
        "\t\tx, y = place_holder_x, place_holder_y\n",
        "\n",
        "\t\t# before estimation starts, need to zero out f, grad and Gv according to the mode\n",
        "\n",
        "\t\tif mode == 'funonly':\n",
        "\t\t\tassert num_data == self.config.num_data\n",
        "\t\t\tassert num_segment == self.num_grad_segment\n",
        "\t\t\tself.sess.run(self.zero_loss)\n",
        "\t\telif mode == 'fungrad':\n",
        "\t\t\tassert num_data == self.config.num_data\n",
        "\t\t\tassert num_segment == self.num_grad_segment\n",
        "\t\t\tself.sess.run([self.zero_loss, self.zero_grad])\n",
        "\t\telse:\n",
        "\t\t\tassert num_data == self.config.GNsize\n",
        "\t\t\tassert num_segment == self.num_Gv_segment\n",
        "\t\t\tself.sess.run(self.zero_Gv)\n",
        "\n",
        "\t\tfor i in range(num_segment):\n",
        "\t\t\t\n",
        "\t\t\tload_time = time.time()\n",
        "\t\t\tidx = np.arange(i * self.config.bsize, min((i+1) * self.config.bsize, num_data))\n",
        "\t\t\tbatch_input = inputs[idx]\n",
        "\t\t\tbatch_labels = labels[idx]\n",
        "\t\t\tbatch_input = np.ascontiguousarray(batch_input)\n",
        "\t\t\tbatch_labels = np.ascontiguousarray(batch_labels)\n",
        "\t\t\tself.config.elapsed_time += time.time() - load_time\n",
        "\n",
        "\t\t\tif mode == 'funonly':\n",
        "\n",
        "\t\t\t\tself.sess.run(self.cal_loss, feed_dict={\n",
        "\t\t\t\t\t\t\tx: batch_input, \n",
        "\t\t\t\t\t\t\ty: batch_labels,})\n",
        "\n",
        "\t\t\telif mode == 'fungrad':\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.sess.run(self.cal_lossgrad, feed_dict={\n",
        "\t\t\t\t\t\t\tx: batch_input, \n",
        "\t\t\t\t\t\t\ty: batch_labels,})\n",
        "\t\t\t\t\n",
        "\t\t\telse:\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.sess.run(self.cal_lossGv, feed_dict={\n",
        "\t\t\t\t\t\t\tx: batch_input, \n",
        "\t\t\t\t\t\t\ty: batch_labels})\n",
        "\n",
        "\t\t# average over batches\n",
        "\t\tif mode == 'funonly':\n",
        "\t\t\tself.sess.run(self.add_reg_avg_loss)\n",
        "\t\telif mode == 'fungrad':\n",
        "\t\t\tself.sess.run([self.add_reg_avg_loss, self.add_reg_avg_grad])\n",
        "\t\telse:\n",
        "\t\t\tself.sess.run(self.add_reg_avg_Gv, \n",
        "\t\t\t\tfeed_dict={self._lambda: self.config._lambda})\n",
        "\n",
        "\n",
        "\tdef _update_model(self):\n",
        "\t\tupdate_model_ops = []\n",
        "\t\tx = self.inverse_vectorize(self.s, self.param)\n",
        "\t\tfor i, p in enumerate(self.param):\n",
        "\t\t\top = tf.compat.v1.assign(p, p + (self.alpha-self.old_alpha) * x[i])\n",
        "\t\t\tupdate_model_ops.append(op)\n",
        "\t\treturn tf.group(*update_model_ops)\n",
        "\n",
        "\tdef _init_cg_vars(self):\n",
        "\t\tinit_ops = []\n",
        "\n",
        "\t\tinit_r = tf.compat.v1.assign(self.r, -self.g)\n",
        "\t\tinit_v = tf.compat.v1.assign(self.v, -self.g)\n",
        "\t\tinit_s = tf.compat.v1.assign(self.s, tf.zeros_like(self.g))\n",
        "\t\tgnorm = self.calc_norm(self.g)\n",
        "\t\tinit_rTr = tf.compat.v1.assign(self.rTr, gnorm**2)\n",
        "\t\tinit_cgtol = tf.compat.v1.assign(self.cgtol, self.config.xi*gnorm)\n",
        "\n",
        "\t\tinit_ops = [init_r, init_v, init_s, init_rTr, init_cgtol]\n",
        "\n",
        "\t\treturn tf.group(*init_ops)\n",
        "\n",
        "\tdef _CG(self):\n",
        "\t\t\"\"\"\n",
        "\t\tCG:\n",
        "\t\t\tdefine operations that will be used in method newton\n",
        "\t\tSame as the previous loss calculation,\n",
        "\t\tGv has been summed over batches when samples were fed into Neural Network.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tdef CG_ops():\n",
        "\t\t\t\n",
        "\t\t\tvGv = tf.tensordot(self.v, self.Gv, axes=1)\n",
        "\n",
        "\t\t\talpha = self.rTr / vGv\n",
        "\t\t\twith tf.control_dependencies([alpha]):\n",
        "\t\t\t\tupdate_s = tf.compat.v1.assign(self.s, self.s + alpha * self.v, name='update_s_ops')\n",
        "\t\t\t\tupdate_r = tf.compat.v1.assign(self.r, self.r - alpha * self.Gv, name='update_r_ops')\n",
        "\n",
        "\t\t\t\twith tf.control_dependencies([update_s, update_r]):\n",
        "\t\t\t\t\trnewTrnew = self.calc_norm(update_r)**2\n",
        "\t\t\t\t\tupdate_beta = tf.compat.v1.assign(self.beta, rnewTrnew / self.rTr)\n",
        "\t\t\t\t\twith tf.control_dependencies([update_beta]):\n",
        "\t\t\t\t\t\tupdate_rTr = tf.compat.v1.assign(self.rTr, rnewTrnew, name='update_rTr_ops')\n",
        "\n",
        "\t\t\treturn tf.group(*[update_s, update_beta, update_rTr])\n",
        "\n",
        "\t\tdef update_v():\n",
        "\t\t\treturn tf.compat.v1.assign(self.v, self.r + self.beta*self.v, name='update_v')\n",
        "\n",
        "\t\treturn (CG_ops(), update_v())\n",
        "\n",
        "\n",
        "\tdef newton(self, full_batch, val_batch, saver, network, test_network=None):\n",
        "\t\t\"\"\"\n",
        "\t\tConduct newton steps for training\n",
        "\t\targs:\n",
        "\t\t\tfull_batch & val_batch: provide training set and validation set. The function will\n",
        "\t\t\t\tsave the best model evaluted on validation set for future prediction.\n",
        "\t\t\tnetwork: a tuple contains (x, y, loss, outputs).\n",
        "\t\t\ttest_network: a tuple similar to argument network. If you use layers which behave differently\n",
        "\t\t\t\tin test phase such as batchnorm, a separate test_network is needed.\n",
        "\t\treturn:\n",
        "\t\t\tNone\n",
        "\t\t\"\"\"\n",
        "\t\t# check whether data is valid\n",
        "\t\tfull_inputs, full_labels = full_batch\n",
        "\t\tassert full_inputs.shape[0] == full_labels.shape[0]\n",
        "\n",
        "\t\tif full_inputs.shape[0] != self.config.num_data:\n",
        "\t\t\traise ValueError('The number of full batch inputs does not agree with the config argument.\\\n",
        "\t\t\t\t\t\t\tThis is important because global loss is averaged over those inputs')\n",
        "\n",
        "\t\tx, y, _, outputs = network\n",
        "\n",
        "\t\ttf.compat.v1.summary.scalar('loss', self.f)\n",
        "\t\tmerged = tf.compat.v1.summary.merge_all()\n",
        "\t\ttrain_writer = tf.compat.v1.summary.FileWriter('./summary/train', self.sess.graph)\n",
        "\n",
        "\t\tprint(self.config.args)\n",
        "\t\tif not self.config.screen_log_only:\n",
        "\t\t\tlog_file = open(self.config.log_file, 'w')\n",
        "\t\t\tprint(self.config.args, file=log_file)\n",
        "\t\t\n",
        "\t\tself.minibatch(full_batch, x, y, mode='fungrad')\n",
        "\t\tf = self.sess.run(self.f)\n",
        "\t\toutput_str = 'initial f: {:.3f}'.format(f)\n",
        "\t\tprint(output_str)\n",
        "\t\tif not self.config.screen_log_only:\n",
        "\t\t\tprint(output_str, file=log_file)\n",
        "\t\t\n",
        "\t\tbest_acc = 0.0\n",
        "\n",
        "\t\ttotal_running_time = 0.0\n",
        "\t\tself.config.elapsed_time = 0.0\n",
        "\t\ttotal_CG = 0\n",
        "\t\t\n",
        "\t\tfor k in range(self.config.iter_max):\n",
        "\n",
        "\t\t\t# randomly select the batch for Gv estimation\n",
        "\t\t\tidx = np.random.choice(np.arange(0, full_labels.shape[0]),\n",
        "\t\t\t\t\tsize=self.config.GNsize, replace=False)\n",
        "\n",
        "\t\t\tmini_inputs = full_inputs[idx]\n",
        "\t\t\tmini_labels = full_labels[idx]\n",
        "\n",
        "\t\t\tstart = time.time()\n",
        "\n",
        "\t\t\tself.sess.run(self.init_cg_vars)\n",
        "\t\t\tcgtol = self.sess.run(self.cgtol)\n",
        "\n",
        "\t\t\tavg_cg_time = 0.0\n",
        "\t\t\tfor CGiter in range(1, self.config.CGmax+1):\n",
        "\t\t\t\t\n",
        "\t\t\t\tcg_time = time.time()\n",
        "\t\t\t\tself.minibatch((mini_inputs, mini_labels), x, y, mode='Gv')\n",
        "\t\t\t\tavg_cg_time += time.time() - cg_time\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.sess.run(self.CG)\n",
        "\n",
        "\t\t\t\trnewTrnew = self.sess.run(self.rTr)\n",
        "\t\t\t\t\n",
        "\t\t\t\tif rnewTrnew**0.5 <= cgtol or CGiter == self.config.CGmax:\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t\tself.sess.run(self.update_v)\n",
        "\n",
        "\t\t\tprint('Avg time per Gv iteration: {:.5f} s\\r\\n'.format(avg_cg_time/CGiter))\n",
        "\n",
        "\t\t\tgs, sGs = self.sess.run([self.update_gs, self.update_sGs], feed_dict={\n",
        "\t\t\t\t\tself._lambda: self.config._lambda\n",
        "\t\t\t\t})\n",
        "\t\t\t\n",
        "\t\t\t# line_search\n",
        "\t\t\tf_old = f\n",
        "\t\t\talpha = 1\n",
        "\t\t\twhile True:\n",
        "\n",
        "\t\t\t\told_alpha = 0 if alpha == 1 else alpha/0.5\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.sess.run(self.update_model, feed_dict={\n",
        "\t\t\t\t\tself.alpha:alpha, self.old_alpha:old_alpha\n",
        "\t\t\t\t\t})\n",
        "\n",
        "\t\t\t\tprered = alpha*gs + (alpha**2)*sGs\n",
        "\n",
        "\t\t\t\tself.minibatch(full_batch, x, y, mode='funonly')\n",
        "\t\t\t\tf = self.sess.run(self.f)\n",
        "\n",
        "\t\t\t\tactred = f - f_old\n",
        "\n",
        "\t\t\t\tif actred <= self.config.eta*alpha*gs:\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t\talpha *= 0.5\n",
        "\n",
        "\t\t\t# update lambda\n",
        "\t\t\tratio = actred / prered\n",
        "\t\t\tif ratio < 0.25:\n",
        "\t\t\t\tself.config._lambda *= self.config.boost\n",
        "\t\t\telif ratio >= 0.75:\n",
        "\t\t\t\tself.config._lambda *= self.config.drop\n",
        "\n",
        "\t\t\tself.minibatch(full_batch, x, y, mode='fungrad')\n",
        "\t\t\tf = self.sess.run(self.f)\n",
        "\n",
        "\t\t\tgnorm = self.sess.run(self.gnorm)\n",
        "\n",
        "\t\t\tsummary = self.sess.run(merged)\n",
        "\t\t\ttrain_writer.add_summary(summary, k)\n",
        "\n",
        "\t\t\t# exclude data loading time for fair comparison\n",
        "\t\t\tend = time.time() \n",
        "\t\t\t\n",
        "\t\t\tend = end - self.config.elapsed_time\n",
        "\t\t\ttotal_running_time += end-start\n",
        "\n",
        "\t\t\tself.config.elapsed_time = 0.0\n",
        "\t\t\t\n",
        "\t\t\ttotal_CG += CGiter\n",
        "\n",
        "\t\t\toutput_str = '{}-iter f: {:.3f} |g|: {:.5f} alpha: {:.3e} ratio: {:.3f} lambda: {:.5f} #CG: {} actred: {:.5f} prered: {:.5f} time: {:.3f}'.\\\n",
        "\t\t\t\t\t\t\tformat(k, f, gnorm, alpha, actred/prered, self.config._lambda, CGiter, actred, prered, end-start)\n",
        "\t\t\tprint(output_str)\n",
        "\t\t\tif not self.config.screen_log_only:\n",
        "\t\t\t\tprint(output_str, file=log_file)\n",
        "\n",
        "\t\t\tif val_batch is not None:\n",
        "\t\t\t\t# Evaluate the performance after every Newton Step\n",
        "\t\t\t\tif test_network == None:\n",
        "\t\t\t\t\tval_loss, val_acc, _ = predict(\n",
        "\t\t\t\t\t\tself.sess, \n",
        "\t\t\t\t\t\tnetwork=(x, y, self.loss, outputs),\n",
        "\t\t\t\t\t\ttest_batch=val_batch,\n",
        "\t\t\t\t\t\tbsize=self.config.bsize,\n",
        "\t\t\t\t\t\t)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t# A separat test network part has not been done...\n",
        "\t\t\t\t\tval_loss, val_acc, _ = predict(\n",
        "\t\t\t\t\t\tself.sess, \n",
        "\t\t\t\t\t\tnetwork=test_network,\n",
        "\t\t\t\t\t\ttest_batch=val_batch,\n",
        "\t\t\t\t\t\tbsize=self.config.bsize\n",
        "\t\t\t\t\t\t)\n",
        "\n",
        "\t\t\t\toutput_str = '\\r\\n {}-iter val_acc: {:.3f}% val_loss {:.3f}\\r\\n'.\\\n",
        "\t\t\t\t\tformat(k, val_acc*100, val_loss)\n",
        "\t\t\t\tprint(output_str)\n",
        "\t\t\t\tif not self.config.screen_log_only:\n",
        "\t\t\t\t\tprint(output_str, file=log_file)\n",
        "\n",
        "\t\t\t\tif val_acc > best_acc:\n",
        "\t\t\t\t\tbest_acc = val_acc\n",
        "\t\t\t\t\tcheckpoint_path = self.config.model_file\n",
        "\t\t\t\t\tsave_path = saver.save(self.sess, checkpoint_path)\n",
        "\t\t\t\t\tprint('Best model saved in {}\\r\\n'.format(save_path))\n",
        "\n",
        "\t\tif val_batch is None:\n",
        "\t\t\tcheckpoint_path = self.config.model_file\n",
        "\t\t\tsave_path = saver.save(self.sess, checkpoint_path)\n",
        "\t\t\tprint('Model at the last iteration saved in {}\\r\\n'.format(save_path))\n",
        "\t\t\toutput_str = 'total_#CG {} | total running time {:.3f}s'.format(total_CG, total_running_time)\n",
        "\t\telse:\n",
        "\t\t\toutput_str = 'Final acc: {:.3f}% | best acc {:.3f}% | total_#CG {} | total running time {:.3f}s'.\\\n",
        "\t\t\t\tformat(val_acc*100, best_acc*100, total_CG, total_running_time)\n",
        "\t\tprint(output_str)\n",
        "\t\tif not self.config.screen_log_only:\n",
        "\t\t\tprint(output_str, file=log_file)\n",
        "\t\t\tlog_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xatdN2Zm7BOQ"
      },
      "source": [
        "##Set Train Arguments##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_DZPFd4m7Og"
      },
      "source": [
        "if USE_HFO:\n",
        "    # Arguments for HFO - PSSP dataset\n",
        "    train_args = (\"--optim NewtonCG --GNsize 2048 --C 0.01 --net CNN_4layers --bsize 10240 --iter_max 100 \" +\n",
        "              \"--train_set ./\" + TRAIN_FILE + \" --val_set ./\" + VALID_FILE + \" --dim \" + \n",
        "              str(WINDOW) + \" \" + str(AMINO_ACID_LEN) + \" 1\").split()\n",
        "else:\n",
        "    # Arguments for SGD - PSSP dataset\n",
        "    train_args = (\"--optim SGD --lr 0.05 --momentum 0.01 --C 0.01 --net CNN_4layers --bsize 10240 --epoch_max 1000 \" +\n",
        "              \"--train_set ./\" + TRAIN_FILE + \" --val_set ./\" + VALID_FILE + \" --dim \" +\n",
        "              str(WINDOW) + \" \" + str(AMINO_ACID_LEN) + \" 1\").split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMCxn-8P5tsH"
      },
      "source": [
        "##Declare Train Function##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr528VD1EDj9"
      },
      "source": [
        "# import pdb\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "# import time\n",
        "# import math\n",
        "# import argparse\n",
        "\n",
        "# from net.net import CNN\n",
        "# from newton_cg import newton_cg\n",
        "# from utilities import read_data, predict, ConfigClass, normalize_and_reshape\n",
        "\n",
        "def parse_args():\n",
        "\tparser = argparse.ArgumentParser(description='Newton method on DNN')\n",
        "\tparser.add_argument('--C', dest='C',\n",
        "\t\t\t\t\t  help='regularization term, or so-called weight decay where'+\\\n",
        "\t\t\t\t\t  \t\t'weight_decay = lr/(C*num_of_samples) in this implementation' ,\n",
        "\t\t\t\t\t  default=0.01, type=float)\n",
        "\n",
        "\t# Newton method arguments\n",
        "\tparser.add_argument('--GNsize', dest='GNsize',\n",
        "\t\t\t\t\t  help='number of samples for estimating Gauss-Newton matrix',\n",
        "\t\t\t\t\t  default=4096, type=int)\n",
        "\tparser.add_argument('--iter_max', dest='iter_max',\n",
        "\t\t\t\t\t  help='the maximal number of Newton iterations',\n",
        "\t\t\t\t\t  default=100, type=int)\n",
        "\tparser.add_argument('--xi', dest='xi',\n",
        "\t\t\t\t\t  help='the tolerance in the relative stopping condition for CG',\n",
        "\t\t\t\t\t  default=0.1, type=float)\n",
        "\tparser.add_argument('--drop', dest='drop',\n",
        "\t\t\t\t\t  help='the drop constants for the LM method',\n",
        "\t\t\t\t\t  default=2/3, type=float)\n",
        "\tparser.add_argument('--boost', dest='boost',\n",
        "\t\t\t\t\t  help='the boost constants for the LM method',\n",
        "\t\t\t\t\t  default=3/2, type=float)\n",
        "\tparser.add_argument('--eta', dest='eta',\n",
        "\t\t\t\t\t  help='the parameter for the line search stopping condition',\n",
        "\t\t\t\t\t  default=0.0001, type=float)\n",
        "\tparser.add_argument('--CGmax', dest='CGmax',\n",
        "\t\t\t\t\t  help='the maximal number of CG iterations',\n",
        "\t\t\t\t\t  default=250, type=int)\n",
        "\tparser.add_argument('--lambda', dest='_lambda',\n",
        "\t\t\t\t\t  help='the initial lambda for the LM method',\n",
        "\t\t\t\t\t  default=1, type=float)\n",
        "\n",
        "\t# SGD arguments\n",
        "\tparser.add_argument('--epoch_max', dest='epoch',\n",
        "\t\t\t\t\t  help='number of training epoch',\n",
        "\t\t\t\t\t  default=500, type=int)\n",
        "\tparser.add_argument('--lr', dest='lr',\n",
        "\t\t\t\t\t  help='learning rate',\n",
        "\t\t\t\t\t  default=0.01, type=float)\n",
        "\tparser.add_argument('--decay', dest='lr_decay',\n",
        "\t\t\t\t\t  help='learning rate decay over each mini-batch update',\n",
        "\t\t\t\t\t  default=0, type=float)\n",
        "\tparser.add_argument('--momentum', dest='momentum',\n",
        "\t\t\t\t\t  help='momentum of learning',\n",
        "\t\t\t\t\t  default=0, type=float)\n",
        "\n",
        "\t# Model training arguments\n",
        "\tparser.add_argument('--bsize', dest='bsize',\n",
        "\t\t\t\t\t  help='batch size to evaluate stochastic gradient, Gv, etc. Since the sampled data \\\n",
        "\t\t\t\t\t  for computing Gauss-Newton matrix and etc. might not fit into memeory \\\n",
        "\t\t\t\t\t  for one time, we will split the data into several segements and average\\\n",
        "\t\t\t\t\t  over them.',\n",
        "\t\t\t\t\t  default=1024, type=int)\n",
        "\tparser.add_argument('--net', dest='net',\n",
        "\t\t\t\t\t  help='classifier type',\n",
        "\t\t\t\t\t  default='CNN_4layers', type=str)\n",
        "\tparser.add_argument('--train_set', dest='train_set',\n",
        "\t\t\t\t\t  help='provide the directory of .mat file for training',\n",
        "\t\t\t\t\t  default=None, type=str)\n",
        "\tparser.add_argument('--val_set', dest='val_set',\n",
        "\t\t\t\t\t  help='provide the directory of .mat file for validation',\n",
        "\t\t\t\t\t  default=None, type=str)\n",
        "\tparser.add_argument('--model', dest='model_file',\n",
        "\t\t\t\t\t  help='model saving address',\n",
        "\t\t\t\t\t  default='./saved_model/model.ckpt', type=str)\n",
        "\tparser.add_argument('--log', dest='log_file',\n",
        "\t\t\t\t\t  help='log saving directory',\n",
        "\t\t\t\t\t  default='./running_log/logger.log', type=str)\n",
        "\tparser.add_argument('--screen_log_only', dest='screen_log_only',\n",
        "\t\t\t\t\t  help='screen printing running log instead of storing it',\n",
        "\t\t\t\t\t  action='store_true')\n",
        "\tparser.add_argument('--optim', '-optim', \n",
        "\t\t\t\t\t  help='which optimizer to use: SGD, Adam or NewtonCG',\n",
        "\t\t\t\t\t  default='NewtonCG', type=str)\n",
        "\tparser.add_argument('--loss', dest='loss', \n",
        "\t\t\t\t\t  help='which loss function to use: MSELoss or CrossEntropy',\n",
        "\t\t\t\t\t  default='MSELoss', type=str)\n",
        "\tparser.add_argument('--dim', dest='dim', nargs='+', help='input dimension of data,'+\\\n",
        "\t\t\t\t\t\t'shape must be:  height width num_channels',\n",
        "\t\t\t\t\t  default=[32, 32, 3], type=int)\n",
        "\tparser.add_argument('--seed', dest='seed', help='a nonnegative integer for \\\n",
        "\t\t\t\t\t\treproducibility', type=int)\t \n",
        "\t\n",
        "\targs = parser.parse_args(args=train_args)\n",
        "\treturn args\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "\n",
        "def init_model(param):\n",
        "\tinit_ops = []\n",
        "\tfor p in param:\n",
        "\t\tif 'kernel' in p.name:\n",
        "\t\t\tweight = np.random.standard_normal(p.shape)* np.sqrt(2.0 / ((np.prod(p.get_shape().as_list()[:-1]))))\n",
        "\t\t\topt = tf.compat.v1.assign(p, weight)\n",
        "\t\telif 'bias' in p.name:\n",
        "\t\t\tzeros = np.zeros(p.shape)\n",
        "\t\t\topt = tf.compat.v1.assign(p, zeros)\n",
        "\t\tinit_ops.append(opt)\n",
        "\treturn tf.group(*init_ops)\n",
        "\n",
        "def gradient_trainer(config, sess, network, full_batch, val_batch, saver, test_network):\n",
        "\tx, y, loss, outputs,  = network\n",
        "\t\n",
        "\tglobal_step = tf.Variable(initial_value=0, trainable=False, name='global_step')\n",
        "\tlearning_rate = tf.compat.v1.placeholder(tf.float32, shape=[], name='learning_rate')\n",
        "\n",
        "\t# Probably not a good way to add regularization.\n",
        "\t# Just to confirm the implementation is the same as MATLAB.\n",
        "\treg = 0.0\n",
        "\tparam = tf.compat.v1.trainable_variables()\n",
        "\tfor p in param:\n",
        "\t\treg = reg + tf.reduce_sum(input_tensor=tf.pow(p,2))\n",
        "\treg_const = 1/(2*config.C)\n",
        "\tbatch_size = tf.compat.v1.cast(tf.shape(x)[0], tf.float32)\n",
        "\tloss_with_reg = reg_const*reg + loss/batch_size\n",
        "\n",
        "\tif config.optim == 'SGD':\n",
        "\t\toptimizer = tf.compat.v1.train.MomentumOptimizer(\n",
        "\t\t\t\t\tlearning_rate=learning_rate, \n",
        "\t\t\t\t\tmomentum=config.momentum).minimize(\n",
        "\t\t\t\t\tloss_with_reg, \n",
        "\t\t\t\t\tglobal_step=global_step)\n",
        "\telif config.optim == 'Adam':\n",
        "\t\toptimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate,\n",
        "\t\t\t\t\t\t\t\tbeta1=0.9,\n",
        "\t\t\t\t\t\t\t\tbeta2=0.999,\n",
        "\t\t\t\t\t\t\t\tepsilon=1e-08).minimize(\n",
        "\t\t\t\t\t\t\t\tloss_with_reg, \n",
        "\t\t\t\t\t\t\t\tglobal_step=global_step)\n",
        "\n",
        "\ttrain_inputs, train_labels = full_batch\n",
        "\tnum_data = train_labels.shape[0]\n",
        "\tnum_iters = math.ceil(num_data/config.bsize)\n",
        "\n",
        "\tprint(config.args)\n",
        "\tif not config.screen_log_only:\n",
        "\t\tlog_file = open(config.log_file, 'w')\n",
        "\t\tprint(config.args, file=log_file)\n",
        "\tsess.run(tf.compat.v1.global_variables_initializer())\n",
        "\t\n",
        "\n",
        "\tprint('-------------- initializing network by methods in He et al. (2015) --------------')\n",
        "\tparam = tf.compat.v1.trainable_variables()\n",
        "\tsess.run(init_model(param))\n",
        "\n",
        "\ttotal_running_time = 0.0\n",
        "\tbest_acc = 0.0\n",
        "\tlr = config.lr\n",
        "\n",
        "\tfor epoch in range(0, args.epoch):\n",
        "\t\t\n",
        "\t\tloss_avg = 0.0\n",
        "\t\tstart = time.time()\n",
        "\n",
        "\t\tfor i in range(num_iters):\n",
        "\t\t\t\n",
        "\t\t\tload_time = time.time()\n",
        "\t\t\t# randomly select the batch\n",
        "\t\t\tidx = np.random.choice(np.arange(0, num_data), \n",
        "\t\t\t\t\tsize=config.bsize, replace=False)\n",
        "\n",
        "\t\t\tbatch_input = train_inputs[idx]\n",
        "\t\t\tbatch_labels = train_labels[idx]\n",
        "\t\t\tbatch_input = np.ascontiguousarray(batch_input)\n",
        "\t\t\tbatch_labels = np.ascontiguousarray(batch_labels)\n",
        "\t\t\tconfig.elapsed_time += time.time() - load_time\n",
        "\n",
        "\t\t\tstep, _, batch_loss= sess.run(\n",
        "\t\t\t\t[global_step, optimizer, loss_with_reg],\n",
        "\t\t\t\tfeed_dict = {x: batch_input, y: batch_labels, learning_rate: lr}\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\t# print initial loss\n",
        "\t\t\tif epoch == 0 and i == 0:\n",
        "\t\t\t\toutput_str = 'initial f (reg + avg. loss of 1st batch): {:.3f}'.format(batch_loss)\n",
        "\t\t\t\tprint(output_str)\n",
        "\t\t\t\tif not config.screen_log_only:\n",
        "\t\t\t\t\tprint(output_str, file=log_file)\n",
        "\n",
        "\t\t\tloss_avg = loss_avg + batch_loss\n",
        "\t\t\t# print log every 10% of the iterations\n",
        "\t\t\tif i % math.ceil(num_iters/10) == 0:\n",
        "\t\t\t\tend = time.time()\n",
        "\t\t\t\toutput_str = 'Epoch {}: {}/{} | loss {:.4f} | lr {:.6} | elapsed time {:.3f}'\\\n",
        "\t\t\t\t\t.format(epoch, i, num_iters, batch_loss , lr, end-start)\n",
        "\t\t\t\tprint(output_str)\n",
        "\t\t\t\tif not config.screen_log_only:\n",
        "\t\t\t\t\tprint(output_str, file=log_file)\n",
        "\t\t\t\n",
        "\t\t\t# adjust learning rate for SGD by inverse time decay\n",
        "\t\t\tif args.optim != 'Adam':\n",
        "\t\t\t\tlr = config.lr/(1 + args.lr_decay*step)\n",
        "\n",
        "\t\t# exclude data loading time for fair comparison\n",
        "\t\tepoch_end = time.time() - config.elapsed_time\n",
        "\t\ttotal_running_time += epoch_end - start\n",
        "\t\tconfig.elapsed_time = 0.0\n",
        "\t\t\n",
        "\t\tif val_batch is None:\n",
        "\t\t\toutput_str = 'In epoch {} train loss: {:.3f} | epoch time {:.3f}'\\\n",
        "\t\t\t\t.format(epoch, loss_avg/(i+1), epoch_end-start)\t\t\t\n",
        "\t\telse:\n",
        "\t\t\tif test_network == None:\n",
        "\t\t\t\tval_loss, val_acc, _ = predict(\n",
        "\t\t\t\t\tsess, \n",
        "\t\t\t\t\tnetwork=(x, y, loss, outputs),\n",
        "\t\t\t\t\ttest_batch=val_batch,\n",
        "\t\t\t\t\tbsize=config.bsize\n",
        "\t\t\t\t\t)\n",
        "\t\t\telse:\n",
        "\t\t\t\t# A separat test network part have been done...\n",
        "\t\t\t\tval_loss, val_acc, _ = predict(\n",
        "\t\t\t\t\tsess, \n",
        "\t\t\t\t\tnetwork=test_network,\n",
        "\t\t\t\t\ttest_batch=val_batch,\n",
        "\t\t\t\t\tbsize=config.bsize\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\n",
        "\t\t\toutput_str = 'In epoch {} train loss: {:.3f} | val loss: {:.3f} | val accuracy: {:.3f}% | epoch time {:.3f}'\\\n",
        "\t\t\t\t.format(epoch, loss_avg/(i+1), val_loss, val_acc*100, epoch_end-start)\n",
        "\t\t\n",
        "\t\t\tif val_acc > best_acc:\n",
        "\t\t\t\tbest_acc = val_acc\n",
        "\t\t\t\tcheckpoint_path = config.model_file \n",
        "\t\t\t\tsave_path = saver.save(sess, checkpoint_path)\n",
        "\t\t\t\tprint('Saved best model in {}'.format(save_path))\n",
        "\n",
        "\t\tprint(output_str)\n",
        "\t\tif not config.screen_log_only:\n",
        "\t\t\tprint(output_str, file=log_file)\n",
        "\n",
        "\tif val_batch is None:\n",
        "\t\tcheckpoint_path = config.model_file \n",
        "\t\tsave_path = saver.save(sess, checkpoint_path)\n",
        "\t\tprint('Model at the last iteration saved in {}\\r\\n'.format(save_path))\n",
        "\t\toutput_str = 'total running time {:.3f}s'.format(total_running_time)\n",
        "\telse:\n",
        "\t\toutput_str = 'Final acc: {:.3f}% | best acc {:.3f}% | total running time {:.3f}s'\\\n",
        "\t\t\t.format(val_acc*100, best_acc*100, total_running_time)\n",
        "\t\n",
        "\tprint(output_str)\n",
        "\tif not config.screen_log_only:\n",
        "\t\tprint(output_str, file=log_file)\n",
        "\t\tlog_file.close()\n",
        "\n",
        "def newton_trainer(config, sess, network, full_batch, val_batch, saver, test_network):\n",
        "\n",
        "\t_, _, loss, outputs = network\n",
        "\tnewton_solver = newton_cg(config, sess, outputs, loss)\n",
        "\tsess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "\tprint('-------------- initializing network by methods in He et al. (2015) --------------')\n",
        "\tparam = tf.compat.v1.trainable_variables()\n",
        "\tsess.run(init_model(param))\n",
        "\tnewton_solver.newton(full_batch, val_batch, saver, network, test_network)\n",
        "\n",
        "\n",
        "def train_model():\n",
        "\tfull_batch, num_cls, label_enum = read_data(filename=args.train_set, dim=args.dim)\n",
        "\t\n",
        "\tif args.val_set is None:\n",
        "\t\tprint('No validation set is provided. Will output model at the last iteration.')\n",
        "\t\tval_batch = None\n",
        "\telse:\n",
        "\t\tval_batch, _, _ = read_data(filename=args.val_set, dim=args.dim, label_enum=label_enum)\n",
        "\n",
        "\tnum_data = full_batch[0].shape[0]\n",
        "\t\n",
        "\tconfig = ConfigClass(args, num_data, num_cls)\n",
        "\n",
        "\tif isinstance(config.seed, int):\n",
        "\t\ttf.compat.v1.random.set_random_seed(config.seed)\n",
        "\t\tnp.random.seed(config.seed)\n",
        "\n",
        "\tif config.net in ('CNN_4layers', 'CNN_7layers', 'VGG11', 'VGG13', 'VGG16','VGG19'):\n",
        "\t\tx, y, outputs = CNN(config.net, num_cls, config.dim)\n",
        "\t\ttest_network = None\n",
        "\telse:\n",
        "\t\traise ValueError('Unrecognized training model')\n",
        "\n",
        "\tif config.loss == 'MSELoss':\n",
        "\t\tloss = tf.reduce_sum(input_tensor=tf.pow(outputs-y, 2))\n",
        "\telse:\n",
        "\t\tloss = tf.reduce_sum(input_tensor=tf.nn.softmax_cross_entropy_with_logits(logits=outputs, labels=y))\n",
        "\t\n",
        "\tnetwork = (x, y, loss, outputs)\n",
        "\n",
        "\tsess_config = tf.compat.v1.ConfigProto()\n",
        "\tsess_config.gpu_options.allow_growth = True\n",
        "\n",
        "\twith tf.compat.v1.Session(config=sess_config) as sess:\n",
        "\t\t\n",
        "\t\tfull_batch[0], mean_tr = normalize_and_reshape(full_batch[0], dim=config.dim, mean_tr=None)\n",
        "\t\tif val_batch is not None:\n",
        "\t\t\tval_batch[0], _ = normalize_and_reshape(val_batch[0], dim=config.dim, mean_tr=mean_tr)\n",
        "\n",
        "\t\tparam = tf.compat.v1.trainable_variables()\n",
        "\n",
        "\t\tmean_param = tf.compat.v1.get_variable(name='mean_tr', initializer=mean_tr, trainable=False, \n",
        "\t\t\t\t\tvalidate_shape=True, use_resource=False)\n",
        "\t\tlabel_enum_var=tf.compat.v1.get_variable(name='label_enum', initializer=label_enum, trainable=False,\n",
        "\t\t\t\t\tvalidate_shape=True, use_resource=False)\n",
        "\t\tsaver = tf.compat.v1.train.Saver(var_list=param+[mean_param])\n",
        "\t\t\n",
        "\t\tif config.optim in ('SGD', 'Adam'):\n",
        "\t\t\tgradient_trainer(\n",
        "\t\t\t\tconfig, sess, network, full_batch, val_batch, saver, test_network)\n",
        "\t\telif config.optim == 'NewtonCG':\n",
        "\t\t\tnewton_trainer(\n",
        "\t\t\t\tconfig, sess, network, full_batch, val_batch, saver, test_network=test_network)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi6UglYiD7Zd"
      },
      "source": [
        "## Train ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSgKfh4r5lu7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7dca214-af62-41a8-d120-2137e0bd4e60"
      },
      "source": [
        "train_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You choose not to specify a random seed.A different result is produced after each run.\n",
            "Saving log to: ./running_log/logger.log\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "No mean of data provided! Normalize images by their own mean.\n",
            "Normalize images according to the provided mean.\n",
            "-------------- initializing network by methods in He et al. (2015) --------------\n",
            "Namespace(C=0.01, CGmax=250, GNsize=2048, _lambda=1, boost=1.5, bsize=10240, dim=[15, 20, 1], drop=0.6666666666666666, epoch=500, eta=0.0001, iter_max=100, log_file='./running_log/logger.log', loss='MSELoss', lr=0.01, lr_decay=0, model_file='./saved_model/model.ckpt', momentum=0, net='CNN_4layers', optim='NewtonCG', screen_log_only=False, seed=None, train_set='./plus7_cb513_train_fold0.mat', val_set='./plus7_cb513_test_fold0.mat', xi=0.1)\n",
            "initial f: 1.281\n",
            "Avg time per Gv iteration: 0.44609 s\n",
            "\n",
            "0-iter f: 0.953 |g|: 0.58002 alpha: 1.000e+00 ratio: 0.995 lambda: 0.66667 #CG: 1 actred: -0.32819 prered: -0.32997 time: 3.118\n",
            "\n",
            " 0-iter val_acc: 42.353% val_loss 0.673\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09632 s\n",
            "\n",
            "1-iter f: 0.821 |g|: 1.72095 alpha: 1.000e+00 ratio: 0.899 lambda: 0.44444 #CG: 6 actred: -0.13263 prered: -0.14753 time: 3.126\n",
            "\n",
            " 1-iter val_acc: 65.442% val_loss 0.549\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09645 s\n",
            "\n",
            "2-iter f: 0.742 |g|: 1.01090 alpha: 1.000e+00 ratio: 1.074 lambda: 0.29630 #CG: 3 actred: -0.07883 prered: -0.07338 time: 2.826\n",
            "\n",
            " 2-iter val_acc: 68.049% val_loss 0.477\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09617 s\n",
            "\n",
            "3-iter f: 0.691 |g|: 0.80550 alpha: 1.000e+00 ratio: 0.978 lambda: 0.19753 #CG: 6 actred: -0.05041 prered: -0.05151 time: 3.117\n",
            "\n",
            " 3-iter val_acc: 70.063% val_loss 0.435\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09627 s\n",
            "\n",
            "4-iter f: 0.672 |g|: 1.00382 alpha: 1.000e+00 ratio: 0.887 lambda: 0.13169 #CG: 6 actred: -0.01949 prered: -0.02197 time: 3.119\n",
            "\n",
            " 4-iter val_acc: 71.650% val_loss 0.425\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09632 s\n",
            "\n",
            "5-iter f: 0.668 |g|: 0.56367 alpha: 1.000e+00 ratio: 0.853 lambda: 0.08779 #CG: 4 actred: -0.00397 prered: -0.00465 time: 2.925\n",
            "\n",
            " 5-iter val_acc: 71.721% val_loss 0.423\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09621 s\n",
            "\n",
            "6-iter f: 0.651 |g|: 1.25736 alpha: 1.000e+00 ratio: 0.826 lambda: 0.05853 #CG: 9 actred: -0.01678 prered: -0.02032 time: 3.404\n",
            "\n",
            " 6-iter val_acc: 72.835% val_loss 0.418\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09606 s\n",
            "\n",
            "7-iter f: 0.649 |g|: 0.10650 alpha: 1.000e+00 ratio: 1.002 lambda: 0.03902 #CG: 2 actred: -0.00220 prered: -0.00219 time: 2.731\n",
            "\n",
            " 7-iter val_acc: 72.681% val_loss 0.414\n",
            "\n",
            "Avg time per Gv iteration: 0.09617 s\n",
            "\n",
            "8-iter f: 0.618 |g|: 1.36355 alpha: 1.000e+00 ratio: 0.823 lambda: 0.02601 #CG: 27 actred: -0.03126 prered: -0.03799 time: 5.139\n",
            "\n",
            " 8-iter val_acc: 73.830% val_loss 0.399\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09609 s\n",
            "\n",
            "9-iter f: 0.614 |g|: 0.38297 alpha: 1.000e+00 ratio: 0.919 lambda: 0.01734 #CG: 4 actred: -0.00392 prered: -0.00427 time: 2.922\n",
            "\n",
            " 9-iter val_acc: 73.972% val_loss 0.398\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09618 s\n",
            "\n",
            "10-iter f: 0.594 |g|: 2.17545 alpha: 5.000e-01 ratio: 0.677 lambda: 0.01734 #CG: 30 actred: -0.01922 prered: -0.02839 time: 6.020\n",
            "\n",
            " 10-iter val_acc: 74.553% val_loss 0.395\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09642 s\n",
            "\n",
            "11-iter f: 0.590 |g|: 0.10536 alpha: 1.000e+00 ratio: 0.999 lambda: 0.01156 #CG: 2 actred: -0.00487 prered: -0.00487 time: 2.733\n",
            "\n",
            " 11-iter val_acc: 74.742% val_loss 0.389\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09606 s\n",
            "\n",
            "12-iter f: 0.579 |g|: 6.15369 alpha: 5.000e-01 ratio: 0.308 lambda: 0.01156 #CG: 59 actred: -0.01063 prered: -0.03455 time: 8.808\n",
            "\n",
            " 12-iter val_acc: 74.091% val_loss 0.395\n",
            "\n",
            "Avg time per Gv iteration: 0.09598 s\n",
            "\n",
            "13-iter f: 0.562 |g|: 0.16729 alpha: 1.000e+00 ratio: 0.998 lambda: 0.00771 #CG: 2 actred: -0.01671 prered: -0.01675 time: 2.732\n",
            "\n",
            " 13-iter val_acc: 74.766% val_loss 0.385\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09593 s\n",
            "\n",
            "14-iter f: 0.554 |g|: 5.15224 alpha: 5.000e-01 ratio: 0.208 lambda: 0.01156 #CG: 61 actred: -0.00852 prered: -0.04098 time: 8.998\n",
            "\n",
            " 14-iter val_acc: 74.126% val_loss 0.400\n",
            "\n",
            "Avg time per Gv iteration: 0.09603 s\n",
            "\n",
            "15-iter f: 0.535 |g|: 0.22407 alpha: 1.000e+00 ratio: 0.999 lambda: 0.00771 #CG: 2 actred: -0.01829 prered: -0.01831 time: 2.735\n",
            "\n",
            " 15-iter val_acc: 74.861% val_loss 0.383\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09613 s\n",
            "\n",
            "16-iter f: 0.523 |g|: 3.30595 alpha: 2.500e-01 ratio: 0.542 lambda: 0.00771 #CG: 67 actred: -0.01209 prered: -0.02230 time: 10.181\n",
            "\n",
            " 16-iter val_acc: 74.719% val_loss 0.382\n",
            "\n",
            "Avg time per Gv iteration: 0.09720 s\n",
            "\n",
            "17-iter f: 0.519 |g|: 0.17757 alpha: 1.000e+00 ratio: 0.996 lambda: 0.00514 #CG: 2 actred: -0.00454 prered: -0.00456 time: 2.741\n",
            "\n",
            " 17-iter val_acc: 75.074% val_loss 0.380\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09672 s\n",
            "\n",
            "18-iter f: 0.495 |g|: 3.09607 alpha: 5.000e-01 ratio: 0.566 lambda: 0.00514 #CG: 76 actred: -0.02406 prered: -0.04251 time: 10.515\n",
            "\n",
            " 18-iter val_acc: 74.671% val_loss 0.382\n",
            "\n",
            "Avg time per Gv iteration: 0.09627 s\n",
            "\n",
            "19-iter f: 0.490 |g|: 0.29998 alpha: 1.000e+00 ratio: 0.998 lambda: 0.00343 #CG: 2 actred: -0.00454 prered: -0.00455 time: 2.737\n",
            "\n",
            " 19-iter val_acc: 74.956% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09617 s\n",
            "\n",
            "20-iter f: 0.474 |g|: 0.82672 alpha: 2.500e-01 ratio: 0.554 lambda: 0.00343 #CG: 77 actred: -0.01603 prered: -0.02894 time: 11.127\n",
            "\n",
            " 20-iter val_acc: 74.920% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09615 s\n",
            "\n",
            "21-iter f: 0.470 |g|: 0.17539 alpha: 1.000e+00 ratio: 0.918 lambda: 0.00228 #CG: 5 actred: -0.00383 prered: -0.00417 time: 3.022\n",
            "\n",
            " 21-iter val_acc: 74.908% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09616 s\n",
            "\n",
            "22-iter f: 0.470 |g|: 2.80150 alpha: 5.000e-01 ratio: 0.016 lambda: 0.00343 #CG: 99 actred: -0.00083 prered: -0.05225 time: 12.664\n",
            "\n",
            " 22-iter val_acc: 74.375% val_loss 0.396\n",
            "\n",
            "Avg time per Gv iteration: 0.09618 s\n",
            "\n",
            "23-iter f: 0.450 |g|: 2.08136 alpha: 1.000e+00 ratio: 0.943 lambda: 0.00228 #CG: 4 actred: -0.01996 prered: -0.02117 time: 2.924\n",
            "\n",
            " 23-iter val_acc: 74.908% val_loss 0.384\n",
            "\n",
            "Avg time per Gv iteration: 0.09618 s\n",
            "\n",
            "24-iter f: 0.446 |g|: 0.52626 alpha: 1.000e+00 ratio: 0.921 lambda: 0.00152 #CG: 4 actred: -0.00388 prered: -0.00421 time: 2.924\n",
            "\n",
            " 24-iter val_acc: 75.003% val_loss 0.382\n",
            "\n",
            "Avg time per Gv iteration: 0.09585 s\n",
            "\n",
            "25-iter f: 0.434 |g|: 1.06119 alpha: 1.250e-01 ratio: 0.695 lambda: 0.00152 #CG: 77 actred: -0.01222 prered: -0.01758 time: 11.696\n",
            "\n",
            " 25-iter val_acc: 74.944% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09619 s\n",
            "\n",
            "26-iter f: 0.432 |g|: 0.22738 alpha: 1.000e+00 ratio: 0.918 lambda: 0.00101 #CG: 4 actred: -0.00199 prered: -0.00217 time: 2.924\n",
            "\n",
            " 26-iter val_acc: 74.884% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09590 s\n",
            "\n",
            "27-iter f: 0.430 |g|: 4.57543 alpha: 2.500e-01 ratio: 0.057 lambda: 0.00152 #CG: 120 actred: -0.00178 prered: -0.03143 time: 15.248\n",
            "\n",
            " 27-iter val_acc: 74.671% val_loss 0.385\n",
            "\n",
            "Avg time per Gv iteration: 0.09629 s\n",
            "\n",
            "28-iter f: 0.421 |g|: 0.40425 alpha: 1.000e+00 ratio: 0.992 lambda: 0.00101 #CG: 3 actred: -0.00879 prered: -0.00886 time: 2.829\n",
            "\n",
            " 28-iter val_acc: 75.086% val_loss 0.380\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09582 s\n",
            "\n",
            "29-iter f: 0.415 |g|: 2.98994 alpha: 1.250e-01 ratio: 0.356 lambda: 0.00101 #CG: 103 actred: -0.00635 prered: -0.01783 time: 14.197\n",
            "\n",
            " 29-iter val_acc: 74.849% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09649 s\n",
            "\n",
            "30-iter f: 0.410 |g|: 0.22902 alpha: 1.000e+00 ratio: 0.996 lambda: 0.00068 #CG: 2 actred: -0.00432 prered: -0.00434 time: 2.734\n",
            "\n",
            " 30-iter val_acc: 74.896% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09603 s\n",
            "\n",
            "31-iter f: 0.403 |g|: 1.74739 alpha: 1.250e-01 ratio: 0.506 lambda: 0.00068 #CG: 129 actred: -0.00769 prered: -0.01521 time: 16.726\n",
            "\n",
            " 31-iter val_acc: 74.636% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09642 s\n",
            "\n",
            "32-iter f: 0.399 |g|: 0.36118 alpha: 1.000e+00 ratio: 0.893 lambda: 0.00045 #CG: 4 actred: -0.00312 prered: -0.00349 time: 2.925\n",
            "\n",
            " 32-iter val_acc: 75.228% val_loss 0.377\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.09589 s\n",
            "\n",
            "33-iter f: 0.396 |g|: 2.29197 alpha: 1.250e-01 ratio: 0.300 lambda: 0.00045 #CG: 123 actred: -0.00390 prered: -0.01299 time: 16.125\n",
            "\n",
            " 33-iter val_acc: 74.873% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09610 s\n",
            "\n",
            "34-iter f: 0.392 |g|: 0.19246 alpha: 1.000e+00 ratio: 1.001 lambda: 0.00030 #CG: 1 actred: -0.00322 prered: -0.00322 time: 2.632\n",
            "\n",
            " 34-iter val_acc: 74.825% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09571 s\n",
            "\n",
            "35-iter f: 0.387 |g|: 0.49274 alpha: 1.250e-01 ratio: 0.416 lambda: 0.00030 #CG: 157 actred: -0.00526 prered: -0.01264 time: 19.365\n",
            "\n",
            " 35-iter val_acc: 74.991% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09600 s\n",
            "\n",
            "36-iter f: 0.384 |g|: 1.19199 alpha: 6.250e-02 ratio: 0.453 lambda: 0.00030 #CG: 93 actred: -0.00278 prered: -0.00614 time: 13.828\n",
            "\n",
            " 36-iter val_acc: 74.695% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09574 s\n",
            "\n",
            "37-iter f: 0.383 |g|: 0.15147 alpha: 1.000e+00 ratio: 0.935 lambda: 0.00020 #CG: 4 actred: -0.00159 prered: -0.00170 time: 2.921\n",
            "\n",
            " 37-iter val_acc: 74.766% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09585 s\n",
            "\n",
            "38-iter f: 0.379 |g|: 1.65535 alpha: 1.250e-01 ratio: 0.405 lambda: 0.00020 #CG: 167 actred: -0.00402 prered: -0.00992 time: 20.331\n",
            "\n",
            " 38-iter val_acc: 74.778% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09626 s\n",
            "\n",
            "39-iter f: 0.377 |g|: 0.19095 alpha: 1.000e+00 ratio: 0.876 lambda: 0.00013 #CG: 4 actred: -0.00156 prered: -0.00178 time: 2.929\n",
            "\n",
            " 39-iter val_acc: 75.003% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09575 s\n",
            "\n",
            "40-iter f: 0.376 |g|: 1.76900 alpha: 6.250e-02 ratio: 0.214 lambda: 0.00020 #CG: 171 actred: -0.00133 prered: -0.00623 time: 21.288\n",
            "\n",
            " 40-iter val_acc: 74.825% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09623 s\n",
            "\n",
            "41-iter f: 0.374 |g|: 0.13507 alpha: 1.000e+00 ratio: 0.996 lambda: 0.00013 #CG: 2 actred: -0.00140 prered: -0.00141 time: 2.730\n",
            "\n",
            " 41-iter val_acc: 74.979% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09576 s\n",
            "\n",
            "42-iter f: 0.372 |g|: 1.12972 alpha: 6.250e-02 ratio: 0.505 lambda: 0.00013 #CG: 194 actred: -0.00259 prered: -0.00514 time: 23.483\n",
            "\n",
            " 42-iter val_acc: 74.932% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09594 s\n",
            "\n",
            "43-iter f: 0.371 |g|: 0.10986 alpha: 1.000e+00 ratio: 0.996 lambda: 0.00009 #CG: 3 actred: -0.00048 prered: -0.00048 time: 2.824\n",
            "\n",
            " 43-iter val_acc: 74.624% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09583 s\n",
            "\n",
            "44-iter f: 0.369 |g|: 1.24120 alpha: 6.250e-02 ratio: 0.454 lambda: 0.00009 #CG: 216 actred: -0.00207 prered: -0.00457 time: 25.615\n",
            "\n",
            " 44-iter val_acc: 74.944% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09603 s\n",
            "\n",
            "45-iter f: 0.369 |g|: 0.11684 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00006 #CG: 1 actred: -0.00045 prered: -0.00045 time: 2.630\n",
            "\n",
            " 45-iter val_acc: 74.742% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09591 s\n",
            "\n",
            "46-iter f: 0.368 |g|: 2.12475 alpha: 6.250e-02 ratio: 0.161 lambda: 0.00009 #CG: 212 actred: -0.00076 prered: -0.00471 time: 25.242\n",
            "\n",
            " 46-iter val_acc: 74.790% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09611 s\n",
            "\n",
            "47-iter f: 0.367 |g|: 0.21035 alpha: 1.000e+00 ratio: 0.996 lambda: 0.00006 #CG: 1 actred: -0.00134 prered: -0.00134 time: 2.632\n",
            "\n",
            " 47-iter val_acc: 74.778% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09632 s\n",
            "\n",
            "48-iter f: 0.366 |g|: 1.93384 alpha: 6.250e-02 ratio: 0.137 lambda: 0.00009 #CG: 171 actred: -0.00065 prered: -0.00473 time: 21.385\n",
            "\n",
            " 48-iter val_acc: 74.790% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09583 s\n",
            "\n",
            "49-iter f: 0.365 |g|: 0.17966 alpha: 1.000e+00 ratio: 0.996 lambda: 0.00006 #CG: 2 actred: -0.00111 prered: -0.00112 time: 2.728\n",
            "\n",
            " 49-iter val_acc: 74.790% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09594 s\n",
            "\n",
            "50-iter f: 0.364 |g|: 1.63897 alpha: 6.250e-02 ratio: 0.109 lambda: 0.00009 #CG: 197 actred: -0.00053 prered: -0.00483 time: 23.805\n",
            "\n",
            " 50-iter val_acc: 74.624% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09596 s\n",
            "\n",
            "51-iter f: 0.363 |g|: 0.15324 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00006 #CG: 2 actred: -0.00101 prered: -0.00101 time: 2.729\n",
            "\n",
            " 51-iter val_acc: 74.612% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09571 s\n",
            "\n",
            "52-iter f: 0.362 |g|: 0.61078 alpha: 3.125e-02 ratio: 0.596 lambda: 0.00006 #CG: 212 actred: -0.00158 prered: -0.00266 time: 25.784\n",
            "\n",
            " 52-iter val_acc: 74.671% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09574 s\n",
            "\n",
            "53-iter f: 0.361 |g|: 0.09766 alpha: 1.000e+00 ratio: 0.814 lambda: 0.00004 #CG: 5 actred: -0.00060 prered: -0.00074 time: 3.011\n",
            "\n",
            " 53-iter val_acc: 75.050% val_loss 0.375\n",
            "\n",
            "Avg time per Gv iteration: 0.09571 s\n",
            "\n",
            "54-iter f: 0.360 |g|: 0.70146 alpha: 1.250e-01 ratio: 0.254 lambda: 0.00004 #CG: 222 actred: -0.00154 prered: -0.00607 time: 25.569\n",
            "\n",
            " 54-iter val_acc: 74.648% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09577 s\n",
            "\n",
            "55-iter f: 0.359 |g|: 1.11963 alpha: 5.000e-01 ratio: 0.379 lambda: 0.00004 #CG: 15 actred: -0.00110 prered: -0.00290 time: 4.560\n",
            "\n",
            " 55-iter val_acc: 74.825% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09594 s\n",
            "\n",
            "56-iter f: 0.358 |g|: 0.11129 alpha: 1.000e+00 ratio: 0.995 lambda: 0.00003 #CG: 1 actred: -0.00034 prered: -0.00034 time: 2.627\n",
            "\n",
            " 56-iter val_acc: 74.813% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09568 s\n",
            "\n",
            "57-iter f: 0.357 |g|: 0.73608 alpha: 6.250e-02 ratio: 0.292 lambda: 0.00003 #CG: 246 actred: -0.00128 prered: -0.00439 time: 28.474\n",
            "\n",
            " 57-iter val_acc: 74.825% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09609 s\n",
            "\n",
            "58-iter f: 0.356 |g|: 0.13350 alpha: 1.000e+00 ratio: 0.801 lambda: 0.00002 #CG: 5 actred: -0.00055 prered: -0.00069 time: 3.010\n",
            "\n",
            " 58-iter val_acc: 74.956% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09564 s\n",
            "\n",
            "59-iter f: 0.355 |g|: 1.02379 alpha: 3.125e-02 ratio: 0.493 lambda: 0.00002 #CG: 237 actred: -0.00114 prered: -0.00232 time: 28.171\n",
            "\n",
            " 59-iter val_acc: 74.908% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09608 s\n",
            "\n",
            "60-iter f: 0.355 |g|: 0.06864 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00001 #CG: 1 actred: -0.00027 prered: -0.00027 time: 2.627\n",
            "\n",
            " 60-iter val_acc: 74.908% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09566 s\n",
            "\n",
            "61-iter f: 0.354 |g|: 0.88876 alpha: 6.250e-02 ratio: 0.334 lambda: 0.00001 #CG: 250 actred: -0.00098 prered: -0.00293 time: 28.841\n",
            "\n",
            " 61-iter val_acc: 74.695% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09571 s\n",
            "\n",
            "62-iter f: 0.354 |g|: 0.08378 alpha: 1.000e+00 ratio: 0.990 lambda: 0.00001 #CG: 2 actred: -0.00026 prered: -0.00026 time: 2.724\n",
            "\n",
            " 62-iter val_acc: 74.849% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09563 s\n",
            "\n",
            "63-iter f: 0.353 |g|: 0.60601 alpha: 3.125e-02 ratio: 0.492 lambda: 0.00001 #CG: 250 actred: -0.00100 prered: -0.00203 time: 29.416\n",
            "\n",
            " 63-iter val_acc: 74.695% val_loss 0.376\n",
            "\n",
            "Avg time per Gv iteration: 0.09598 s\n",
            "\n",
            "64-iter f: 0.353 |g|: 0.07399 alpha: 1.000e+00 ratio: 0.876 lambda: 0.00001 #CG: 4 actred: -0.00019 prered: -0.00021 time: 2.913\n",
            "\n",
            " 64-iter val_acc: 74.742% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09563 s\n",
            "\n",
            "65-iter f: 0.352 |g|: 0.99201 alpha: 6.250e-02 ratio: 0.131 lambda: 0.00001 #CG: 250 actred: -0.00036 prered: -0.00274 time: 28.839\n",
            "\n",
            " 65-iter val_acc: 74.683% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09597 s\n",
            "\n",
            "66-iter f: 0.352 |g|: 0.10731 alpha: 1.000e+00 ratio: 0.885 lambda: 0.00001 #CG: 4 actred: -0.00044 prered: -0.00050 time: 2.915\n",
            "\n",
            " 66-iter val_acc: 74.588% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09580 s\n",
            "\n",
            "67-iter f: 0.351 |g|: 1.92153 alpha: 3.125e-02 ratio: 0.161 lambda: 0.00001 #CG: 250 actred: -0.00035 prered: -0.00219 time: 29.471\n",
            "\n",
            " 67-iter val_acc: 74.802% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09641 s\n",
            "\n",
            "68-iter f: 0.351 |g|: 0.16019 alpha: 1.000e+00 ratio: 0.998 lambda: 0.00001 #CG: 1 actred: -0.00086 prered: -0.00086 time: 2.627\n",
            "\n",
            " 68-iter val_acc: 74.588% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09602 s\n",
            "\n",
            "69-iter f: 0.350 |g|: 0.62501 alpha: 3.125e-02 ratio: 0.418 lambda: 0.00001 #CG: 218 actred: -0.00065 prered: -0.00156 time: 26.450\n",
            "\n",
            " 69-iter val_acc: 74.648% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09583 s\n",
            "\n",
            "70-iter f: 0.350 |g|: 0.05958 alpha: 1.000e+00 ratio: 0.997 lambda: 0.00000 #CG: 2 actred: -0.00012 prered: -0.00012 time: 2.722\n",
            "\n",
            " 70-iter val_acc: 74.565% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09569 s\n",
            "\n",
            "71-iter f: 0.349 |g|: 0.81728 alpha: 3.125e-02 ratio: 0.437 lambda: 0.00000 #CG: 250 actred: -0.00063 prered: -0.00145 time: 29.432\n",
            "\n",
            " 71-iter val_acc: 74.695% val_loss 0.377\n",
            "\n",
            "Avg time per Gv iteration: 0.09594 s\n",
            "\n",
            "72-iter f: 0.349 |g|: 0.08102 alpha: 1.000e+00 ratio: 0.993 lambda: 0.00000 #CG: 2 actred: -0.00015 prered: -0.00016 time: 2.729\n",
            "\n",
            " 72-iter val_acc: 74.683% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09572 s\n",
            "\n",
            "73-iter f: 0.348 |g|: 0.63556 alpha: 3.125e-02 ratio: 0.399 lambda: 0.00000 #CG: 250 actred: -0.00055 prered: -0.00138 time: 29.436\n",
            "\n",
            " 73-iter val_acc: 74.576% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09610 s\n",
            "\n",
            "74-iter f: 0.348 |g|: 0.05825 alpha: 1.000e+00 ratio: 0.995 lambda: 0.00000 #CG: 2 actred: -0.00010 prered: -0.00010 time: 2.724\n",
            "\n",
            " 74-iter val_acc: 74.505% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09572 s\n",
            "\n",
            "75-iter f: 0.348 |g|: 0.87173 alpha: 3.125e-02 ratio: 0.383 lambda: 0.00000 #CG: 250 actred: -0.00052 prered: -0.00137 time: 29.440\n",
            "\n",
            " 75-iter val_acc: 74.636% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09617 s\n",
            "\n",
            "76-iter f: 0.348 |g|: 0.07788 alpha: 1.000e+00 ratio: 0.996 lambda: 0.00000 #CG: 1 actred: -0.00016 prered: -0.00016 time: 2.626\n",
            "\n",
            " 76-iter val_acc: 74.541% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09577 s\n",
            "\n",
            "77-iter f: 0.347 |g|: 1.05642 alpha: 3.125e-02 ratio: 0.271 lambda: 0.00000 #CG: 250 actred: -0.00037 prered: -0.00138 time: 29.444\n",
            "\n",
            " 77-iter val_acc: 74.505% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09601 s\n",
            "\n",
            "78-iter f: 0.347 |g|: 0.09539 alpha: 1.000e+00 ratio: 0.998 lambda: 0.00000 #CG: 1 actred: -0.00024 prered: -0.00024 time: 2.626\n",
            "\n",
            " 78-iter val_acc: 74.529% val_loss 0.378\n",
            "\n",
            "Avg time per Gv iteration: 0.09563 s\n",
            "\n",
            "79-iter f: 0.347 |g|: 0.79280 alpha: 3.125e-02 ratio: 0.310 lambda: 0.00000 #CG: 250 actred: -0.00044 prered: -0.00140 time: 29.404\n",
            "\n",
            " 79-iter val_acc: 74.553% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09613 s\n",
            "\n",
            "80-iter f: 0.346 |g|: 0.06466 alpha: 1.000e+00 ratio: 0.940 lambda: 0.00000 #CG: 4 actred: -0.00024 prered: -0.00026 time: 2.914\n",
            "\n",
            " 80-iter val_acc: 74.434% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09569 s\n",
            "\n",
            "81-iter f: 0.346 |g|: 1.00799 alpha: 3.125e-02 ratio: 0.301 lambda: 0.00000 #CG: 250 actred: -0.00040 prered: -0.00134 time: 29.424\n",
            "\n",
            " 81-iter val_acc: 74.588% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09594 s\n",
            "\n",
            "82-iter f: 0.346 |g|: 0.05567 alpha: 1.000e+00 ratio: 0.995 lambda: 0.00000 #CG: 1 actred: -0.00021 prered: -0.00021 time: 2.626\n",
            "\n",
            " 82-iter val_acc: 74.458% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09561 s\n",
            "\n",
            "83-iter f: 0.345 |g|: 0.57806 alpha: 1.562e-02 ratio: 0.633 lambda: 0.00000 #CG: 250 actred: -0.00043 prered: -0.00068 time: 29.984\n",
            "\n",
            " 83-iter val_acc: 74.399% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09598 s\n",
            "\n",
            "84-iter f: 0.345 |g|: 0.04733 alpha: 1.000e+00 ratio: 0.998 lambda: 0.00000 #CG: 1 actred: -0.00007 prered: -0.00007 time: 2.624\n",
            "\n",
            " 84-iter val_acc: 74.363% val_loss 0.379\n",
            "\n",
            "Avg time per Gv iteration: 0.09565 s\n",
            "\n",
            "85-iter f: 0.345 |g|: 0.96885 alpha: 6.250e-02 ratio: 0.435 lambda: 0.00000 #CG: 250 actred: -0.00075 prered: -0.00172 time: 28.837\n",
            "\n",
            " 85-iter val_acc: 74.351% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09582 s\n",
            "\n",
            "86-iter f: 0.344 |g|: 0.07221 alpha: 1.000e+00 ratio: 0.995 lambda: 0.00000 #CG: 2 actred: -0.00027 prered: -0.00027 time: 2.720\n",
            "\n",
            " 86-iter val_acc: 74.304% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09572 s\n",
            "\n",
            "87-iter f: 0.344 |g|: 0.56978 alpha: 1.562e-02 ratio: 0.588 lambda: 0.00000 #CG: 250 actred: -0.00043 prered: -0.00073 time: 30.051\n",
            "\n",
            " 87-iter val_acc: 74.375% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09585 s\n",
            "\n",
            "88-iter f: 0.344 |g|: 0.05299 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00000 #CG: 1 actred: -0.00006 prered: -0.00006 time: 2.625\n",
            "\n",
            " 88-iter val_acc: 74.304% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09555 s\n",
            "\n",
            "89-iter f: 0.343 |g|: 0.55741 alpha: 6.250e-02 ratio: 0.322 lambda: 0.00000 #CG: 250 actred: -0.00059 prered: -0.00183 time: 28.809\n",
            "\n",
            " 89-iter val_acc: 74.422% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09566 s\n",
            "\n",
            "90-iter f: 0.343 |g|: 0.05669 alpha: 1.000e+00 ratio: 0.894 lambda: 0.00000 #CG: 4 actred: -0.00015 prered: -0.00016 time: 2.913\n",
            "\n",
            " 90-iter val_acc: 74.387% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09563 s\n",
            "\n",
            "91-iter f: 0.343 |g|: 0.69606 alpha: 1.562e-02 ratio: 0.561 lambda: 0.00000 #CG: 250 actred: -0.00050 prered: -0.00090 time: 30.000\n",
            "\n",
            " 91-iter val_acc: 74.505% val_loss 0.380\n",
            "\n",
            "Avg time per Gv iteration: 0.09620 s\n",
            "\n",
            "92-iter f: 0.342 |g|: 0.05007 alpha: 1.000e+00 ratio: 0.998 lambda: 0.00000 #CG: 1 actred: -0.00009 prered: -0.00009 time: 2.625\n",
            "\n",
            " 92-iter val_acc: 74.340% val_loss 0.381\n",
            "\n",
            "Avg time per Gv iteration: 0.09556 s\n",
            "\n",
            "93-iter f: 0.342 |g|: 0.40779 alpha: 3.125e-02 ratio: 0.586 lambda: 0.00000 #CG: 250 actred: -0.00058 prered: -0.00099 time: 29.401\n",
            "\n",
            " 93-iter val_acc: 74.399% val_loss 0.381\n",
            "\n",
            "Avg time per Gv iteration: 0.09597 s\n",
            "\n",
            "94-iter f: 0.342 |g|: 0.03515 alpha: 1.000e+00 ratio: 0.938 lambda: 0.00000 #CG: 4 actred: -0.00005 prered: -0.00005 time: 2.915\n",
            "\n",
            " 94-iter val_acc: 74.280% val_loss 0.381\n",
            "\n",
            "Avg time per Gv iteration: 0.09601 s\n",
            "\n",
            "95-iter f: 0.341 |g|: 0.35518 alpha: 1.562e-02 ratio: 0.585 lambda: 0.00000 #CG: 250 actred: -0.00035 prered: -0.00060 time: 30.085\n",
            "\n",
            " 95-iter val_acc: 74.340% val_loss 0.381\n",
            "\n",
            "Avg time per Gv iteration: 0.09588 s\n",
            "\n",
            "96-iter f: 0.341 |g|: 0.02758 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00000 #CG: 1 actred: -0.00002 prered: -0.00002 time: 2.627\n",
            "\n",
            " 96-iter val_acc: 74.209% val_loss 0.381\n",
            "\n",
            "Avg time per Gv iteration: 0.09573 s\n",
            "\n",
            "97-iter f: 0.341 |g|: 0.48948 alpha: 3.125e-02 ratio: 0.518 lambda: 0.00000 #CG: 250 actred: -0.00042 prered: -0.00082 time: 29.430\n",
            "\n",
            " 97-iter val_acc: 74.482% val_loss 0.381\n",
            "\n",
            "Avg time per Gv iteration: 0.09613 s\n",
            "\n",
            "98-iter f: 0.341 |g|: 0.02657 alpha: 1.000e+00 ratio: 0.996 lambda: 0.00000 #CG: 1 actred: -0.00004 prered: -0.00004 time: 2.625\n",
            "\n",
            " 98-iter val_acc: 74.363% val_loss 0.381\n",
            "\n",
            "Avg time per Gv iteration: 0.09554 s\n",
            "\n",
            "99-iter f: 0.341 |g|: 0.56260 alpha: 1.562e-02 ratio: 0.461 lambda: 0.00000 #CG: 250 actred: -0.00030 prered: -0.00064 time: 29.977\n",
            "\n",
            " 99-iter val_acc: 74.482% val_loss 0.381\n",
            "\n",
            "Final acc: 74.482% | best acc 75.228% | total_#CG 8674 | total running time 1189.615s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwH_nXJZDz2T"
      },
      "source": [
        "## Predict ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zyzmNHFnOwD"
      },
      "source": [
        "# Arguments for prediction PSSP dataset\n",
        "pred_args = (\"--bsize 1024 --valid_set ./\" + VALID_FILE + \" --train_set ./\" + TRAIN_FILE + \n",
        "\t\t\t\t\t\t \" --model ./saved_model/model.ckpt --dim \" +\n",
        "             str(WINDOW) + \" \" + str(AMINO_ACID_LEN) + \" 1\").split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6MctxH5_nTR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a3813f81-e78c-48f9-e598-0a8bcae68619"
      },
      "source": [
        "valid_origin = \"https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/{0}/{1}_folds/{1}_test_fold{2}.txt\".format(dataset, dataset.lower(), str(ds_num))\n",
        "train_origin = \"https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/{0}/{1}_folds/{1}_train_fold{2}.txt\".format(dataset, dataset.lower(), str(ds_num))\n",
        "test_origin = \"https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/CASP13/casp13_sorted.txt\"\n",
        "train_origin, valid_origin, test_origin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/CB513/cb513_folds/cb513_train_fold0.txt',\n",
              " 'https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/CB513/cb513_folds/cb513_test_fold0.txt',\n",
              " 'https://gitlab.com/perf.ai/pssp_project/-/raw/master/corrected_datasets/CASP13/casp13_sorted.txt')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0R1rY5rw030"
      },
      "source": [
        "import requests\n",
        "valid_f = requests.get(valid_origin)\n",
        "valid_f = valid_f.text.split('\\n')[0:-1]\n",
        "train_f = requests.get(train_origin)\n",
        "train_f = train_f.text.split('\\n')[0:-1]\n",
        "test_f = requests.get(test_origin)\n",
        "test_f = test_f.text.split('\\n')[0:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeQqT96h_NHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bac05103-0fd3-425f-9067-e9840173c911"
      },
      "source": [
        "VALID_PRED_FILE=\"pred_test_fold{0}.txt\".format(ds_num)\n",
        "TRAIN_PRED_FILE=\"pred_train_fold{0}.txt\".format(ds_num)\n",
        "TEST_PRED_FILE=\"pred_casp13_fold{0}.txt\".format(ds_num)\n",
        "VALID_PRED_FILE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pred_test_fold0.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNNnI_mU6LN5"
      },
      "source": [
        "##Declare Predict Methods##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYGPhdqk5wYp"
      },
      "source": [
        "def create_output_pred(pred, origin_f, outFileName):\n",
        "    pred = pred.astype(int)\n",
        "    labels = ['C', 'E', 'H']\n",
        "    counter = 0\n",
        "    with open(outFileName, 'w') as out_file:\n",
        "        for line in range(0, len(origin_f)//3):\n",
        "            protein_name = origin_f[line*3]\n",
        "            primary_structure = origin_f[line*3+1].replace('!', '')\n",
        "            secondary_structure = origin_f[line*3+2].replace('!', '')\n",
        "            prediction = \"\"\n",
        "            for c in secondary_structure:\n",
        "                if (c != '!'):\n",
        "                    prediction = prediction + labels[pred[counter]]\n",
        "                    counter += 1\n",
        "            out_file.write(protein_name + \"\\n\")\n",
        "            out_file.write(primary_structure + \"\\n\")\n",
        "            out_file.write(secondary_structure + \"\\n\")\n",
        "            out_file.write(prediction + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA8Pq5a0C3m5"
      },
      "source": [
        "# import tensorflow as tf \n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "# from utilities import predict, read_data, normalize_and_reshape\n",
        "# from net.net import CNN\n",
        "# import numpy as np \n",
        "# import argparse\n",
        "# import pdb\n",
        "\n",
        "def parse_args():\n",
        "\t\tparser = argparse.ArgumentParser(description='prediction')\n",
        "\t\tparser.add_argument('--test_set', dest='test_set',\n",
        "\t\t\t\t\t\t\thelp='provide the directory of .mat file for testing',\n",
        "\t\t\t\t\t\t\tdefault=None, type=str)\n",
        "\t\tparser.add_argument('--valid_set', dest='valid_set',\n",
        "\t\t\t\t\t\t\thelp='provide the directory of .mat file for validation',\n",
        "\t\t\t\t\t\t\tdefault=None, type=str)\n",
        "\t\tparser.add_argument('--train_set', dest='train_set',\n",
        "\t\t\t\t\t\t\thelp='provide the directory of .mat file for training',\n",
        "\t\t\t\t\t\t\tdefault=None, type=str)\n",
        "\t\tparser.add_argument('--model', dest='model_file',\n",
        "\t\t\t\t\t\t\thelp='provide file storing network parameters, i.e. ./dir/model.ckpt',\n",
        "\t\t\t\t\t\t\tdefault='./saved_model/model.ckpt', type=str)\n",
        "\t\tparser.add_argument('--bsize', dest='bsize',\n",
        "\t\t\t\t\t\t\thelp='batch size',\n",
        "\t\t\t\t\t\t\tdefault=1024, type=int)\n",
        "\t\tparser.add_argument('--loss', dest='loss', \n",
        "\t\t\t\t\t\t\thelp='which loss function to use: MSELoss or CrossEntropy',\n",
        "\t\t\t\t\t\t\tdefault='MSELoss', type=str)\n",
        "\t\tparser.add_argument('--dim', dest='dim', nargs='+', help='input dimension of data,'+\\\n",
        "\t\t\t\t\t\t\t'shape must be:  height width num_channels',\n",
        "\t\t\t\t\t\t\tdefault=[32, 32, 3], type=int)\n",
        "\n",
        "\t\targs = parser.parse_args(args=pred_args)\n",
        "\t\treturn args\n",
        "\n",
        "def predict_model():\n",
        "\t\targs = parse_args()\n",
        "\n",
        "\t\tsess_config = tf.compat.v1.ConfigProto()\n",
        "\t\tsess_config.gpu_options.allow_growth = True\n",
        "\n",
        "\t\twith tf.compat.v1.Session(config=sess_config) as sess:\n",
        "\t\t\t\tgraph_address = args.model_file + '.meta'\n",
        "\t\t\t\timported_graph = tf.compat.v1.train.import_meta_graph(graph_address)\n",
        "\t\t\t\timported_graph.restore(sess, args.model_file)\n",
        "\t\t\t\tmean_param = [v for v in tf.compat.v1.global_variables() if 'mean_tr:0' in v.name][0]\n",
        "\t\t\t\tlabel_enum_var = [v for v in tf.compat.v1.global_variables() if 'label_enum:0' in v.name][0]\n",
        "\n",
        "\t\t\t\tsess.run(tf.compat.v1.variables_initializer([mean_param, label_enum_var]))\n",
        "\t\t\t\tmean_tr = sess.run(mean_param)\n",
        "\t\t\t\tlabel_enum = sess.run(label_enum_var)\n",
        "\n",
        "\t\t\t\tx = tf.compat.v1.get_default_graph().get_tensor_by_name('main_params/input_of_net:0')\n",
        "\t\t\t\ty = tf.compat.v1.get_default_graph().get_tensor_by_name('main_params/labels:0')\n",
        "\t\t\t\toutputs = tf.compat.v1.get_default_graph().get_tensor_by_name('output_of_net:0')\n",
        "\n",
        "\t\t\t\tif args.loss == 'MSELoss':\n",
        "\t\t\t\t\t\tloss = tf.reduce_sum(input_tensor=tf.pow(outputs-y, 2))\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t\tloss = tf.reduce_sum(input_tensor=\n",
        "\t\t\t\t\t\t    tf.nn.softmax_cross_entropy_with_logits(logits=outputs, labels=tf.stop_gradient(y)))\n",
        "\t\t\t\t\n",
        "\t\t\t\tnetwork = (x, y, loss, outputs)\n",
        "\n",
        "\t\t\t\tif args.valid_set is not None:\n",
        "\t\t\t\t\t\tvalid_batch, num_cls, _ = read_data(args.valid_set, dim=args.dim, label_enum=label_enum)\n",
        "\t\t\t\t\t\tvalid_batch[0], _ = normalize_and_reshape(valid_batch[0], dim=args.dim, mean_tr=mean_tr)\n",
        "\t\t\t\n",
        "\t\t\t\t\t\tavg_loss_valid, avg_acc_valid, results_valid = predict(sess, network, valid_batch, args.bsize)\n",
        "\n",
        "\t\t\t\t\t\t# convert results back to the original labels\n",
        "\t\t\t\t\t\tinverse_map = dict(zip(np.arange(num_cls), label_enum))\n",
        "\t\t\t\t\t\tresults_valid = np.expand_dims(results_valid, axis=1)\n",
        "\t\t\t\t\t\tresults_valid = np.apply_along_axis(lambda x: inverse_map[x[0]], axis=1, arr=results_valid)\n",
        "\n",
        "\t\t\t\t\t\tcreate_output_pred(results_valid, valid_f, VALID_PRED_FILE)\n",
        "\t\t\t\t\t\tprint('In valid phase, average loss: {:.3f} | average accuracy: {:.3f}%'.\\\n",
        "\t\t\t\t\t\t\tformat(avg_loss_valid, avg_acc_valid*100))\n",
        "\t\t\t\t\n",
        "\t\t\t\tif args.train_set is not None:\n",
        "\t\t\t\t\t\ttrain_batch, num_cls, _ = read_data(args.train_set, dim=args.dim, label_enum=label_enum)\n",
        "\t\t\t\t\t\ttrain_batch[0], _ = normalize_and_reshape(train_batch[0], dim=args.dim, mean_tr=mean_tr)\n",
        "\n",
        "\t\t\t\t\t\tavg_loss_train, avg_acc_train, results_train = predict(sess, network, train_batch, args.bsize)\n",
        "\t\t\t\t\t\t# convert results back to the original labels\n",
        "\t\t\t\t\t\tinverse_map = dict(zip(np.arange(num_cls), label_enum))\n",
        "\t\t\t\t\t\tresults_train = np.expand_dims(results_train, axis=1)\n",
        "\t\t\t\t\t\tresults_train = np.apply_along_axis(lambda x: inverse_map[x[0]], axis=1, arr=results_train)\n",
        "\n",
        "\t\t\t\t\t\t# create_output_pred(results, results_train)\n",
        "\n",
        "\t\t\t\t\t\tcreate_output_pred(results_train, train_f, TRAIN_PRED_FILE)\n",
        "\t\t\t\t\t\tprint('In train phase, average loss: {:.3f} | average accuracy: {:.3f}%'.\\\n",
        "\t\t\t\t\t\t\tformat(avg_loss_train, avg_acc_train*100))\n",
        "\n",
        "\t\t\t\tif args.test_set is not None:\n",
        "\t\t\t\t\t\ttest_batch, num_cls, _ = read_data(args.test_set, dim=args.dim, label_enum=label_enum)\n",
        "\t\t\t\t\t\ttest_batch[0], _ = normalize_and_reshape(test_batch[0], dim=args.dim, mean_tr=mean_tr)\n",
        "\n",
        "\t\t\t\t\t\tavg_loss_test, avg_acc_test, results_test = predict(sess, network, test_batch, args.bsize)\n",
        "\t\t\t\t\t\t# convert results back to the original labels\n",
        "\t\t\t\t\t\tinverse_map = dict(zip(np.arange(num_cls), label_enum))\n",
        "\t\t\t\t\t\tresults_test = np.expand_dims(results_test, axis=1)\n",
        "\t\t\t\t\t\tresults_test = np.apply_along_axis(lambda x: inverse_map[x[0]], axis=1, arr=results_test)\n",
        "\n",
        "\t\t\t\t\t\t# create_output_pred(results, results_train)\n",
        "\n",
        "\t\t\t\t\t\tcreate_output_pred(results_test, test_f, TEST_PRED_FILE)\n",
        "\t\t\t\t\t\tprint('In test phase, average loss: {:.3f} | average accuracy: {:.3f}%'.\\\n",
        "\t\t\t\t\t\t\tformat(avg_loss_test, avg_acc_test*100))\n",
        "\t\t\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN8BTASh6eSL"
      },
      "source": [
        "##Run Predict and Display output##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCInY5uB6Y3G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6eb42445-78e4-4411-8104-b4ae4248432c"
      },
      "source": [
        "predict_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./saved_model/model.ckpt\n",
            "Normalize images according to the provided mean.\n",
            "In valid phase, average loss: 0.377 | average accuracy: 75.228%\n",
            "Normalize images according to the provided mean.\n",
            "In train phase, average loss: 0.327 | average accuracy: 79.295%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loR25EiOE4cQ"
      },
      "source": [
        "# !head \"$VALID_PRED_FILE\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOnpS-N3DwhK"
      },
      "source": [
        "# !head \"$TRAIN_PRED_FILE\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exgdCTXb68Vl"
      },
      "source": [
        "## Check Test score on CASP13 ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lda3hrM4dmWk"
      },
      "source": [
        "# Arguments for prediction PSSP dataset\n",
        "pred_args = (\"--bsize 1024 --test_set ./\" + TEST_FILE + \n",
        "\t\t\t\t\t\t \" --model ./saved_model/model.ckpt --dim \" +\n",
        "             str(WINDOW) + \" \" + str(AMINO_ACID_LEN) + \" 1\").split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JCC5-2mk0rs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ca90191a-4ebd-4075-f96c-f70714a5e9d5"
      },
      "source": [
        "predict_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./saved_model/model.ckpt\n",
            "Normalize images according to the provided mean.\n",
            "In test phase, average loss: 0.401 | average accuracy: 73.041%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMY6ihMjG1iO"
      },
      "source": [
        "# !head \"$TEST_PRED_FILE\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H93cFHmTH1su"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}