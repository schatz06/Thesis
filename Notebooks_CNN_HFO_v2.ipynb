{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebooks_CNN_HFO_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PYXlwVnXKhOJ",
        "CVtiFO19ymk_",
        "fzh5PNccJ28-",
        "gcdrh-r9JRdS",
        "2pQEA9LADkBP",
        "J5uoUeQBDq5Q",
        "vMCxn-8P5tsH",
        "UwH_nXJZDz2T",
        "NNNnI_mU6LN5"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schatz06/Thesis/blob/main/Notebooks_CNN_HFO_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa_PJwlt7zI2"
      },
      "source": [
        "##Mount drive## "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DjpeG7t71KC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135374f9-965b-4f7d-a300-9d8bc2010f73"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMo4HooFl0dv"
      },
      "source": [
        "##General Variables to use to load data##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJHXZcSlNqL9"
      },
      "source": [
        "fold = 2 # which fold to take \n",
        "embedding = \"protbert\"\n",
        "# embedding = \"seqvec\"\n",
        "# dataset=\"PISCES\" \n",
        "dataset=\"CB513\"\n",
        "USE_HFO=True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYXlwVnXKhOJ"
      },
      "source": [
        "## Imports ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCuZCtMgg5ns"
      },
      "source": [
        "# Reload all modules (except those excluded by %aimport) every time before executing the Python code typed.\n",
        "%load_ext autoreload \n",
        "%autoreload 2\n",
        "# matplotlib graphs will be included in your notebook, next to the code. \n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKDaAU3F5Bgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9ab92d-c1e5-4496-a0fc-738f461142fd"
      },
      "source": [
        "# install hdf5storage package \r\n",
        "!pip install hdf5storage"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hdf5storage in /usr/local/lib/python3.6/dist-packages (0.1.15)\n",
            "Requirement already satisfied: h5py>=2.1; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from hdf5storage) (2.10.0)\n",
            "Requirement already satisfied: numpy; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.1; python_version >= \"3.3\"->hdf5storage) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjrANRzOFauh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f517bef5-9499-4562-dff7-c91fa73d5a38"
      },
      "source": [
        "import pdb # python debugger\n",
        "import numpy as np # import numpy \n",
        "import tensorflow as tf # import tensorflow  \n",
        "tf.compat.v1.disable_eager_execution() # disable eager execution\n",
        "import time # import time\n",
        "import math # import math\n",
        "import argparse # import argparse\n",
        "import os # import os\n",
        "import scipy.io as sio # import scipy.io \n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() # makes different behaviors betweem tf_v1 & tf_v2 behave the same \n",
        "from tensorflow.python.client import device_lib # package to find available gpus\n",
        "import pandas as pd # import padas\n",
        "import hdf5storage # import hdf5storage"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVtiFO19ymk_"
      },
      "source": [
        "## Get data ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfOssHbYEh-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628f652f-405d-4402-d2fe-f5c8af882cef"
      },
      "source": [
        "VALID_FILE = \"/content/drive/MyDrive/Datasets/{0}_{1}_testSet{2}.mat\".format(dataset.lower(),embedding,str(fold)) # validation set\n",
        "TRAIN_FILE = \"/content/drive/MyDrive/Datasets/{0}_{1}_trainSet{2}.mat\".format(dataset.lower(),embedding,str(fold)) # train set  \n",
        "TEST_FILE = \"/content/drive/MyDrive/Datasets/casp13_{0}.mat\".format(embedding) # test set CASP13\n",
        "print(VALID_FILE)\n",
        "print(TRAIN_FILE)\n",
        "print(TEST_FILE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Datasets/cb513_protbert_testSet2.mat\n",
            "/content/drive/MyDrive/Datasets/cb513_protbert_trainSet2.mat\n",
            "/content/drive/MyDrive/Datasets/casp13_protbert.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKVIpZww1-dw"
      },
      "source": [
        "HEIGHT = 32\n",
        "WIDTH = 32\n",
        "DEPTH = 1\n",
        "CATEGORIES = 3 # number of different classification categories"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzh5PNccJ28-"
      },
      "source": [
        "## VGG ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwaNt8clJ5Vu"
      },
      "source": [
        "\"\"\"\n",
        "Codes are modifeid from PyTorch and Tensorflow Versions of VGG: \n",
        "https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py, and\n",
        "https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg16.py\n",
        "\"\"\"\n",
        "\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "# import numpy as np \n",
        "# import pdb\n",
        "from tensorflow.keras.applications.vgg16 import VGG16 as vgg16 # import vgg16 convolutional network\n",
        "from tensorflow.keras.applications.vgg19 import VGG19 as vgg19 # import vgg19 convolutional network\n",
        "\n",
        "__all__ = ['VGG11', 'VGG13', 'VGG16','VGG19'] # array holds all vgg CNN's names\n",
        " \n",
        "def VGG(feature, num_cls): # define VGG \n",
        "\n",
        "\twith tf.variable_scope('fully_connected') as scope:\n",
        "\t\tdim =np.prod(feature.shape[1:]) # returns the product of the given array\n",
        "\t\tx = tf.reshape(feature, [-1, dim]) # reshape tensor\n",
        "\n",
        "\t\tx = tf.keras.layers.Dense(units=4096, activation='relu', name=scope.name)(x) # define layers \n",
        "\t\tx = tf.keras.layers.Dense(units=4096, activation='relu', name=scope.name)(x)\n",
        "\t\tx = tf.keras.layers.Dense(units=num_cls, name=scope.name)(x)\n",
        "\n",
        "\treturn x\n",
        "# make the layers of CNN \n",
        "def make_layers(x, cfg):\n",
        "\tfor v in cfg:\n",
        "\t\tif v == 'M':\n",
        "\t\t\tx = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(x)\n",
        "\t\telse:\n",
        "\t\t\tx = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=v,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t\t)(x)\n",
        "\treturn x\n",
        "\n",
        "cfg = {\n",
        "\t'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "\t'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "\t'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "\t'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
        "\t\t  512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "def VGG11(x_images, num_cls):\n",
        "\tfeature = make_layers(x_images, cfg['A'])\n",
        "\treturn VGG(feature, num_cls)\n",
        "\n",
        "def VGG13(x_images, num_cls):\n",
        "\tfeature = make_layers(x_images, cfg['B'])\n",
        "\treturn VGG(feature, num_cls)\n",
        "\n",
        "def VGG16(x_images, num_cls):\n",
        "\tfeature = make_layers(x_images, cfg['D'])\n",
        "\treturn VGG(feature, num_cls)\n",
        "\n",
        "def VGG19(x_images, num_cls):\n",
        "\tfeature = make_layers(x_images, cfg['E'])\n",
        "\treturn VGG(feature, num_cls)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcdrh-r9JRdS"
      },
      "source": [
        "## Net ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHA5zxK1JRtg"
      },
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "# import math\n",
        "# import pdb\n",
        "# from tensorflow.python.client import device_lib\n",
        "# import numpy as np\n",
        "# from net.vgg import *\n",
        "\n",
        "def CNN_4layers(x_image, num_cls, reuse=False):\n",
        "\t_NUM_CLASSES = num_cls\n",
        "\twith tf.variable_scope('conv1', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(x_image)\n",
        "\n",
        "\twith tf.variable_scope('conv2', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\t\t\n",
        "\twith tf.variable_scope('conv3', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\n",
        "\twith tf.variable_scope('fully_connected', reuse=reuse) as scope:\n",
        "\t\tdim =np.prod(conv.shape[1:])\n",
        "\t\tflat = tf.reshape(conv, [-1, dim])\n",
        "\t\toutputs = tf.keras.layers.Dense(units=_NUM_CLASSES, name=scope.name)(flat)\n",
        "\n",
        "\treturn outputs\n",
        "\n",
        "\n",
        "\t# with tf.variable_scope('conv1', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=32,\n",
        "\t# \t\tkernel_size=[5, 5],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(x_image)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 16 x 16 x 32\n",
        "\n",
        "\t# with tf.variable_scope('conv2', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(pool)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 8 x 8 x 64\n",
        "\t\t\n",
        "\t# with tf.variable_scope('conv3', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(pool)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 4 x 4 x 64\n",
        "\n",
        "\t# with tf.variable_scope('fully_connected', reuse=reuse) as scope:\n",
        "\t# \tdim =np.prod(pool.shape[1:])\n",
        "\t# \tflat = tf.reshape(pool, [-1, dim])\n",
        "\t# \toutputs = tf.keras.layers.Dense(units=_NUM_CLASSES, name=scope.name)(flat)\n",
        "\n",
        "\t# return outputs\n",
        "\n",
        "def CNN_7layers(x_image, num_cls, reuse=False):\n",
        "\t_NUM_CLASSES = num_cls\n",
        "\twith tf.variable_scope('conv1', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(x_image)\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\n",
        "\twith tf.variable_scope('conv2', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\n",
        "\twith tf.variable_scope('conv3', reuse=reuse) as scope:\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\t\tconv = tf.keras.layers.Conv2D(\n",
        "\t\t\tfilters=64,\n",
        "\t\t\tkernel_size=[3, 3],\n",
        "\t\t\tpadding='SAME',\n",
        "\t\t\tactivation=tf.nn.relu\n",
        "\t\t)(conv)\n",
        "\n",
        "\twith tf.variable_scope('fully_connected', reuse=reuse) as scope:\n",
        "\t\tdim = np.prod(conv.shape[1:])\n",
        "\t\tflat = tf.reshape(conv, [-1, dim])\n",
        "\t\toutputs = tf.keras.layers.Dense(units=_NUM_CLASSES, name=scope.name)(flat)\n",
        "\n",
        "\treturn outputs\n",
        "\n",
        "\t# with tf.variable_scope('conv1', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=32,\n",
        "\t# \t\tkernel_size=[5, 5],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(x_image)\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=32,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(conv)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 16 x 16 x 32\n",
        "\n",
        "\t# with tf.variable_scope('conv2', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(pool)\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(conv)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# N x 8 x 8 x 64\n",
        "\n",
        "\t# with tf.variable_scope('conv3', reuse=reuse) as scope:\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=64,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(pool)\n",
        "\t# \tconv = tf.keras.layers.Conv2D(\n",
        "\t# \t\tfilters=128,\n",
        "\t# \t\tkernel_size=[3, 3],\n",
        "\t# \t\tpadding='SAME',\n",
        "\t# \t\tactivation=tf.nn.relu\n",
        "\t# \t)(conv)\n",
        "\t# \tpool = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='valid')(conv)\n",
        "\t# \t# pool = tf.layers.dropout(pool, rate=0.25, name=scope.name)\n",
        "\t# \t# N x 4 x 4 x 128\n",
        "\n",
        "\t# with tf.variable_scope('fully_connected', reuse=reuse) as scope:\n",
        "\t# \tdim = np.prod(pool.shape[1:])\n",
        "\t# \tflat = tf.reshape(pool, [-1, dim])\n",
        "\t# \toutputs = tf.keras.layers.Dense(units=_NUM_CLASSES, name=scope.name)(flat)\n",
        "\n",
        "\t# return outputs\n",
        "\n",
        "def CNN(net, num_cls, dim):\n",
        "\n",
        "\t_NUM_CLASSES = num_cls\n",
        "\t_IMAGE_HEIGHT, _IMAGE_WIDTH, _IMAGE_CHANNELS = dim\n",
        "\n",
        "\twith tf.name_scope('main_params'):\n",
        "\t\tx = tf.placeholder(tf.float32, shape=[None, _IMAGE_HEIGHT, _IMAGE_WIDTH, _IMAGE_CHANNELS], name='input_of_net')\n",
        "\t\ty = tf.placeholder(tf.float32, shape=[None, _NUM_CLASSES], name='labels')\n",
        "\n",
        "\t# call CNN structure according to string net\n",
        "\toutputs = globals()[net](x, _NUM_CLASSES)\n",
        "\toutputs = tf.identity(outputs, name='output_of_net')\n",
        "\n",
        "\treturn (x, y, outputs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pQEA9LADkBP"
      },
      "source": [
        "## Utilities ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxQzW-93DIdN"
      },
      "source": [
        "# import numpy as np\n",
        "# import math\n",
        "# import scipy.io as sio\n",
        "# import os\n",
        "# import math\n",
        "# import pdb\n",
        "\n",
        "class ConfigClass(object):\n",
        "\tdef __init__(self, args, num_data, num_cls):\n",
        "\t\tsuper(ConfigClass, self).__init__()\n",
        "\t\tself.args = args\n",
        "\t\tself.iter_max = args.iter_max\n",
        "\t\t\n",
        "\t\t# Different notations of regularization term:\n",
        "\t\t# In SGD, weight decay:\n",
        "\t\t# \tweight_decay <- lr/(C*num_of_training_samples)\n",
        "\t\t# In Newton method:\n",
        "\t\t# \tC <- C * num_of_training_samples\n",
        "\n",
        "\t\tself.seed = args.seed\n",
        "\n",
        "\t\tif self.seed is None:\n",
        "\t\t\tprint('You choose not to specify a random seed.'+\\\n",
        "\t\t\t\t'A different result is produced after each run.')\n",
        "\t\telif isinstance(self.seed, int) and self.seed >= 0:\n",
        "\t\t\tprint('You specify random seed {}.'.format(self.seed))\n",
        "\t\telse:\n",
        "\t\t\traise ValueError('Only accept None type or nonnegative integers for'+\\\n",
        "\t\t\t\t\t' random seed argument!')\n",
        "\n",
        "\t\tself.train_set = args.train_set\n",
        "\t\tself.val_set = args.val_set\n",
        "\t\tself.num_cls = num_cls\n",
        "\t\tself.dim = args.dim\n",
        "\n",
        "\t\tself.num_data = num_data\n",
        "\t\tself.GNsize = min(args.GNsize, self.num_data)\n",
        "\t\tself.C = args.C * self.num_data\n",
        "\t\tself.net = args.net\n",
        "\n",
        "\t\tself.xi = 0.1\n",
        "\t\tself.CGmax = args.CGmax\n",
        "\t\tself._lambda = args._lambda\n",
        "\t\tself.drop = args.drop\n",
        "\t\tself.boost = args.boost\n",
        "\t\tself.eta = args.eta\n",
        "\t\tself.lr = args.lr\n",
        "\t\tself.lr_decay = args.lr_decay\n",
        "\n",
        "\t\tself.bsize = args.bsize\n",
        "\t\tif args.momentum < 0:\n",
        "\t\t\traise ValueError('Momentum needs to be larger than 0!')\n",
        "\t\tself.momentum = args.momentum\n",
        "\n",
        "\t\tself.loss = args.loss\n",
        "\t\tif self.loss not in ('MSELoss', 'CrossEntropy'):\n",
        "\t\t\traise ValueError('Unrecognized loss type!')\n",
        "\t\tself.optim = args.optim\n",
        "\t\tif self.optim not in ('SGD', 'NewtonCG', 'Adam'):\n",
        "\t\t\traise ValueError('Only support SGD, Adam & NewtonCG optimizer!')\n",
        "\t\t\n",
        "\t\tself.log_file = args.log_file\n",
        "\t\tself.model_file = args.model_file\n",
        "\t\tself.screen_log_only = args.screen_log_only\n",
        "\n",
        "\t\tif self.screen_log_only:\n",
        "\t\t\tprint('You choose not to store running log. Only store model to {}'.format(self.log_file))\n",
        "\t\telse:\n",
        "\t\t\tprint('Saving log to: {}'.format(self.log_file))\n",
        "\t\t\tdir_name, _ = os.path.split(self.log_file)\n",
        "\t\t\tif not os.path.isdir(dir_name):\n",
        "\t\t\t\tos.makedirs(dir_name, exist_ok=True)\n",
        "\n",
        "\t\tdir_name, _ = os.path.split(self.model_file)\n",
        "\t\tif not os.path.isdir(dir_name):\n",
        "\t\t\tos.makedirs(dir_name, exist_ok=True)\n",
        "\t\t\n",
        "\t\tself.elapsed_time = 0.0\n",
        "\n",
        "def read_data(filename, dim, label_enum=None):\n",
        "\t\"\"\"\n",
        "\targs:\n",
        "\t\tfilename: the path where .mat files are stored\n",
        "\t\tlabel_enum (default None): the list that stores the original labels. \n",
        "\t\t\tIf label_enum is None, the function will generate a new list which stores the \n",
        "\t\t\toriginal labels in a sequence, and map original labels to [0, 1, ... number_of_classes-1]. \n",
        "\t\t\tIf label_enum is a list, the function will use it to convert \n",
        "\t\t\toriginal labels to [0, 1,..., number_of_classes-1].\n",
        "\t\"\"\"\n",
        "\n",
        "\tmat_contents = sio.loadmat(filename)\n",
        "\t#mat_contents = hdf5storage.loadmat(filename)\n",
        "\timages, labels = mat_contents['x'], mat_contents['y']\n",
        "\t\n",
        "\tlabels = labels.reshape(-1)\n",
        "\timages = images.reshape(images.shape[0], -1)\n",
        "\n",
        "\t_IMAGE_HEIGHT, _IMAGE_WIDTH, _IMAGE_CHANNELS = dim\n",
        "\tzero_to_append = np.zeros((images.shape[0],\n",
        "\t\t\t_IMAGE_CHANNELS*_IMAGE_HEIGHT*_IMAGE_WIDTH-np.prod(images.shape[1:])))\n",
        "\timages = np.append(images, zero_to_append, axis=1)\n",
        "\n",
        "\t# check data validity\n",
        "\tif label_enum is None:\n",
        "\t\tlabel_enum, labels = np.unique(labels, return_inverse=True)\n",
        "\t\tnum_cls = labels.max() + 1\n",
        "\n",
        "\t\tif len(label_enum) != num_cls:\n",
        "\t\t\traise ValueError('The number of classes is not equal to the number of\\\n",
        "\t\t\t\t\t\t\tlabels in dataset. Please verify them.')\n",
        "\telse:\n",
        "\t\tnum_cls = len(label_enum)\n",
        "\t\tforward_map = dict(zip(label_enum, np.arange(num_cls)))\n",
        "\t\tlabels = np.expand_dims(labels, axis=1)\n",
        "\t\tlabels = np.apply_along_axis(lambda x:forward_map[x[0]], axis=1, arr=labels)\n",
        "\t\t\n",
        "\n",
        "\t# convert groundtruth to one-hot encoding\n",
        "\tlabels = np.eye(num_cls)[labels]\n",
        "\tlabels = labels.astype('float32')\n",
        "\n",
        "\treturn [images, labels], num_cls, label_enum\n",
        "\n",
        "def normalize_and_reshape(images, dim, mean_tr=None):\n",
        "\t_IMAGE_HEIGHT, _IMAGE_WIDTH, _IMAGE_CHANNELS = dim\n",
        "\timages_shape = [images.shape[0], _IMAGE_CHANNELS, _IMAGE_HEIGHT, _IMAGE_WIDTH]\n",
        "\n",
        "\t# images normalization and zero centering\n",
        "\timages = images.reshape(images_shape[0], -1)\n",
        "\n",
        "\timages = images/255.0\n",
        "\n",
        "\tif mean_tr is None:\n",
        "\t\tprint('No mean of data provided! Normalize images by their own mean.')\n",
        "\t\t# if no mean_tr is provided, we calculate it according to the current data\n",
        "\t\tmean_tr = images.mean(axis=0) \n",
        "\telse:\n",
        "\t\tprint('Normalize images according to the provided mean.')\n",
        "\t\tif np.prod(mean_tr.shape) != np.prod(dim):\n",
        "\t\t\traise ValueError('Dimension of provided mean does not agree with the data! Please verify them!')\n",
        "\n",
        "\timages = images - mean_tr\n",
        "\n",
        "\timages = images.reshape(images_shape)\n",
        "\t# Tensorflow accepts data shape: B x H x W x C\n",
        "\timages = np.transpose(images, (0, 2, 3, 1))\n",
        "\treturn images, mean_tr\n",
        "\n",
        "\n",
        "def predict(sess, network, test_batch, bsize):\n",
        "\tx, y, loss, outputs = network\n",
        "\n",
        "\ttest_inputs, test_labels = test_batch\n",
        "\tbatch_size = bsize\n",
        "\n",
        "\tnum_data = test_labels.shape[0]\n",
        "\tnum_batches = math.ceil(num_data/batch_size)\n",
        "\n",
        "\tresults = np.zeros(shape=num_data, dtype=np.int)\n",
        "\tinfer_loss = 0.0\n",
        "\n",
        "\tfor i in range(num_batches):\n",
        "\t\tbatch_idx = np.arange(i*batch_size, min((i+1)*batch_size, num_data))\n",
        "\n",
        "\t\tbatch_input = test_inputs[batch_idx]\n",
        "\t\tbatch_labels = test_labels[batch_idx]\n",
        "\n",
        "\t\tnet_outputs, _loss = sess.run(\n",
        "\t\t\t[outputs, loss], feed_dict={x: batch_input, y: batch_labels}\n",
        "\t\t\t)\n",
        "\t\t\n",
        "\t\tresults[batch_idx] = np.argmax(net_outputs, axis=1)\n",
        "\t\t# note that _loss was summed over batches\n",
        "\t\tinfer_loss = infer_loss + _loss\n",
        "\n",
        "\tavg_acc = (np.argmax(test_labels, axis=1) == results).mean()\n",
        "\tavg_loss = infer_loss/num_data\n",
        "\t\n",
        "\treturn avg_loss, avg_acc, results"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5uoUeQBDq5Q"
      },
      "source": [
        "## Newton - CG ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDug0aiKCqeG"
      },
      "source": [
        "# import pdb\n",
        "# import tensorflow as tf\n",
        "# import time\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import math\n",
        "# from utilities import predict\n",
        "\n",
        "def Rop(f, weights, v):\n",
        "\t\"\"\"Implementation of R operator\n",
        "\tArgs:\n",
        "\t\tf: any function of weights\n",
        "\t\tweights: list of tensors.\n",
        "\t\tv: vector for right multiplication\n",
        "\tReturns:\n",
        "\t\tJv: Jaccobian vector product, length same as\n",
        "\t\t\tthe number of output of f\n",
        "\t\"\"\"\n",
        "\tif type(f) == list:\n",
        "\t\tu = [tf.zeros_like(ff) for ff in f]\n",
        "\telse:\n",
        "\t\tu = tf.zeros_like(f)  # dummy variable\n",
        "\tg = tf.gradients(ys=f, xs=weights, grad_ys=u)\n",
        "\treturn tf.gradients(ys=g, xs=u, grad_ys=v)\n",
        "\n",
        "def Gauss_Newton_vec(outputs, loss, weights, v):\n",
        "\t\"\"\"Implements Gauss-Newton vector product.\n",
        "\tArgs:\n",
        "\t\tloss: Loss function.\n",
        "\t\toutputs: outputs of the last layer (pre-softmax).\n",
        "\t\tweights: Weights, list of tensors.\n",
        "\t\tv: vector to be multiplied with Gauss Newton matrix\n",
        "\tReturns:\n",
        "\t\tJ'BJv: Guass-Newton vector product.\n",
        "\t\"\"\"\n",
        "\t# Validate the input\n",
        "\tif type(weights) == list:\n",
        "\t\tif len(v) != len(weights):\n",
        "\t\t\traise ValueError(\"weights and v must have the same length.\")\n",
        "\n",
        "\tgrads_outputs = tf.gradients(ys=loss, xs=outputs)\n",
        "\tBJv = Rop(grads_outputs, weights, v)\n",
        "\tJBJv = tf.gradients(ys=outputs, xs=weights, grad_ys=BJv)\n",
        "\treturn JBJv\n",
        "\t\n",
        "\n",
        "class newton_cg(object):\n",
        "\tdef __init__(self, config, sess, outputs, loss):\n",
        "\t\t\"\"\"\n",
        "\t\tinitialize operations and vairables that will be used in newton\n",
        "\t\targs:\n",
        "\t\t\tsess: tensorflow session\n",
        "\t\t\toutputs: output of the neural network (pre-softmax layer)\n",
        "\t\t\tloss: function to calculate loss\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(newton_cg, self).__init__()\n",
        "\t\tself.sess = sess\n",
        "\t\tself.config = config\n",
        "\t\tself.outputs = outputs\n",
        "\t\tself.loss = loss\n",
        "\t\tself.param = tf.compat.v1.trainable_variables()\n",
        "\n",
        "\t\tself.CGiter = 0\n",
        "\t\tFLOAT = tf.float32\n",
        "\t\tmodel_weight = self.vectorize(self.param)\n",
        "\t\t\n",
        "\t\t# initial variable used in CG\n",
        "\t\tzeros = tf.zeros(model_weight.get_shape(), dtype=FLOAT)\n",
        "\t\tself.r = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\tself.v = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\tself.s = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\tself.g = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\t# initial Gv, f for method minibatch\n",
        "\t\tself.Gv = tf.Variable(zeros, dtype=FLOAT, trainable=False)\n",
        "\t\tself.f = tf.Variable(0., dtype=FLOAT, trainable=False)\n",
        "\n",
        "\t\t# rTr, cgtol and beta to be used in CG\n",
        "\t\tself.rTr = tf.Variable(0., dtype=FLOAT, trainable=False)\n",
        "\t\tself.cgtol = tf.Variable(0., dtype=FLOAT, trainable=False)\n",
        "\t\tself.beta = tf.Variable(0., dtype=FLOAT, trainable=False)\n",
        "\n",
        "\t\t# placeholder alpha, old_alpha and lambda\n",
        "\t\tself.alpha = tf.compat.v1.placeholder(FLOAT, shape=[])\n",
        "\t\tself.old_alpha = tf.compat.v1.placeholder(FLOAT, shape=[])\n",
        "\t\tself._lambda = tf.compat.v1.placeholder(FLOAT, shape=[])\n",
        "\n",
        "\t\tself.num_grad_segment = math.ceil(self.config.num_data/self.config.bsize)\n",
        "\t\tself.num_Gv_segment = math.ceil(self.config.GNsize/self.config.bsize)\n",
        "\n",
        "\t\tcal_loss, cal_lossgrad, cal_lossGv, \\\n",
        "\t\tadd_reg_avg_loss, add_reg_avg_grad, add_reg_avg_Gv, \\\n",
        "\t\tzero_loss, zero_grad, zero_Gv = self._ops_in_minibatch()\n",
        "\n",
        "\t\t# initial operations that will be used in minibatch and newton\n",
        "\t\tself.cal_loss = cal_loss\n",
        "\t\tself.cal_lossgrad = cal_lossgrad\n",
        "\t\tself.cal_lossGv = cal_lossGv\n",
        "\t\tself.add_reg_avg_loss = add_reg_avg_loss\n",
        "\t\tself.add_reg_avg_grad = add_reg_avg_grad\n",
        "\t\tself.add_reg_avg_Gv = add_reg_avg_Gv\n",
        "\t\tself.zero_loss = zero_loss\n",
        "\t\tself.zero_grad = zero_grad\n",
        "\t\tself.zero_Gv = zero_Gv\n",
        "\n",
        "\t\tself.CG, self.update_v = self._CG()\n",
        "\t\tself.init_cg_vars = self._init_cg_vars()\n",
        "\t\tself.update_gs = tf.tensordot(self.s, self.g, axes=1)\n",
        "\t\tself.update_sGs = 0.5*tf.tensordot(self.s, -self.g-self.r-self._lambda*self.s, axes=1)\n",
        "\t\tself.update_model = self._update_model()\n",
        "\t\tself.gnorm = self.calc_norm(self.g)\n",
        "\n",
        "\n",
        "\tdef vectorize(self, tensors):\n",
        "\t\tif isinstance(tensors, list) or isinstance(tensors, tuple):\n",
        "\t\t\tvector = [tf.reshape(tensor, [-1]) for tensor in tensors]\n",
        "\t\t\treturn tf.concat(vector, 0) \n",
        "\t\telse:\n",
        "\t\t\treturn tensors \n",
        "\t\n",
        "\tdef inverse_vectorize(self, vector, param):\n",
        "\t\tif isinstance(vector, list):\n",
        "\t\t\treturn vector\n",
        "\t\telse:\n",
        "\t\t\ttensors = []\n",
        "\t\t\toffset = 0\n",
        "\t\t\tnum_total_param = np.sum([np.prod(p.shape.as_list()) for p in param])\n",
        "\t\t\tfor p in param:\n",
        "\t\t\t\tnumel = np.prod(p.shape.as_list())\n",
        "\t\t\t\ttensors.append(tf.reshape(vector[offset: offset+numel], p.shape))\n",
        "\t\t\t\toffset += numel\n",
        "\n",
        "\t\t\tassert offset == num_total_param\n",
        "\t\t\treturn tensors\n",
        "\n",
        "\tdef calc_norm(self, v):\n",
        "\t\t# default: frobenius norm\n",
        "\t\tif isinstance(v, list):\n",
        "\t\t\tnorm = 0.\n",
        "\t\t\tfor p in v:\n",
        "\t\t\t\tnorm = norm + tf.norm(tensor=p)**2\n",
        "\t\t\treturn norm**0.5\n",
        "\t\telse:\n",
        "\t\t\treturn tf.norm(tensor=v)\n",
        "\n",
        "\tdef _ops_in_minibatch(self):\n",
        "\t\t\"\"\"\n",
        "\t\tDefine operations that will be used in method minibatch\n",
        "\t\tVectorization is already a deep copy operation.\n",
        "\t\tBefore using newton method, loss needs to be summed over training samples\n",
        "\t\tto make results consistent.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tdef cal_loss():\n",
        "\t\t\treturn tf.compat.v1.assign(self.f, self.f + self.loss)\n",
        "\n",
        "\t\tdef cal_lossgrad():\n",
        "\t\t\tupdate_f = tf.compat.v1.assign(self.f, self.f + self.loss)\n",
        "\n",
        "\t\t\tgrad = tf.gradients(ys=self.loss, xs=self.param)\n",
        "\t\t\tgrad = self.vectorize(grad)\n",
        "\t\t\tupdate_grad = tf.compat.v1.assign(self.g, self.g + grad)\n",
        "\n",
        "\t\t\treturn tf.group(*[update_f, update_grad])\n",
        "\n",
        "\t\tdef cal_lossGv():\n",
        "\t\t\tv = self.inverse_vectorize(self.v, self.param)\n",
        "\t\t\tGv = Gauss_Newton_vec(self.outputs, self.loss, self.param, v)\n",
        "\t\t\tGv = self.vectorize(Gv)\n",
        "\t\t\treturn tf.compat.v1.assign(self.Gv, self.Gv + Gv) \n",
        "\n",
        "\t\t# add regularization term to loss, gradient and Gv and further average over batches \n",
        "\t\tdef add_reg_avg_loss():\n",
        "\t\t\tmodel_weight = self.vectorize(self.param)\n",
        "\t\t\treg = (self.calc_norm(model_weight))**2\n",
        "\t\t\treg = 1.0/(2*self.config.C) * reg\n",
        "\t\t\treturn tf.compat.v1.assign(self.f, reg + self.f/self.config.num_data)\n",
        "\n",
        "\t\tdef add_reg_avg_lossgrad():\n",
        "\t\t\tmodel_weight = self.vectorize(self.param)\n",
        "\t\t\treg_grad = model_weight/self.config.C\n",
        "\t\t\treturn tf.compat.v1.assign(self.g, reg_grad + self.g/self.config.num_data)\n",
        "\n",
        "\t\tdef add_reg_avg_lossGv():\n",
        "\t\t\treturn tf.compat.v1.assign(self.Gv, (self._lambda + 1/self.config.C)*self.v\n",
        "\t\t\t + self.Gv/self.config.GNsize) \n",
        "\n",
        "\t\t# zero out loss, grad and Gv \n",
        "\t\tdef zero_loss():\n",
        "\t\t\treturn tf.compat.v1.assign(self.f, tf.zeros_like(self.f))\n",
        "\t\tdef zero_grad():\n",
        "\t\t\treturn tf.compat.v1.assign(self.g, tf.zeros_like(self.g))\n",
        "\t\tdef zero_Gv():\n",
        "\t\t\treturn tf.compat.v1.assign(self.Gv, tf.zeros_like(self.Gv))\n",
        "\n",
        "\t\treturn (cal_loss(), cal_lossgrad(), cal_lossGv(),\n",
        "\t\t\t\tadd_reg_avg_loss(), add_reg_avg_lossgrad(), add_reg_avg_lossGv(),\n",
        "\t\t\t\tzero_loss(), zero_grad(), zero_Gv())\n",
        "\n",
        "\tdef minibatch(self, data_batch, place_holder_x, place_holder_y, mode):\n",
        "\t\t\"\"\"\n",
        "\t\tA function to evaluate either function value, global gradient or sub-sampled Gv\n",
        "\t\t\"\"\"\n",
        "\t\tif mode not in ('funonly', 'fungrad', 'Gv'):\n",
        "\t\t\traise ValueError('Unknown mode other than funonly & fungrad & Gv!')\n",
        "\n",
        "\t\tinputs, labels = data_batch\n",
        "\t\tnum_data = labels.shape[0]\n",
        "\t\tnum_segment = math.ceil(num_data/self.config.bsize)\n",
        "\t\tx, y = place_holder_x, place_holder_y\n",
        "\n",
        "\t\t# before estimation starts, need to zero out f, grad and Gv according to the mode\n",
        "\n",
        "\t\tif mode == 'funonly':\n",
        "\t\t\tassert num_data == self.config.num_data\n",
        "\t\t\tassert num_segment == self.num_grad_segment\n",
        "\t\t\tself.sess.run(self.zero_loss)\n",
        "\t\telif mode == 'fungrad':\n",
        "\t\t\tassert num_data == self.config.num_data\n",
        "\t\t\tassert num_segment == self.num_grad_segment\n",
        "\t\t\tself.sess.run([self.zero_loss, self.zero_grad])\n",
        "\t\telse:\n",
        "\t\t\tassert num_data == self.config.GNsize\n",
        "\t\t\tassert num_segment == self.num_Gv_segment\n",
        "\t\t\tself.sess.run(self.zero_Gv)\n",
        "\n",
        "\t\tfor i in range(num_segment):\n",
        "\t\t\t\n",
        "\t\t\tload_time = time.time()\n",
        "\t\t\tidx = np.arange(i * self.config.bsize, min((i+1) * self.config.bsize, num_data))\n",
        "\t\t\tbatch_input = inputs[idx]\n",
        "\t\t\tbatch_labels = labels[idx]\n",
        "\t\t\tbatch_input = np.ascontiguousarray(batch_input)\n",
        "\t\t\tbatch_labels = np.ascontiguousarray(batch_labels)\n",
        "\t\t\tself.config.elapsed_time += time.time() - load_time\n",
        "\n",
        "\t\t\tif mode == 'funonly':\n",
        "\n",
        "\t\t\t\tself.sess.run(self.cal_loss, feed_dict={\n",
        "\t\t\t\t\t\t\tx: batch_input, \n",
        "\t\t\t\t\t\t\ty: batch_labels,})\n",
        "\n",
        "\t\t\telif mode == 'fungrad':\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.sess.run(self.cal_lossgrad, feed_dict={\n",
        "\t\t\t\t\t\t\tx: batch_input, \n",
        "\t\t\t\t\t\t\ty: batch_labels,})\n",
        "\t\t\t\t\n",
        "\t\t\telse:\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.sess.run(self.cal_lossGv, feed_dict={\n",
        "\t\t\t\t\t\t\tx: batch_input, \n",
        "\t\t\t\t\t\t\ty: batch_labels})\n",
        "\n",
        "\t\t# average over batches\n",
        "\t\tif mode == 'funonly':\n",
        "\t\t\tself.sess.run(self.add_reg_avg_loss)\n",
        "\t\telif mode == 'fungrad':\n",
        "\t\t\tself.sess.run([self.add_reg_avg_loss, self.add_reg_avg_grad])\n",
        "\t\telse:\n",
        "\t\t\tself.sess.run(self.add_reg_avg_Gv, \n",
        "\t\t\t\tfeed_dict={self._lambda: self.config._lambda})\n",
        "\n",
        "\n",
        "\tdef _update_model(self):\n",
        "\t\tupdate_model_ops = []\n",
        "\t\tx = self.inverse_vectorize(self.s, self.param)\n",
        "\t\tfor i, p in enumerate(self.param):\n",
        "\t\t\top = tf.compat.v1.assign(p, p + (self.alpha-self.old_alpha) * x[i])\n",
        "\t\t\tupdate_model_ops.append(op)\n",
        "\t\treturn tf.group(*update_model_ops)\n",
        "\n",
        "\tdef _init_cg_vars(self):\n",
        "\t\tinit_ops = []\n",
        "\n",
        "\t\tinit_r = tf.compat.v1.assign(self.r, -self.g)\n",
        "\t\tinit_v = tf.compat.v1.assign(self.v, -self.g)\n",
        "\t\tinit_s = tf.compat.v1.assign(self.s, tf.zeros_like(self.g))\n",
        "\t\tgnorm = self.calc_norm(self.g)\n",
        "\t\tinit_rTr = tf.compat.v1.assign(self.rTr, gnorm**2)\n",
        "\t\tinit_cgtol = tf.compat.v1.assign(self.cgtol, self.config.xi*gnorm)\n",
        "\n",
        "\t\tinit_ops = [init_r, init_v, init_s, init_rTr, init_cgtol]\n",
        "\n",
        "\t\treturn tf.group(*init_ops)\n",
        "\n",
        "\tdef _CG(self):\n",
        "\t\t\"\"\"\n",
        "\t\tCG:\n",
        "\t\t\tdefine operations that will be used in method newton\n",
        "\t\tSame as the previous loss calculation,\n",
        "\t\tGv has been summed over batches when samples were fed into Neural Network.\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tdef CG_ops():\n",
        "\t\t\t\n",
        "\t\t\tvGv = tf.tensordot(self.v, self.Gv, axes=1)\n",
        "\n",
        "\t\t\talpha = self.rTr / vGv\n",
        "\t\t\twith tf.control_dependencies([alpha]):\n",
        "\t\t\t\tupdate_s = tf.compat.v1.assign(self.s, self.s + alpha * self.v, name='update_s_ops')\n",
        "\t\t\t\tupdate_r = tf.compat.v1.assign(self.r, self.r - alpha * self.Gv, name='update_r_ops')\n",
        "\n",
        "\t\t\t\twith tf.control_dependencies([update_s, update_r]):\n",
        "\t\t\t\t\trnewTrnew = self.calc_norm(update_r)**2\n",
        "\t\t\t\t\tupdate_beta = tf.compat.v1.assign(self.beta, rnewTrnew / self.rTr)\n",
        "\t\t\t\t\twith tf.control_dependencies([update_beta]):\n",
        "\t\t\t\t\t\tupdate_rTr = tf.compat.v1.assign(self.rTr, rnewTrnew, name='update_rTr_ops')\n",
        "\n",
        "\t\t\treturn tf.group(*[update_s, update_beta, update_rTr])\n",
        "\n",
        "\t\tdef update_v():\n",
        "\t\t\treturn tf.compat.v1.assign(self.v, self.r + self.beta*self.v, name='update_v')\n",
        "\n",
        "\t\treturn (CG_ops(), update_v())\n",
        "\n",
        "\n",
        "\tdef newton(self, full_batch, val_batch, saver, network, test_network=None):\n",
        "\t\t\"\"\"\n",
        "\t\tConduct newton steps for training\n",
        "\t\targs:\n",
        "\t\t\tfull_batch & val_batch: provide training set and validation set. The function will\n",
        "\t\t\t\tsave the best model evaluted on validation set for future prediction.\n",
        "\t\t\tnetwork: a tuple contains (x, y, loss, outputs).\n",
        "\t\t\ttest_network: a tuple similar to argument network. If you use layers which behave differently\n",
        "\t\t\t\tin test phase such as batchnorm, a separate test_network is needed.\n",
        "\t\treturn:\n",
        "\t\t\tNone\n",
        "\t\t\"\"\"\n",
        "\t\t# check whether data is valid\n",
        "\t\tfull_inputs, full_labels = full_batch\n",
        "\t\tassert full_inputs.shape[0] == full_labels.shape[0]\n",
        "\n",
        "\t\tif full_inputs.shape[0] != self.config.num_data:\n",
        "\t\t\traise ValueError('The number of full batch inputs does not agree with the config argument.\\\n",
        "\t\t\t\t\t\t\tThis is important because global loss is averaged over those inputs')\n",
        "\n",
        "\t\tx, y, _, outputs = network\n",
        "\n",
        "\t\ttf.compat.v1.summary.scalar('loss', self.f)\n",
        "\t\tmerged = tf.compat.v1.summary.merge_all()\n",
        "\t\ttrain_writer = tf.compat.v1.summary.FileWriter('./summary/train', self.sess.graph)\n",
        "\n",
        "\t\tprint(self.config.args)\n",
        "\t\tif not self.config.screen_log_only:\n",
        "\t\t\tlog_file = open(self.config.log_file, 'w')\n",
        "\t\t\tprint(self.config.args, file=log_file)\n",
        "\t\t\n",
        "\t\tself.minibatch(full_batch, x, y, mode='fungrad')\n",
        "\t\tf = self.sess.run(self.f)\n",
        "\t\toutput_str = 'initial f: {:.3f}'.format(f)\n",
        "\t\tprint(output_str)\n",
        "\t\tif not self.config.screen_log_only:\n",
        "\t\t\tprint(output_str, file=log_file)\n",
        "\t\t\n",
        "\t\tbest_acc = 0.0\n",
        "\n",
        "\t\ttotal_running_time = 0.0\n",
        "\t\tself.config.elapsed_time = 0.0\n",
        "\t\ttotal_CG = 0\n",
        "\t\t\n",
        "\t\tfor k in range(self.config.iter_max):\n",
        "\n",
        "\t\t\t# randomly select the batch for Gv estimation\n",
        "\t\t\tidx = np.random.choice(np.arange(0, full_labels.shape[0]),\n",
        "\t\t\t\t\tsize=self.config.GNsize, replace=False)\n",
        "\n",
        "\t\t\tmini_inputs = full_inputs[idx]\n",
        "\t\t\tmini_labels = full_labels[idx]\n",
        "\n",
        "\t\t\tstart = time.time()\n",
        "\n",
        "\t\t\tself.sess.run(self.init_cg_vars)\n",
        "\t\t\tcgtol = self.sess.run(self.cgtol)\n",
        "\n",
        "\t\t\tavg_cg_time = 0.0\n",
        "\t\t\tfor CGiter in range(1, self.config.CGmax+1):\n",
        "\t\t\t\t\n",
        "\t\t\t\tcg_time = time.time()\n",
        "\t\t\t\tself.minibatch((mini_inputs, mini_labels), x, y, mode='Gv')\n",
        "\t\t\t\tavg_cg_time += time.time() - cg_time\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.sess.run(self.CG)\n",
        "\n",
        "\t\t\t\trnewTrnew = self.sess.run(self.rTr)\n",
        "\t\t\t\t\n",
        "\t\t\t\tif rnewTrnew**0.5 <= cgtol or CGiter == self.config.CGmax:\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t\tself.sess.run(self.update_v)\n",
        "\n",
        "\t\t\tprint('Avg time per Gv iteration: {:.5f} s\\r\\n'.format(avg_cg_time/CGiter))\n",
        "\n",
        "\t\t\tgs, sGs = self.sess.run([self.update_gs, self.update_sGs], feed_dict={\n",
        "\t\t\t\t\tself._lambda: self.config._lambda\n",
        "\t\t\t\t})\n",
        "\t\t\t\n",
        "\t\t\t# line_search\n",
        "\t\t\tf_old = f\n",
        "\t\t\talpha = 1\n",
        "\t\t\twhile True:\n",
        "\n",
        "\t\t\t\told_alpha = 0 if alpha == 1 else alpha/0.5\n",
        "\t\t\t\t\n",
        "\t\t\t\tself.sess.run(self.update_model, feed_dict={\n",
        "\t\t\t\t\tself.alpha:alpha, self.old_alpha:old_alpha\n",
        "\t\t\t\t\t})\n",
        "\n",
        "\t\t\t\tprered = alpha*gs + (alpha**2)*sGs\n",
        "\n",
        "\t\t\t\tself.minibatch(full_batch, x, y, mode='funonly')\n",
        "\t\t\t\tf = self.sess.run(self.f)\n",
        "\n",
        "\t\t\t\tactred = f - f_old\n",
        "\n",
        "\t\t\t\tif actred <= self.config.eta*alpha*gs:\n",
        "\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t\talpha *= 0.5\n",
        "\n",
        "\t\t\t# update lambda\n",
        "\t\t\tratio = actred / prered\n",
        "\t\t\tif ratio < 0.25:\n",
        "\t\t\t\tself.config._lambda *= self.config.boost\n",
        "\t\t\telif ratio >= 0.75:\n",
        "\t\t\t\tself.config._lambda *= self.config.drop\n",
        "\n",
        "\t\t\tself.minibatch(full_batch, x, y, mode='fungrad')\n",
        "\t\t\tf = self.sess.run(self.f)\n",
        "\n",
        "\t\t\tgnorm = self.sess.run(self.gnorm)\n",
        "\n",
        "\t\t\tsummary = self.sess.run(merged)\n",
        "\t\t\ttrain_writer.add_summary(summary, k)\n",
        "\n",
        "\t\t\t# exclude data loading time for fair comparison\n",
        "\t\t\tend = time.time() \n",
        "\t\t\t\n",
        "\t\t\tend = end - self.config.elapsed_time\n",
        "\t\t\ttotal_running_time += end-start\n",
        "\n",
        "\t\t\tself.config.elapsed_time = 0.0\n",
        "\t\t\t\n",
        "\t\t\ttotal_CG += CGiter\n",
        "\n",
        "\t\t\toutput_str = '{}-iter f: {:.3f} |g|: {:.5f} alpha: {:.3e} ratio: {:.3f} lambda: {:.5f} #CG: {} actred: {:.5f} prered: {:.5f} time: {:.3f}'.\\\n",
        "\t\t\t\t\t\t\tformat(k, f, gnorm, alpha, actred/prered, self.config._lambda, CGiter, actred, prered, end-start)\n",
        "\t\t\tprint(output_str)\n",
        "\t\t\tif not self.config.screen_log_only:\n",
        "\t\t\t\tprint(output_str, file=log_file)\n",
        "\n",
        "\t\t\tif val_batch is not None:\n",
        "\t\t\t\t# Evaluate the performance after every Newton Step\n",
        "\t\t\t\tif test_network == None:\n",
        "\t\t\t\t\tval_loss, val_acc, _ = predict(\n",
        "\t\t\t\t\t\tself.sess, \n",
        "\t\t\t\t\t\tnetwork=(x, y, self.loss, outputs),\n",
        "\t\t\t\t\t\ttest_batch=val_batch,\n",
        "\t\t\t\t\t\tbsize=self.config.bsize,\n",
        "\t\t\t\t\t\t)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\t# A separat test network part has not been done...\n",
        "\t\t\t\t\tval_loss, val_acc, _ = predict(\n",
        "\t\t\t\t\t\tself.sess, \n",
        "\t\t\t\t\t\tnetwork=test_network,\n",
        "\t\t\t\t\t\ttest_batch=val_batch,\n",
        "\t\t\t\t\t\tbsize=self.config.bsize\n",
        "\t\t\t\t\t\t)\n",
        "\n",
        "\t\t\t\toutput_str = '\\r\\n {}-iter val_acc: {:.3f}% val_loss {:.3f}\\r\\n'.\\\n",
        "\t\t\t\t\tformat(k, val_acc*100, val_loss)\n",
        "\t\t\t\tprint(output_str)\n",
        "\t\t\t\tif not self.config.screen_log_only:\n",
        "\t\t\t\t\tprint(output_str, file=log_file)\n",
        "\n",
        "\t\t\t\tif val_acc > best_acc:\n",
        "\t\t\t\t\tbest_acc = val_acc\n",
        "\t\t\t\t\tcheckpoint_path = self.config.model_file\n",
        "\t\t\t\t\tsave_path = saver.save(self.sess, checkpoint_path)\n",
        "\t\t\t\t\tprint('Best model saved in {}\\r\\n'.format(save_path))\n",
        "\n",
        "\t\tif val_batch is None:\n",
        "\t\t\tcheckpoint_path = self.config.model_file\n",
        "\t\t\tsave_path = saver.save(self.sess, checkpoint_path)\n",
        "\t\t\tprint('Model at the last iteration saved in {}\\r\\n'.format(save_path))\n",
        "\t\t\toutput_str = 'total_#CG {} | total running time {:.3f}s'.format(total_CG, total_running_time)\n",
        "\t\telse:\n",
        "\t\t\toutput_str = 'Final acc: {:.3f}% | best acc {:.3f}% | total_#CG {} | total running time {:.3f}s'.\\\n",
        "\t\t\t\tformat(val_acc*100, best_acc*100, total_CG, total_running_time)\n",
        "\t\tprint(output_str)\n",
        "\t\tif not self.config.screen_log_only:\n",
        "\t\t\tprint(output_str, file=log_file)\n",
        "\t\t\tlog_file.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xatdN2Zm7BOQ"
      },
      "source": [
        "##Set Train Arguments##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_DZPFd4m7Og"
      },
      "source": [
        "if USE_HFO:\n",
        "    # Arguments for HFO - PSSP dataset\n",
        "    train_args = (\"--optim NewtonCG --GNsize 4096 --C 0.01 --net CNN_4layers --bsize 1024 --iter_max 100 \" +\n",
        "              \"--train_set \" + TRAIN_FILE + \" --val_set \" + VALID_FILE + \" --dim \" + \n",
        "              str(HEIGHT) + \" \" + str(WIDTH) + \" \" + str(DEPTH)).split()\n",
        "else:\n",
        "    # Arguments for SGD - PSSP dataset\n",
        "    train_args = (\"--optim SGD --lr 0.05 --momentum 0.01 --C 0.01 --net CNN_4layers --bsize 1024 --epoch_max 1000 \" +\n",
        "              \"--train_set \" + TRAIN_FILE + \" --val_set \" + VALID_FILE + \" --dim \" +\n",
        "              str(HEIGHT) + \" \" + str(WIDTH) + \" \" + str(DEPTH)).split()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMCxn-8P5tsH"
      },
      "source": [
        "##Declare Train Function##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr528VD1EDj9"
      },
      "source": [
        "# import pdb\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "# import time\n",
        "# import math\n",
        "# import argparse\n",
        "\n",
        "# from net.net import CNN\n",
        "# from newton_cg import newton_cg\n",
        "# from utilities import read_data, predict, ConfigClass, normalize_and_reshape\n",
        "\n",
        "def parse_args():\n",
        "\tparser = argparse.ArgumentParser(description='Newton method on DNN')\n",
        "\tparser.add_argument('--C', dest='C',\n",
        "\t\t\t\t\t  help='regularization term, or so-called weight decay where'+\\\n",
        "\t\t\t\t\t  \t\t'weight_decay = lr/(C*num_of_samples) in this implementation' ,\n",
        "\t\t\t\t\t  default=0.01, type=float)\n",
        "\n",
        "\t# Newton method arguments\n",
        "\tparser.add_argument('--GNsize', dest='GNsize',\n",
        "\t\t\t\t\t  help='number of samples for estimating Gauss-Newton matrix',\n",
        "\t\t\t\t\t  default=4096, type=int)\n",
        "\tparser.add_argument('--iter_max', dest='iter_max',\n",
        "\t\t\t\t\t  help='the maximal number of Newton iterations',\n",
        "\t\t\t\t\t  default=100, type=int)\n",
        "\tparser.add_argument('--xi', dest='xi',\n",
        "\t\t\t\t\t  help='the tolerance in the relative stopping condition for CG',\n",
        "\t\t\t\t\t  default=0.1, type=float)\n",
        "\tparser.add_argument('--drop', dest='drop',\n",
        "\t\t\t\t\t  help='the drop constants for the LM method',\n",
        "\t\t\t\t\t  default=2/3, type=float)\n",
        "\tparser.add_argument('--boost', dest='boost',\n",
        "\t\t\t\t\t  help='the boost constants for the LM method',\n",
        "\t\t\t\t\t  default=3/2, type=float)\n",
        "\tparser.add_argument('--eta', dest='eta',\n",
        "\t\t\t\t\t  help='the parameter for the line search stopping condition',\n",
        "\t\t\t\t\t  default=0.0001, type=float)\n",
        "\tparser.add_argument('--CGmax', dest='CGmax',\n",
        "\t\t\t\t\t  help='the maximal number of CG iterations',\n",
        "\t\t\t\t\t  default=250, type=int)\n",
        "\tparser.add_argument('--lambda', dest='_lambda',\n",
        "\t\t\t\t\t  help='the initial lambda for the LM method',\n",
        "\t\t\t\t\t  default=1, type=float)\n",
        "\n",
        "\t# SGD arguments\n",
        "\tparser.add_argument('--epoch_max', dest='epoch',\n",
        "\t\t\t\t\t  help='number of training epoch',\n",
        "\t\t\t\t\t  default=500, type=int)\n",
        "\tparser.add_argument('--lr', dest='lr',\n",
        "\t\t\t\t\t  help='learning rate',\n",
        "\t\t\t\t\t  default=0.01, type=float)\n",
        "\tparser.add_argument('--decay', dest='lr_decay',\n",
        "\t\t\t\t\t  help='learning rate decay over each mini-batch update',\n",
        "\t\t\t\t\t  default=0, type=float)\n",
        "\tparser.add_argument('--momentum', dest='momentum',\n",
        "\t\t\t\t\t  help='momentum of learning',\n",
        "\t\t\t\t\t  default=0, type=float)\n",
        "\n",
        "\t# Model training arguments\n",
        "\tparser.add_argument('--bsize', dest='bsize',\n",
        "\t\t\t\t\t  help='batch size to evaluate stochastic gradient, Gv, etc. Since the sampled data \\\n",
        "\t\t\t\t\t  for computing Gauss-Newton matrix and etc. might not fit into memeory \\\n",
        "\t\t\t\t\t  for one time, we will split the data into several segements and average\\\n",
        "\t\t\t\t\t  over them.',\n",
        "\t\t\t\t\t  default=1024, type=int)\n",
        "\tparser.add_argument('--net', dest='net',\n",
        "\t\t\t\t\t  help='classifier type',\n",
        "\t\t\t\t\t  default='CNN_4layers', type=str)\n",
        "\tparser.add_argument('--train_set', dest='train_set',\n",
        "\t\t\t\t\t  help='provide the directory of .mat file for training',\n",
        "\t\t\t\t\t  default=None, type=str)\n",
        "\tparser.add_argument('--val_set', dest='val_set',\n",
        "\t\t\t\t\t  help='provide the directory of .mat file for validation',\n",
        "\t\t\t\t\t  default=None, type=str)\n",
        "\tparser.add_argument('--model', dest='model_file',\n",
        "\t\t\t\t\t  help='model saving address',\n",
        "\t\t\t\t\t  default='./saved_model/model.ckpt', type=str)\n",
        "\tparser.add_argument('--log', dest='log_file',\n",
        "\t\t\t\t\t  help='log saving directory',\n",
        "\t\t\t\t\t  default='./running_log/logger.log', type=str)\n",
        "\tparser.add_argument('--screen_log_only', dest='screen_log_only',\n",
        "\t\t\t\t\t  help='screen printing running log instead of storing it',\n",
        "\t\t\t\t\t  action='store_true')\n",
        "\tparser.add_argument('--optim', '-optim', \n",
        "\t\t\t\t\t  help='which optimizer to use: SGD, Adam or NewtonCG',\n",
        "\t\t\t\t\t  default='NewtonCG', type=str)\n",
        "\tparser.add_argument('--loss', dest='loss', \n",
        "\t\t\t\t\t  help='which loss function to use: MSELoss or CrossEntropy',\n",
        "\t\t\t\t\t  default='MSELoss', type=str)\n",
        "\tparser.add_argument('--dim', dest='dim', nargs='+', help='input dimension of data,'+\\\n",
        "\t\t\t\t\t\t'shape must be:  height width num_channels',\n",
        "\t\t\t\t\t  default=[32, 32, 3], type=int)\n",
        "\tparser.add_argument('--seed', dest='seed', help='a nonnegative integer for \\\n",
        "\t\t\t\t\t\treproducibility', type=int)\t \n",
        "\t\n",
        "\targs = parser.parse_args(args=train_args)\n",
        "\treturn args\n",
        "\n",
        "\n",
        "args = parse_args()\n",
        "\n",
        "def init_model(param):\n",
        "\tinit_ops = []\n",
        "\tfor p in param:\n",
        "\t\tif 'kernel' in p.name:\n",
        "\t\t\tweight = np.random.standard_normal(p.shape)* np.sqrt(2.0 / ((np.prod(p.get_shape().as_list()[:-1]))))\n",
        "\t\t\topt = tf.compat.v1.assign(p, weight)\n",
        "\t\telif 'bias' in p.name:\n",
        "\t\t\tzeros = np.zeros(p.shape)\n",
        "\t\t\topt = tf.compat.v1.assign(p, zeros)\n",
        "\t\tinit_ops.append(opt)\n",
        "\treturn tf.group(*init_ops)\n",
        "\n",
        "def gradient_trainer(config, sess, network, full_batch, val_batch, saver, test_network):\n",
        "\tx, y, loss, outputs,  = network\n",
        "\t\n",
        "\tglobal_step = tf.Variable(initial_value=0, trainable=False, name='global_step')\n",
        "\tlearning_rate = tf.compat.v1.placeholder(tf.float32, shape=[], name='learning_rate')\n",
        "\n",
        "\t# Probably not a good way to add regularization.\n",
        "\t# Just to confirm the implementation is the same as MATLAB.\n",
        "\treg = 0.0\n",
        "\tparam = tf.compat.v1.trainable_variables()\n",
        "\tfor p in param:\n",
        "\t\treg = reg + tf.reduce_sum(input_tensor=tf.pow(p,2))\n",
        "\treg_const = 1/(2*config.C)\n",
        "\tbatch_size = tf.compat.v1.cast(tf.shape(x)[0], tf.float32)\n",
        "\tloss_with_reg = reg_const*reg + loss/batch_size\n",
        "\n",
        "\tif config.optim == 'SGD':\n",
        "\t\toptimizer = tf.compat.v1.train.MomentumOptimizer(\n",
        "\t\t\t\t\tlearning_rate=learning_rate, \n",
        "\t\t\t\t\tmomentum=config.momentum).minimize(\n",
        "\t\t\t\t\tloss_with_reg, \n",
        "\t\t\t\t\tglobal_step=global_step)\n",
        "\telif config.optim == 'Adam':\n",
        "\t\toptimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate,\n",
        "\t\t\t\t\t\t\t\tbeta1=0.9,\n",
        "\t\t\t\t\t\t\t\tbeta2=0.999,\n",
        "\t\t\t\t\t\t\t\tepsilon=1e-08).minimize(\n",
        "\t\t\t\t\t\t\t\tloss_with_reg, \n",
        "\t\t\t\t\t\t\t\tglobal_step=global_step)\n",
        "\n",
        "\ttrain_inputs, train_labels = full_batch\n",
        "\tnum_data = train_labels.shape[0]\n",
        "\tnum_iters = math.ceil(num_data/config.bsize)\n",
        "\n",
        "\tprint(config.args)\n",
        "\tif not config.screen_log_only:\n",
        "\t\tlog_file = open(config.log_file, 'w')\n",
        "\t\tprint(config.args, file=log_file)\n",
        "\tsess.run(tf.compat.v1.global_variables_initializer())\n",
        "\t\n",
        "\n",
        "\tprint('-------------- initializing network by methods in He et al. (2015) --------------')\n",
        "\tparam = tf.compat.v1.trainable_variables()\n",
        "\tsess.run(init_model(param))\n",
        "\n",
        "\ttotal_running_time = 0.0\n",
        "\tbest_acc = 0.0\n",
        "\tlr = config.lr\n",
        "\n",
        "\tfor epoch in range(0, args.epoch):\n",
        "\t\t\n",
        "\t\tloss_avg = 0.0\n",
        "\t\tstart = time.time()\n",
        "\n",
        "\t\tfor i in range(num_iters):\n",
        "\t\t\t\n",
        "\t\t\tload_time = time.time()\n",
        "\t\t\t# randomly select the batch\n",
        "\t\t\tidx = np.random.choice(np.arange(0, num_data), \n",
        "\t\t\t\t\tsize=config.bsize, replace=False)\n",
        "\n",
        "\t\t\tbatch_input = train_inputs[idx]\n",
        "\t\t\tbatch_labels = train_labels[idx]\n",
        "\t\t\tbatch_input = np.ascontiguousarray(batch_input)\n",
        "\t\t\tbatch_labels = np.ascontiguousarray(batch_labels)\n",
        "\t\t\tconfig.elapsed_time += time.time() - load_time\n",
        "\n",
        "\t\t\tstep, _, batch_loss= sess.run(\n",
        "\t\t\t\t[global_step, optimizer, loss_with_reg],\n",
        "\t\t\t\tfeed_dict = {x: batch_input, y: batch_labels, learning_rate: lr}\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\t# print initial loss\n",
        "\t\t\tif epoch == 0 and i == 0:\n",
        "\t\t\t\toutput_str = 'initial f (reg + avg. loss of 1st batch): {:.3f}'.format(batch_loss)\n",
        "\t\t\t\tprint(output_str)\n",
        "\t\t\t\tif not config.screen_log_only:\n",
        "\t\t\t\t\tprint(output_str, file=log_file)\n",
        "\n",
        "\t\t\tloss_avg = loss_avg + batch_loss\n",
        "\t\t\t# print log every 10% of the iterations\n",
        "\t\t\tif i % math.ceil(num_iters/10) == 0:\n",
        "\t\t\t\tend = time.time()\n",
        "\t\t\t\toutput_str = 'Epoch {}: {}/{} | loss {:.4f} | lr {:.6} | elapsed time {:.3f}'\\\n",
        "\t\t\t\t\t.format(epoch, i, num_iters, batch_loss , lr, end-start)\n",
        "\t\t\t\tprint(output_str)\n",
        "\t\t\t\tif not config.screen_log_only:\n",
        "\t\t\t\t\tprint(output_str, file=log_file)\n",
        "\t\t\t\n",
        "\t\t\t# adjust learning rate for SGD by inverse time decay\n",
        "\t\t\tif args.optim != 'Adam':\n",
        "\t\t\t\tlr = config.lr/(1 + args.lr_decay*step)\n",
        "\n",
        "\t\t# exclude data loading time for fair comparison\n",
        "\t\tepoch_end = time.time() - config.elapsed_time\n",
        "\t\ttotal_running_time += epoch_end - start\n",
        "\t\tconfig.elapsed_time = 0.0\n",
        "\t\t\n",
        "\t\tif val_batch is None:\n",
        "\t\t\toutput_str = 'In epoch {} train loss: {:.3f} | epoch time {:.3f}'\\\n",
        "\t\t\t\t.format(epoch, loss_avg/(i+1), epoch_end-start)\t\t\t\n",
        "\t\telse:\n",
        "\t\t\tif test_network == None:\n",
        "\t\t\t\tval_loss, val_acc, _ = predict(\n",
        "\t\t\t\t\tsess, \n",
        "\t\t\t\t\tnetwork=(x, y, loss, outputs),\n",
        "\t\t\t\t\ttest_batch=val_batch,\n",
        "\t\t\t\t\tbsize=config.bsize\n",
        "\t\t\t\t\t)\n",
        "\t\t\telse:\n",
        "\t\t\t\t# A separat test network part have been done...\n",
        "\t\t\t\tval_loss, val_acc, _ = predict(\n",
        "\t\t\t\t\tsess, \n",
        "\t\t\t\t\tnetwork=test_network,\n",
        "\t\t\t\t\ttest_batch=val_batch,\n",
        "\t\t\t\t\tbsize=config.bsize\n",
        "\t\t\t\t\t)\n",
        "\t\t\t\n",
        "\t\t\toutput_str = 'In epoch {} train loss: {:.3f} | val loss: {:.3f} | val accuracy: {:.3f}% | epoch time {:.3f}'\\\n",
        "\t\t\t\t.format(epoch, loss_avg/(i+1), val_loss, val_acc*100, epoch_end-start)\n",
        "\t\t\n",
        "\t\t\tif val_acc > best_acc:\n",
        "\t\t\t\tbest_acc = val_acc\n",
        "\t\t\t\tcheckpoint_path = config.model_file \n",
        "\t\t\t\tsave_path = saver.save(sess, checkpoint_path)\n",
        "\t\t\t\tprint('Saved best model in {}'.format(save_path))\n",
        "\n",
        "\t\tprint(output_str)\n",
        "\t\tif not config.screen_log_only:\n",
        "\t\t\tprint(output_str, file=log_file)\n",
        "\n",
        "\tif val_batch is None:\n",
        "\t\tcheckpoint_path = config.model_file \n",
        "\t\tsave_path = saver.save(sess, checkpoint_path)\n",
        "\t\tprint('Model at the last iteration saved in {}\\r\\n'.format(save_path))\n",
        "\t\toutput_str = 'total running time {:.3f}s'.format(total_running_time)\n",
        "\telse:\n",
        "\t\toutput_str = 'Final acc: {:.3f}% | best acc {:.3f}% | total running time {:.3f}s'\\\n",
        "\t\t\t.format(val_acc*100, best_acc*100, total_running_time)\n",
        "\t\n",
        "\tprint(output_str)\n",
        "\tif not config.screen_log_only:\n",
        "\t\tprint(output_str, file=log_file)\n",
        "\t\tlog_file.close()\n",
        "\n",
        "def newton_trainer(config, sess, network, full_batch, val_batch, saver, test_network):\n",
        "\n",
        "\t_, _, loss, outputs = network\n",
        "\tnewton_solver = newton_cg(config, sess, outputs, loss)\n",
        "\tsess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "\tprint('-------------- initializing network by methods in He et al. (2015) --------------')\n",
        "\tparam = tf.compat.v1.trainable_variables()\n",
        "\tsess.run(init_model(param))\n",
        "\tnewton_solver.newton(full_batch, val_batch, saver, network, test_network)\n",
        "\n",
        "\n",
        "def train_model():\n",
        "\tfull_batch, num_cls, label_enum = read_data(filename=args.train_set, dim=args.dim)\n",
        "\t\n",
        "\tif args.val_set is None:\n",
        "\t\tprint('No validation set is provided. Will output model at the last iteration.')\n",
        "\t\tval_batch = None\n",
        "\telse:\n",
        "\t\tval_batch, _, _ = read_data(filename=args.val_set, dim=args.dim, label_enum=label_enum)\n",
        "\n",
        "\tnum_data = full_batch[0].shape[0]\n",
        "\t\n",
        "\tconfig = ConfigClass(args, num_data, num_cls)\n",
        "\n",
        "\tif isinstance(config.seed, int):\n",
        "\t\ttf.compat.v1.random.set_random_seed(config.seed)\n",
        "\t\tnp.random.seed(config.seed)\n",
        "\n",
        "\tif config.net in ('CNN_4layers', 'CNN_7layers', 'VGG11', 'VGG13', 'VGG16','VGG19'):\n",
        "\t\tx, y, outputs = CNN(config.net, num_cls, config.dim)\n",
        "\t\ttest_network = None\n",
        "\telse:\n",
        "\t\traise ValueError('Unrecognized training model')\n",
        "\n",
        "\tif config.loss == 'MSELoss':\n",
        "\t\tloss = tf.reduce_sum(input_tensor=tf.pow(outputs-y, 2))\n",
        "\telse:\n",
        "\t\tloss = tf.reduce_sum(input_tensor=tf.nn.softmax_cross_entropy_with_logits(logits=outputs, labels=y))\n",
        "\t\n",
        "\tnetwork = (x, y, loss, outputs)\n",
        "\n",
        "\tsess_config = tf.compat.v1.ConfigProto()\n",
        "\tsess_config.gpu_options.allow_growth = True\n",
        "\n",
        "\twith tf.compat.v1.Session(config=sess_config) as sess:\n",
        "\t\t\n",
        "\t\tfull_batch[0], mean_tr = normalize_and_reshape(full_batch[0], dim=config.dim, mean_tr=None)\n",
        "\t\tif val_batch is not None:\n",
        "\t\t\tval_batch[0], _ = normalize_and_reshape(val_batch[0], dim=config.dim, mean_tr=mean_tr)\n",
        "\n",
        "\t\tparam = tf.compat.v1.trainable_variables()\n",
        "\n",
        "\t\tmean_param = tf.compat.v1.get_variable(name='mean_tr', initializer=mean_tr, trainable=False, \n",
        "\t\t\t\t\tvalidate_shape=True, use_resource=False)\n",
        "\t\tlabel_enum_var=tf.compat.v1.get_variable(name='label_enum', initializer=label_enum, trainable=False,\n",
        "\t\t\t\t\tvalidate_shape=True, use_resource=False)\n",
        "\t\tsaver = tf.compat.v1.train.Saver(var_list=param+[mean_param])\n",
        "\t\t\n",
        "\t\tif config.optim in ('SGD', 'Adam'):\n",
        "\t\t\tgradient_trainer(\n",
        "\t\t\t\tconfig, sess, network, full_batch, val_batch, saver, test_network)\n",
        "\t\telif config.optim == 'NewtonCG':\n",
        "\t\t\tnewton_trainer(\n",
        "\t\t\t\tconfig, sess, network, full_batch, val_batch, saver, test_network=test_network)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi6UglYiD7Zd"
      },
      "source": [
        "## Train ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSgKfh4r5lu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afaf52d-c365-430b-c654-7aa808280e25"
      },
      "source": [
        "train_model()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You choose not to specify a random seed.A different result is produced after each run.\n",
            "Saving log to: ./running_log/logger.log\n",
            "No mean of data provided! Normalize images by their own mean.\n",
            "Normalize images according to the provided mean.\n",
            "-------------- initializing network by methods in He et al. (2015) --------------\n",
            "Namespace(C=0.01, CGmax=250, GNsize=4096, _lambda=1, boost=1.5, bsize=1024, dim=[32, 32, 1], drop=0.6666666666666666, epoch=500, eta=0.0001, iter_max=100, log_file='./running_log/logger.log', loss='MSELoss', lr=0.01, lr_decay=0, model_file='./saved_model/model.ckpt', momentum=0, net='CNN_4layers', optim='NewtonCG', screen_log_only=False, seed=None, train_set='/content/drive/MyDrive/Datasets/cb513_protbert_trainSet2.mat', val_set='/content/drive/MyDrive/Datasets/cb513_protbert_testSet2.mat', xi=0.1)\n",
            "initial f: 1.257\n",
            "Avg time per Gv iteration: 0.74604 s\n",
            "\n",
            "0-iter f: 0.929 |g|: 2.60463 alpha: 1.000e+00 ratio: 0.974 lambda: 0.66667 #CG: 1 actred: -0.32868 prered: -0.33758 time: 7.592\n",
            "\n",
            " 0-iter val_acc: 32.617% val_loss 0.674\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55369 s\n",
            "\n",
            "1-iter f: 0.904 |g|: 0.12936 alpha: 1.000e+00 ratio: 0.999 lambda: 0.44444 #CG: 1 actred: -0.02520 prered: -0.02522 time: 7.286\n",
            "\n",
            " 1-iter val_acc: 44.198% val_loss 0.646\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55265 s\n",
            "\n",
            "2-iter f: 0.902 |g|: 0.22331 alpha: 1.000e+00 ratio: 0.561 lambda: 0.44444 #CG: 3 actred: -0.00157 prered: -0.00280 time: 8.392\n",
            "\n",
            " 2-iter val_acc: 44.198% val_loss 0.645\n",
            "\n",
            "Avg time per Gv iteration: 0.55309 s\n",
            "\n",
            "3-iter f: 0.900 |g|: 0.21503 alpha: 1.000e+00 ratio: 0.807 lambda: 0.29630 #CG: 3 actred: -0.00187 prered: -0.00232 time: 8.381\n",
            "\n",
            " 3-iter val_acc: 44.198% val_loss 0.645\n",
            "\n",
            "Avg time per Gv iteration: 0.55231 s\n",
            "\n",
            "4-iter f: 0.898 |g|: 0.31611 alpha: 1.000e+00 ratio: 0.593 lambda: 0.29630 #CG: 3 actred: -0.00221 prered: -0.00373 time: 8.372\n",
            "\n",
            " 4-iter val_acc: 44.198% val_loss 0.645\n",
            "\n",
            "Avg time per Gv iteration: 0.55163 s\n",
            "\n",
            "5-iter f: 0.897 |g|: 0.60248 alpha: 5.000e-01 ratio: 0.154 lambda: 0.44444 #CG: 3 actred: -0.00058 prered: -0.00374 time: 9.940\n",
            "\n",
            " 5-iter val_acc: 44.198% val_loss 0.646\n",
            "\n",
            "Avg time per Gv iteration: 0.55167 s\n",
            "\n",
            "6-iter f: 0.896 |g|: 0.04820 alpha: 1.000e+00 ratio: 0.995 lambda: 0.29630 #CG: 1 actred: -0.00093 prered: -0.00093 time: 7.272\n",
            "\n",
            " 6-iter val_acc: 44.198% val_loss 0.644\n",
            "\n",
            "Avg time per Gv iteration: 0.55206 s\n",
            "\n",
            "7-iter f: 0.894 |g|: 0.28662 alpha: 1.000e+00 ratio: 0.378 lambda: 0.29630 #CG: 3 actred: -0.00214 prered: -0.00567 time: 8.369\n",
            "\n",
            " 7-iter val_acc: 44.198% val_loss 0.645\n",
            "\n",
            "Avg time per Gv iteration: 0.55368 s\n",
            "\n",
            "8-iter f: 0.892 |g|: 0.31447 alpha: 1.000e+00 ratio: 0.352 lambda: 0.29630 #CG: 4 actred: -0.00235 prered: -0.00668 time: 8.910\n",
            "\n",
            " 8-iter val_acc: 44.198% val_loss 0.644\n",
            "\n",
            "Avg time per Gv iteration: 0.55126 s\n",
            "\n",
            "9-iter f: 0.889 |g|: 0.41552 alpha: 1.000e+00 ratio: 0.604 lambda: 0.29630 #CG: 3 actred: -0.00278 prered: -0.00460 time: 8.361\n",
            "\n",
            " 9-iter val_acc: 44.198% val_loss 0.642\n",
            "\n",
            "Avg time per Gv iteration: 0.55183 s\n",
            "\n",
            "10-iter f: 0.889 |g|: 0.76625 alpha: 1.000e+00 ratio: 0.028 lambda: 0.44444 #CG: 3 actred: -0.00057 prered: -0.02027 time: 8.358\n",
            "\n",
            " 10-iter val_acc: 44.198% val_loss 0.643\n",
            "\n",
            "Avg time per Gv iteration: 0.55175 s\n",
            "\n",
            "11-iter f: 0.887 |g|: 0.04135 alpha: 1.000e+00 ratio: 1.000 lambda: 0.29630 #CG: 1 actred: -0.00119 prered: -0.00119 time: 7.278\n",
            "\n",
            " 11-iter val_acc: 44.198% val_loss 0.643\n",
            "\n",
            "Avg time per Gv iteration: 0.55206 s\n",
            "\n",
            "12-iter f: 0.885 |g|: 0.17097 alpha: 1.000e+00 ratio: 0.497 lambda: 0.29630 #CG: 3 actred: -0.00254 prered: -0.00512 time: 8.362\n",
            "\n",
            " 12-iter val_acc: 44.198% val_loss 0.643\n",
            "\n",
            "Avg time per Gv iteration: 0.55111 s\n",
            "\n",
            "13-iter f: 0.883 |g|: 0.72523 alpha: 1.000e+00 ratio: 0.534 lambda: 0.29630 #CG: 3 actred: -0.00206 prered: -0.00385 time: 8.356\n",
            "\n",
            " 13-iter val_acc: 44.198% val_loss 0.642\n",
            "\n",
            "Avg time per Gv iteration: 0.55097 s\n",
            "\n",
            "14-iter f: 0.882 |g|: 0.03579 alpha: 1.000e+00 ratio: 1.000 lambda: 0.19753 #CG: 1 actred: -0.00088 prered: -0.00088 time: 7.265\n",
            "\n",
            " 14-iter val_acc: 44.198% val_loss 0.642\n",
            "\n",
            "Avg time per Gv iteration: 0.55128 s\n",
            "\n",
            "15-iter f: 0.878 |g|: 0.65714 alpha: 1.000e+00 ratio: 0.645 lambda: 0.19753 #CG: 3 actred: -0.00349 prered: -0.00542 time: 8.363\n",
            "\n",
            " 15-iter val_acc: 44.198% val_loss 0.640\n",
            "\n",
            "Avg time per Gv iteration: 0.55212 s\n",
            "\n",
            "16-iter f: 0.878 |g|: 0.03519 alpha: 1.000e+00 ratio: 1.000 lambda: 0.13169 #CG: 1 actred: -0.00060 prered: -0.00060 time: 7.273\n",
            "\n",
            " 16-iter val_acc: 44.198% val_loss 0.641\n",
            "\n",
            "Avg time per Gv iteration: 0.55187 s\n",
            "\n",
            "17-iter f: 0.875 |g|: 1.52244 alpha: 1.000e+00 ratio: 0.298 lambda: 0.13169 #CG: 3 actred: -0.00249 prered: -0.00834 time: 8.368\n",
            "\n",
            " 17-iter val_acc: 44.451% val_loss 0.645\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55193 s\n",
            "\n",
            "18-iter f: 0.873 |g|: 0.04286 alpha: 1.000e+00 ratio: 1.000 lambda: 0.08779 #CG: 1 actred: -0.00225 prered: -0.00225 time: 7.274\n",
            "\n",
            " 18-iter val_acc: 44.198% val_loss 0.640\n",
            "\n",
            "Avg time per Gv iteration: 0.55164 s\n",
            "\n",
            "19-iter f: 0.866 |g|: 1.00154 alpha: 1.000e+00 ratio: 0.596 lambda: 0.08779 #CG: 5 actred: -0.00709 prered: -0.01190 time: 9.463\n",
            "\n",
            " 19-iter val_acc: 44.198% val_loss 0.639\n",
            "\n",
            "Avg time per Gv iteration: 0.55127 s\n",
            "\n",
            "20-iter f: 0.865 |g|: 0.10816 alpha: 1.000e+00 ratio: 1.003 lambda: 0.05853 #CG: 1 actred: -0.00091 prered: -0.00091 time: 7.273\n",
            "\n",
            " 20-iter val_acc: 44.198% val_loss 0.639\n",
            "\n",
            "Avg time per Gv iteration: 0.55163 s\n",
            "\n",
            "21-iter f: 0.863 |g|: 2.42910 alpha: 5.000e-01 ratio: 0.084 lambda: 0.08779 #CG: 5 actred: -0.00211 prered: -0.02506 time: 11.046\n",
            "\n",
            " 21-iter val_acc: 44.198% val_loss 0.639\n",
            "\n",
            "Avg time per Gv iteration: 0.55135 s\n",
            "\n",
            "22-iter f: 0.860 |g|: 0.11145 alpha: 1.000e+00 ratio: 1.000 lambda: 0.05853 #CG: 1 actred: -0.00321 prered: -0.00321 time: 7.275\n",
            "\n",
            " 22-iter val_acc: 44.198% val_loss 0.638\n",
            "\n",
            "Avg time per Gv iteration: 0.55152 s\n",
            "\n",
            "23-iter f: 0.857 |g|: 1.41041 alpha: 2.500e-01 ratio: 0.123 lambda: 0.08779 #CG: 5 actred: -0.00230 prered: -0.01869 time: 12.614\n",
            "\n",
            " 23-iter val_acc: 44.198% val_loss 0.638\n",
            "\n",
            "Avg time per Gv iteration: 0.55132 s\n",
            "\n",
            "24-iter f: 0.857 |g|: 1.18847 alpha: 1.250e-01 ratio: 0.006 lambda: 0.13169 #CG: 3 actred: -0.00007 prered: -0.01182 time: 13.100\n",
            "\n",
            " 24-iter val_acc: 44.198% val_loss 0.638\n",
            "\n",
            "Avg time per Gv iteration: 0.55137 s\n",
            "\n",
            "25-iter f: 0.857 |g|: 0.07310 alpha: 1.000e+00 ratio: 1.000 lambda: 0.08779 #CG: 1 actred: -0.00068 prered: -0.00068 time: 7.277\n",
            "\n",
            " 25-iter val_acc: 44.198% val_loss 0.637\n",
            "\n",
            "Avg time per Gv iteration: 0.55156 s\n",
            "\n",
            "26-iter f: 0.856 |g|: 1.95681 alpha: 2.500e-01 ratio: 0.093 lambda: 0.13169 #CG: 5 actred: -0.00087 prered: -0.00938 time: 12.611\n",
            "\n",
            " 26-iter val_acc: 44.198% val_loss 0.636\n",
            "\n",
            "Avg time per Gv iteration: 0.55131 s\n",
            "\n",
            "27-iter f: 0.854 |g|: 0.04945 alpha: 1.000e+00 ratio: 1.000 lambda: 0.08779 #CG: 1 actred: -0.00178 prered: -0.00178 time: 7.279\n",
            "\n",
            " 27-iter val_acc: 44.198% val_loss 0.636\n",
            "\n",
            "Avg time per Gv iteration: 0.55150 s\n",
            "\n",
            "28-iter f: 0.850 |g|: 2.64729 alpha: 1.000e+00 ratio: 0.209 lambda: 0.13169 #CG: 5 actred: -0.00417 prered: -0.01991 time: 9.455\n",
            "\n",
            " 28-iter val_acc: 44.198% val_loss 0.636\n",
            "\n",
            "Avg time per Gv iteration: 0.55159 s\n",
            "\n",
            "29-iter f: 0.848 |g|: 0.15603 alpha: 1.000e+00 ratio: 1.000 lambda: 0.08779 #CG: 1 actred: -0.00218 prered: -0.00218 time: 7.277\n",
            "\n",
            " 29-iter val_acc: 44.198% val_loss 0.636\n",
            "\n",
            "Avg time per Gv iteration: 0.55152 s\n",
            "\n",
            "30-iter f: 0.847 |g|: 0.56302 alpha: 6.250e-02 ratio: 0.038 lambda: 0.13169 #CG: 3 actred: -0.00026 prered: -0.00689 time: 14.671\n",
            "\n",
            " 30-iter val_acc: 44.198% val_loss 0.636\n",
            "\n",
            "Avg time per Gv iteration: 0.55189 s\n",
            "\n",
            "31-iter f: 0.847 |g|: 0.72496 alpha: 6.250e-02 ratio: 0.001 lambda: 0.19753 #CG: 3 actred: -0.00001 prered: -0.00677 time: 14.804\n",
            "\n",
            " 31-iter val_acc: 44.198% val_loss 0.636\n",
            "\n",
            "Avg time per Gv iteration: 0.55038 s\n",
            "\n",
            "32-iter f: 0.847 |g|: 1.06074 alpha: 2.500e-01 ratio: 0.004 lambda: 0.29630 #CG: 3 actred: -0.00014 prered: -0.03157 time: 11.515\n",
            "\n",
            " 32-iter val_acc: 44.198% val_loss 0.635\n",
            "\n",
            "Avg time per Gv iteration: 0.55268 s\n",
            "\n",
            "33-iter f: 0.847 |g|: 0.03017 alpha: 1.000e+00 ratio: 1.000 lambda: 0.19753 #CG: 1 actred: -0.00032 prered: -0.00032 time: 7.276\n",
            "\n",
            " 33-iter val_acc: 44.198% val_loss 0.635\n",
            "\n",
            "Avg time per Gv iteration: 0.55080 s\n",
            "\n",
            "34-iter f: 0.843 |g|: 0.40990 alpha: 1.000e+00 ratio: 0.967 lambda: 0.13169 #CG: 3 actred: -0.00435 prered: -0.00450 time: 8.381\n",
            "\n",
            " 34-iter val_acc: 44.198% val_loss 0.633\n",
            "\n",
            "Avg time per Gv iteration: 0.55283 s\n",
            "\n",
            "35-iter f: 0.843 |g|: 0.03103 alpha: 1.000e+00 ratio: 0.998 lambda: 0.08779 #CG: 1 actred: -0.00005 prered: -0.00005 time: 7.280\n",
            "\n",
            " 35-iter val_acc: 44.198% val_loss 0.633\n",
            "\n",
            "Avg time per Gv iteration: 0.55152 s\n",
            "\n",
            "36-iter f: 0.832 |g|: 0.99955 alpha: 1.000e+00 ratio: 1.047 lambda: 0.05853 #CG: 3 actred: -0.01087 prered: -0.01038 time: 8.368\n",
            "\n",
            " 36-iter val_acc: 44.330% val_loss 0.627\n",
            "\n",
            "Avg time per Gv iteration: 0.55191 s\n",
            "\n",
            "37-iter f: 0.831 |g|: 0.05281 alpha: 1.000e+00 ratio: 1.000 lambda: 0.03902 #CG: 1 actred: -0.00029 prered: -0.00029 time: 7.282\n",
            "\n",
            " 37-iter val_acc: 45.031% val_loss 0.627\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55122 s\n",
            "\n",
            "38-iter f: 0.827 |g|: 4.43148 alpha: 5.000e-01 ratio: 0.233 lambda: 0.05853 #CG: 5 actred: -0.00489 prered: -0.02097 time: 11.033\n",
            "\n",
            " 38-iter val_acc: 44.632% val_loss 0.628\n",
            "\n",
            "Avg time per Gv iteration: 0.55207 s\n",
            "\n",
            "39-iter f: 0.822 |g|: 0.11961 alpha: 1.000e+00 ratio: 1.000 lambda: 0.03902 #CG: 1 actred: -0.00494 prered: -0.00494 time: 7.278\n",
            "\n",
            " 39-iter val_acc: 46.649% val_loss 0.623\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55132 s\n",
            "\n",
            "40-iter f: 0.821 |g|: 1.91926 alpha: 6.250e-02 ratio: 0.140 lambda: 0.05853 #CG: 5 actred: -0.00081 prered: -0.00576 time: 15.760\n",
            "\n",
            " 40-iter val_acc: 44.560% val_loss 0.622\n",
            "\n",
            "Avg time per Gv iteration: 0.55117 s\n",
            "\n",
            "41-iter f: 0.820 |g|: 0.04730 alpha: 1.000e+00 ratio: 1.000 lambda: 0.03902 #CG: 1 actred: -0.00090 prered: -0.00090 time: 7.276\n",
            "\n",
            " 41-iter val_acc: 46.842% val_loss 0.622\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55276 s\n",
            "\n",
            "42-iter f: 0.800 |g|: 6.03815 alpha: 1.000e+00 ratio: 0.508 lambda: 0.03902 #CG: 5 actred: -0.01947 prered: -0.03831 time: 9.462\n",
            "\n",
            " 42-iter val_acc: 56.575% val_loss 0.615\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55182 s\n",
            "\n",
            "43-iter f: 0.794 |g|: 3.46989 alpha: 1.000e+00 ratio: 0.068 lambda: 0.05853 #CG: 3 actred: -0.00656 prered: -0.09696 time: 8.365\n",
            "\n",
            " 43-iter val_acc: 52.699% val_loss 0.607\n",
            "\n",
            "Avg time per Gv iteration: 0.55320 s\n",
            "\n",
            "44-iter f: 0.792 |g|: 0.13399 alpha: 1.000e+00 ratio: 1.000 lambda: 0.03902 #CG: 1 actred: -0.00159 prered: -0.00159 time: 7.276\n",
            "\n",
            " 44-iter val_acc: 51.588% val_loss 0.605\n",
            "\n",
            "Avg time per Gv iteration: 0.55218 s\n",
            "\n",
            "45-iter f: 0.786 |g|: 8.30864 alpha: 5.000e-01 ratio: 0.163 lambda: 0.05853 #CG: 5 actred: -0.00618 prered: -0.03791 time: 11.048\n",
            "\n",
            " 45-iter val_acc: 54.474% val_loss 0.604\n",
            "\n",
            "Avg time per Gv iteration: 0.55154 s\n",
            "\n",
            "46-iter f: 0.778 |g|: 0.41012 alpha: 1.000e+00 ratio: 0.999 lambda: 0.03902 #CG: 1 actred: -0.00856 prered: -0.00857 time: 7.270\n",
            "\n",
            " 46-iter val_acc: 55.042% val_loss 0.595\n",
            "\n",
            "Avg time per Gv iteration: 0.55183 s\n",
            "\n",
            "47-iter f: 0.775 |g|: 3.38840 alpha: 5.000e-01 ratio: 0.049 lambda: 0.05853 #CG: 3 actred: -0.00265 prered: -0.05454 time: 9.945\n",
            "\n",
            " 47-iter val_acc: 58.797% val_loss 0.593\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55127 s\n",
            "\n",
            "48-iter f: 0.774 |g|: 3.18118 alpha: 5.000e-01 ratio: 0.029 lambda: 0.08779 #CG: 3 actred: -0.00091 prered: -0.03175 time: 9.952\n",
            "\n",
            " 48-iter val_acc: 55.670% val_loss 0.590\n",
            "\n",
            "Avg time per Gv iteration: 0.55197 s\n",
            "\n",
            "49-iter f: 0.773 |g|: 0.33255 alpha: 1.000e+00 ratio: 1.001 lambda: 0.05853 #CG: 1 actred: -0.00115 prered: -0.00115 time: 7.278\n",
            "\n",
            " 49-iter val_acc: 55.658% val_loss 0.590\n",
            "\n",
            "Avg time per Gv iteration: 0.55158 s\n",
            "\n",
            "50-iter f: 0.771 |g|: 5.60491 alpha: 5.000e-01 ratio: 0.043 lambda: 0.08779 #CG: 5 actred: -0.00194 prered: -0.04504 time: 11.035\n",
            "\n",
            " 50-iter val_acc: 50.380% val_loss 0.587\n",
            "\n",
            "Avg time per Gv iteration: 0.55247 s\n",
            "\n",
            "51-iter f: 0.769 |g|: 2.07281 alpha: 5.000e-01 ratio: 0.031 lambda: 0.13169 #CG: 3 actred: -0.00233 prered: -0.07478 time: 9.948\n",
            "\n",
            " 51-iter val_acc: 56.720% val_loss 0.588\n",
            "\n",
            "Avg time per Gv iteration: 0.55138 s\n",
            "\n",
            "52-iter f: 0.768 |g|: 0.05529 alpha: 1.000e+00 ratio: 1.000 lambda: 0.08779 #CG: 1 actred: -0.00037 prered: -0.00037 time: 7.268\n",
            "\n",
            " 52-iter val_acc: 56.491% val_loss 0.587\n",
            "\n",
            "Avg time per Gv iteration: 0.55121 s\n",
            "\n",
            "53-iter f: 0.741 |g|: 2.30603 alpha: 1.000e+00 ratio: 1.077 lambda: 0.05853 #CG: 5 actred: -0.02687 prered: -0.02496 time: 9.463\n",
            "\n",
            " 53-iter val_acc: 60.452% val_loss 0.564\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55210 s\n",
            "\n",
            "54-iter f: 0.741 |g|: 0.19261 alpha: 1.000e+00 ratio: 1.000 lambda: 0.03902 #CG: 1 actred: -0.00047 prered: -0.00047 time: 7.270\n",
            "\n",
            " 54-iter val_acc: 59.691% val_loss 0.563\n",
            "\n",
            "Avg time per Gv iteration: 0.55083 s\n",
            "\n",
            "55-iter f: 0.727 |g|: 14.70508 alpha: 1.000e+00 ratio: 0.208 lambda: 0.05853 #CG: 7 actred: -0.01392 prered: -0.06704 time: 10.546\n",
            "\n",
            " 55-iter val_acc: 58.954% val_loss 0.557\n",
            "\n",
            "Avg time per Gv iteration: 0.55217 s\n",
            "\n",
            "56-iter f: 0.710 |g|: 0.07355 alpha: 1.000e+00 ratio: 1.000 lambda: 0.03902 #CG: 1 actred: -0.01703 prered: -0.01703 time: 7.275\n",
            "\n",
            " 56-iter val_acc: 61.961% val_loss 0.540\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55222 s\n",
            "\n",
            "57-iter f: 0.651 |g|: 5.06940 alpha: 1.000e+00 ratio: 1.126 lambda: 0.02601 #CG: 8 actred: -0.05900 prered: -0.05240 time: 11.100\n",
            "\n",
            " 57-iter val_acc: 66.333% val_loss 0.485\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55160 s\n",
            "\n",
            "58-iter f: 0.649 |g|: 0.24769 alpha: 1.000e+00 ratio: 0.999 lambda: 0.01734 #CG: 1 actred: -0.00226 prered: -0.00227 time: 7.278\n",
            "\n",
            " 58-iter val_acc: 65.282% val_loss 0.483\n",
            "\n",
            "Avg time per Gv iteration: 0.55107 s\n",
            "\n",
            "59-iter f: 0.643 |g|: 5.81620 alpha: 5.000e-01 ratio: 0.140 lambda: 0.02601 #CG: 10 actred: -0.00591 prered: -0.04206 time: 13.763\n",
            "\n",
            " 59-iter val_acc: 69.062% val_loss 0.485\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55022 s\n",
            "\n",
            "60-iter f: 0.637 |g|: 1.42861 alpha: 1.000e+00 ratio: 0.110 lambda: 0.03902 #CG: 2 actred: -0.00575 prered: -0.05249 time: 7.792\n",
            "\n",
            " 60-iter val_acc: 68.398% val_loss 0.479\n",
            "\n",
            "Avg time per Gv iteration: 0.55003 s\n",
            "\n",
            "61-iter f: 0.637 |g|: 0.07910 alpha: 1.000e+00 ratio: 0.999 lambda: 0.02601 #CG: 1 actred: -0.00018 prered: -0.00018 time: 7.247\n",
            "\n",
            " 61-iter val_acc: 68.180% val_loss 0.478\n",
            "\n",
            "Avg time per Gv iteration: 0.54921 s\n",
            "\n",
            "62-iter f: 0.593 |g|: 7.49161 alpha: 1.000e+00 ratio: 0.784 lambda: 0.01734 #CG: 12 actred: -0.04410 prered: -0.05627 time: 13.252\n",
            "\n",
            " 62-iter val_acc: 69.955% val_loss 0.442\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55286 s\n",
            "\n",
            "63-iter f: 0.589 |g|: 0.08840 alpha: 1.000e+00 ratio: 1.000 lambda: 0.01156 #CG: 1 actred: -0.00391 prered: -0.00391 time: 7.287\n",
            "\n",
            " 63-iter val_acc: 70.740% val_loss 0.437\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.54922 s\n",
            "\n",
            "64-iter f: 0.541 |g|: 12.14342 alpha: 1.000e+00 ratio: 0.869 lambda: 0.00771 #CG: 17 actred: -0.04783 prered: -0.05507 time: 15.954\n",
            "\n",
            " 64-iter val_acc: 72.177% val_loss 0.411\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.54986 s\n",
            "\n",
            "65-iter f: 0.529 |g|: 0.22937 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00514 #CG: 1 actred: -0.01230 prered: -0.01230 time: 7.253\n",
            "\n",
            " 65-iter val_acc: 73.300% val_loss 0.395\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.54903 s\n",
            "\n",
            "66-iter f: 0.524 |g|: 9.69933 alpha: 5.000e-01 ratio: 0.153 lambda: 0.00771 #CG: 20 actred: -0.00443 prered: -0.02893 time: 19.146\n",
            "\n",
            " 66-iter val_acc: 74.399% val_loss 0.405\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55025 s\n",
            "\n",
            "67-iter f: 0.515 |g|: 0.13370 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00514 #CG: 1 actred: -0.00954 prered: -0.00954 time: 7.241\n",
            "\n",
            " 67-iter val_acc: 74.399% val_loss 0.396\n",
            "\n",
            "Avg time per Gv iteration: 0.54916 s\n",
            "\n",
            "68-iter f: 0.503 |g|: 7.54946 alpha: 2.500e-01 ratio: 0.730 lambda: 0.00514 #CG: 22 actred: -0.01156 prered: -0.01585 time: 21.800\n",
            "\n",
            " 68-iter val_acc: 74.085% val_loss 0.388\n",
            "\n",
            "Avg time per Gv iteration: 0.54980 s\n",
            "\n",
            "69-iter f: 0.496 |g|: 0.50326 alpha: 1.000e+00 ratio: 0.537 lambda: 0.00514 #CG: 2 actred: -0.00736 prered: -0.01371 time: 7.791\n",
            "\n",
            " 69-iter val_acc: 75.051% val_loss 0.383\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.54957 s\n",
            "\n",
            "70-iter f: 0.496 |g|: 0.04788 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00343 #CG: 1 actred: -0.00003 prered: -0.00003 time: 7.245\n",
            "\n",
            " 70-iter val_acc: 75.051% val_loss 0.383\n",
            "\n",
            "Avg time per Gv iteration: 0.54959 s\n",
            "\n",
            "71-iter f: 0.495 |g|: 11.73867 alpha: 5.000e-01 ratio: 0.029 lambda: 0.00514 #CG: 34 actred: -0.00085 prered: -0.02934 time: 26.792\n",
            "\n",
            " 71-iter val_acc: 73.699% val_loss 0.403\n",
            "\n",
            "Avg time per Gv iteration: 0.55048 s\n",
            "\n",
            "72-iter f: 0.466 |g|: 0.35382 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00343 #CG: 1 actred: -0.02867 prered: -0.02867 time: 7.258\n",
            "\n",
            " 72-iter val_acc: 75.909% val_loss 0.370\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55048 s\n",
            "\n",
            "73-iter f: 0.465 |g|: 1.60794 alpha: 5.000e-01 ratio: 0.438 lambda: 0.00343 #CG: 4 actred: -0.00088 prered: -0.00202 time: 10.472\n",
            "\n",
            " 73-iter val_acc: 75.776% val_loss 0.369\n",
            "\n",
            "Avg time per Gv iteration: 0.55241 s\n",
            "\n",
            "74-iter f: 0.465 |g|: 0.03082 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00228 #CG: 1 actred: -0.00053 prered: -0.00053 time: 7.266\n",
            "\n",
            " 74-iter val_acc: 75.740% val_loss 0.369\n",
            "\n",
            "Avg time per Gv iteration: 0.54942 s\n",
            "\n",
            "75-iter f: 0.451 |g|: 5.06516 alpha: 5.000e-01 ratio: 0.562 lambda: 0.00228 #CG: 45 actred: -0.01385 prered: -0.02466 time: 32.768\n",
            "\n",
            " 75-iter val_acc: 75.848% val_loss 0.369\n",
            "\n",
            "Avg time per Gv iteration: 0.55024 s\n",
            "\n",
            "76-iter f: 0.440 |g|: 0.02900 alpha: 1.000e+00 ratio: 1.000 lambda: 0.00152 #CG: 2 actred: -0.01063 prered: -0.01064 time: 7.792\n",
            "\n",
            " 76-iter val_acc: 76.319% val_loss 0.361\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.54903 s\n",
            "\n",
            "77-iter f: 0.429 |g|: 3.82253 alpha: 5.000e-01 ratio: 0.566 lambda: 0.00152 #CG: 54 actred: -0.01168 prered: -0.02063 time: 37.680\n",
            "\n",
            " 77-iter val_acc: 76.042% val_loss 0.367\n",
            "\n",
            "Avg time per Gv iteration: 0.54960 s\n",
            "\n",
            "78-iter f: 0.421 |g|: 0.07771 alpha: 1.000e+00 ratio: 0.998 lambda: 0.00101 #CG: 2 actred: -0.00768 prered: -0.00770 time: 7.793\n",
            "\n",
            " 78-iter val_acc: 76.983% val_loss 0.356\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.54961 s\n",
            "\n",
            "79-iter f: 0.418 |g|: 1.77358 alpha: 2.500e-01 ratio: 0.344 lambda: 0.00101 #CG: 52 actred: -0.00326 prered: -0.00949 time: 38.163\n",
            "\n",
            " 79-iter val_acc: 76.959% val_loss 0.359\n",
            "\n",
            "Avg time per Gv iteration: 0.55055 s\n",
            "\n",
            "80-iter f: 0.416 |g|: 0.12556 alpha: 1.000e+00 ratio: 0.999 lambda: 0.00068 #CG: 2 actred: -0.00152 prered: -0.00152 time: 7.802\n",
            "\n",
            " 80-iter val_acc: 77.177% val_loss 0.356\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55035 s\n",
            "\n",
            "81-iter f: 0.413 |g|: 0.84377 alpha: 1.250e-01 ratio: 0.782 lambda: 0.00045 #CG: 41 actred: -0.00312 prered: -0.00399 time: 33.868\n",
            "\n",
            " 81-iter val_acc: 77.153% val_loss 0.354\n",
            "\n",
            "Avg time per Gv iteration: 0.54997 s\n",
            "\n",
            "82-iter f: 0.412 |g|: 0.23030 alpha: 1.000e+00 ratio: 0.442 lambda: 0.00045 #CG: 4 actred: -0.00087 prered: -0.00197 time: 8.888\n",
            "\n",
            " 82-iter val_acc: 77.273% val_loss 0.353\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55129 s\n",
            "\n",
            "83-iter f: 0.412 |g|: 0.92335 alpha: 1.000e+00 ratio: 0.311 lambda: 0.00045 #CG: 8 actred: -0.00059 prered: -0.00189 time: 11.083\n",
            "\n",
            " 83-iter val_acc: 77.104% val_loss 0.353\n",
            "\n",
            "Avg time per Gv iteration: 0.55044 s\n",
            "\n",
            "84-iter f: 0.411 |g|: 0.06641 alpha: 1.000e+00 ratio: 0.996 lambda: 0.00030 #CG: 2 actred: -0.00050 prered: -0.00051 time: 7.804\n",
            "\n",
            " 84-iter val_acc: 77.310% val_loss 0.352\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55007 s\n",
            "\n",
            "85-iter f: 0.408 |g|: 1.23391 alpha: 1.250e-01 ratio: 0.784 lambda: 0.00020 #CG: 67 actred: -0.00318 prered: -0.00406 time: 47.941\n",
            "\n",
            " 85-iter val_acc: 77.092% val_loss 0.352\n",
            "\n",
            "Avg time per Gv iteration: 0.54977 s\n",
            "\n",
            "86-iter f: 0.407 |g|: 0.03758 alpha: 1.000e+00 ratio: 0.999 lambda: 0.00013 #CG: 2 actred: -0.00078 prered: -0.00078 time: 7.797\n",
            "\n",
            " 86-iter val_acc: 77.418% val_loss 0.351\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.54949 s\n",
            "\n",
            "87-iter f: 0.402 |g|: 2.03591 alpha: 2.500e-01 ratio: 0.728 lambda: 0.00013 #CG: 76 actred: -0.00499 prered: -0.00685 time: 51.234\n",
            "\n",
            " 87-iter val_acc: 77.297% val_loss 0.351\n",
            "\n",
            "Avg time per Gv iteration: 0.54934 s\n",
            "\n",
            "88-iter f: 0.400 |g|: 0.07774 alpha: 1.000e+00 ratio: 0.850 lambda: 0.00009 #CG: 3 actred: -0.00185 prered: -0.00218 time: 8.344\n",
            "\n",
            " 88-iter val_acc: 77.611% val_loss 0.347\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.54936 s\n",
            "\n",
            "89-iter f: 0.399 |g|: 2.91945 alpha: 5.000e-01 ratio: 0.122 lambda: 0.00013 #CG: 51 actred: -0.00088 prered: -0.00718 time: 36.042\n",
            "\n",
            " 89-iter val_acc: 77.768% val_loss 0.347\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55104 s\n",
            "\n",
            "90-iter f: 0.395 |g|: 0.91543 alpha: 1.000e+00 ratio: 0.741 lambda: 0.00013 #CG: 4 actred: -0.00410 prered: -0.00554 time: 8.890\n",
            "\n",
            " 90-iter val_acc: 77.950% val_loss 0.345\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.54985 s\n",
            "\n",
            "91-iter f: 0.395 |g|: 0.07348 alpha: 1.000e+00 ratio: 0.998 lambda: 0.00009 #CG: 2 actred: -0.00034 prered: -0.00034 time: 7.795\n",
            "\n",
            " 91-iter val_acc: 77.925% val_loss 0.344\n",
            "\n",
            "Avg time per Gv iteration: 0.54947 s\n",
            "\n",
            "92-iter f: 0.394 |g|: 1.87477 alpha: 1.250e-01 ratio: 0.313 lambda: 0.00009 #CG: 59 actred: -0.00073 prered: -0.00232 time: 43.543\n",
            "\n",
            " 92-iter val_acc: 78.119% val_loss 0.344\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Avg time per Gv iteration: 0.55104 s\n",
            "\n",
            "93-iter f: 0.393 |g|: 0.32580 alpha: 1.000e+00 ratio: 0.580 lambda: 0.00009 #CG: 2 actred: -0.00158 prered: -0.00273 time: 7.798\n",
            "\n",
            " 93-iter val_acc: 78.119% val_loss 0.342\n",
            "\n",
            "Avg time per Gv iteration: 0.54979 s\n",
            "\n",
            "94-iter f: 0.392 |g|: 0.18169 alpha: 1.000e+00 ratio: 0.569 lambda: 0.00009 #CG: 3 actred: -0.00021 prered: -0.00038 time: 8.336\n",
            "\n",
            " 94-iter val_acc: 78.010% val_loss 0.343\n",
            "\n",
            "Avg time per Gv iteration: 0.54955 s\n",
            "\n",
            "95-iter f: 0.392 |g|: 0.14343 alpha: 2.500e-01 ratio: 0.876 lambda: 0.00006 #CG: 6 actred: -0.00036 prered: -0.00041 time: 13.105\n",
            "\n",
            " 95-iter val_acc: 78.022% val_loss 0.342\n",
            "\n",
            "Avg time per Gv iteration: 0.54954 s\n",
            "\n",
            "96-iter f: 0.392 |g|: 0.15036 alpha: 1.000e+00 ratio: 0.407 lambda: 0.00006 #CG: 9 actred: -0.00027 prered: -0.00067 time: 11.606\n",
            "\n",
            " 96-iter val_acc: 78.107% val_loss 0.342\n",
            "\n",
            "Avg time per Gv iteration: 0.54930 s\n",
            "\n",
            "97-iter f: 0.392 |g|: 0.42235 alpha: 5.000e-01 ratio: 0.516 lambda: 0.00006 #CG: 4 actred: -0.00013 prered: -0.00025 time: 10.463\n",
            "\n",
            " 97-iter val_acc: 78.107% val_loss 0.342\n",
            "\n",
            "Avg time per Gv iteration: 0.55267 s\n",
            "\n",
            "98-iter f: 0.392 |g|: 0.01110 alpha: 1.000e+00 ratio: 0.997 lambda: 0.00004 #CG: 2 actred: -0.00005 prered: -0.00005 time: 7.837\n",
            "\n",
            " 98-iter val_acc: 78.058% val_loss 0.341\n",
            "\n",
            "Avg time per Gv iteration: 0.54992 s\n",
            "\n",
            "99-iter f: 0.390 |g|: 1.34261 alpha: 2.500e-01 ratio: 0.833 lambda: 0.00003 #CG: 105 actred: -0.00176 prered: -0.00212 time: 67.089\n",
            "\n",
            " 99-iter val_acc: 78.131% val_loss 0.341\n",
            "\n",
            "Best model saved in ./saved_model/model.ckpt\n",
            "\n",
            "Final acc: 78.131% | best acc 78.131% | total_#CG 898 | total running time 1250.173s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwH_nXJZDz2T"
      },
      "source": [
        "## Predict ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zyzmNHFnOwD"
      },
      "source": [
        "# Arguments for prediction PSSP dataset\n",
        "pred_args = (\"--bsize 1024 --valid_set \" + VALID_FILE + \" --train_set \" + TRAIN_FILE + \n",
        "\t\t\t\t\t\t \" --model ./saved_model/model.ckpt --dim \" +\n",
        "             str(HEIGHT) + \" \" + str(WIDTH) + \" \" + str(DEPTH)).split()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6MctxH5_nTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7226cc-e1e1-4511-9975-802bc5c012dc"
      },
      "source": [
        "valid_f =  \"/content/drive/MyDrive/Datasets/{0}_test_fold{1}.txt\".format(dataset.lower(),str(fold)) # train set  \n",
        "train_f = \"/content/drive/MyDrive/Datasets/{0}_train_fold{1}.txt\".format(dataset.lower(),str(fold)) # validation set\n",
        "test_f = \"/content/drive/MyDrive/Datasets/CASP13_3class.txt\" # test set CASP13\n",
        "print(valid_f)\n",
        "print(train_f)\n",
        "print(test_f)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Datasets/cb513_test_fold2.txt\n",
            "/content/drive/MyDrive/Datasets/cb513_train_fold2.txt\n",
            "/content/drive/MyDrive/Datasets/CASP13_3class.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeQqT96h_NHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5c3498-1167-46bb-90c7-8f9b2cc81d32"
      },
      "source": [
        "VALID_PRED_FILE=\"pred_test_fold{0}.txt\".format(fold)\n",
        "TRAIN_PRED_FILE=\"pred_train_fold{0}.txt\".format(fold)\n",
        "TEST_PRED_FILE=\"pred_casp13_fold{0}.txt\".format(fold)\n",
        "print(VALID_PRED_FILE)\n",
        "print(TRAIN_PRED_FILE)\n",
        "print(TEST_PRED_FILE)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pred_test_fold2.txt\n",
            "pred_train_fold2.txt\n",
            "pred_casp13_fold2.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNNnI_mU6LN5"
      },
      "source": [
        "##Declare Predict Methods##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYGPhdqk5wYp"
      },
      "source": [
        "def create_output_pred(pred, origin_f, outFileName):\n",
        "    labels = ['C','H','E']\n",
        "    read_file = open(origin_f,\"r\")\n",
        "    output_file = open(outFileName,\"w\")\n",
        "    count =1 \n",
        "    target_name =1\n",
        "    target_secondary = 3\n",
        "    counter = 0\n",
        "    while True:\n",
        "        line = read_file.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        if count == target_name:\n",
        "            output_file.write(line)\n",
        "            target_name+=3\n",
        "        if count == target_secondary:\n",
        "            output_file.write(line)\n",
        "            target_secondary+=3\n",
        "            line = line.replace(\"\\n\",\"\") \n",
        "            prediction = \"\"\n",
        "            for c in line:\n",
        "                if (c!='!'):\n",
        "                    prediction = prediction + labels[pred[counter]]\n",
        "                    counter +=1\n",
        "            output_file.write(prediction + \"\\n\")        \n",
        "        count+=1\n",
        "        "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA8Pq5a0C3m5"
      },
      "source": [
        "# import tensorflow as tf \n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "# from utilities import predict, read_data, normalize_and_reshape\n",
        "# from net.net import CNN\n",
        "# import numpy as np \n",
        "# import argparse\n",
        "# import pdb\n",
        "\n",
        "def parse_args():\n",
        "        parser = argparse.ArgumentParser(description='prediction')\n",
        "        parser.add_argument('--test_set', dest='test_set',\n",
        "                            help='provide the directory of .mat file for testing',\n",
        "                            default=None, type=str)\n",
        "        parser.add_argument('--valid_set', dest='valid_set',\n",
        "                            help='provide the directory of .mat file for validation',\n",
        "                            default=None, type=str)\n",
        "        parser.add_argument('--train_set', dest='train_set',\n",
        "                            help='provide the directory of .mat file for training',\n",
        "                            default=None, type=str)\n",
        "        parser.add_argument('--model', dest='model_file',\n",
        "                            help='provide file storing network parameters, i.e. ./dir/model.ckpt',\n",
        "                            default='./saved_model/model.ckpt', type=str)\n",
        "        parser.add_argument('--bsize', dest='bsize',\n",
        "                            help='batch size',\n",
        "                            default=1024, type=int)\n",
        "        parser.add_argument('--loss', dest='loss', \n",
        "                            help='which loss function to use: MSELoss or CrossEntropy',\n",
        "                            default='MSELoss', type=str)\n",
        "        parser.add_argument('--dim', dest='dim', nargs='+', help='input dimension of data,'+\\\n",
        "                            'shape must be:  height width num_channels',\n",
        "                            default=[32, 32, 3], type=int)\n",
        "\n",
        "        args = parser.parse_args(args=pred_args)\n",
        "        return args\n",
        "\n",
        "def predict_model():\n",
        "        args = parse_args()\n",
        "\n",
        "        sess_config = tf.compat.v1.ConfigProto()\n",
        "        sess_config.gpu_options.allow_growth = True\n",
        "\n",
        "        with tf.compat.v1.Session(config=sess_config) as sess:\n",
        "                graph_address = args.model_file + '.meta'\n",
        "                imported_graph = tf.compat.v1.train.import_meta_graph(graph_address)\n",
        "                imported_graph.restore(sess, args.model_file)\n",
        "                mean_param = [v for v in tf.compat.v1.global_variables() if 'mean_tr:0' in v.name][0]\n",
        "                label_enum_var = [v for v in tf.compat.v1.global_variables() if 'label_enum:0' in v.name][0]\n",
        "\n",
        "                sess.run(tf.compat.v1.variables_initializer([mean_param, label_enum_var]))\n",
        "                mean_tr = sess.run(mean_param)\n",
        "                label_enum = sess.run(label_enum_var)\n",
        "\n",
        "                x = tf.compat.v1.get_default_graph().get_tensor_by_name('main_params/input_of_net:0')\n",
        "                y = tf.compat.v1.get_default_graph().get_tensor_by_name('main_params/labels:0')\n",
        "                outputs = tf.compat.v1.get_default_graph().get_tensor_by_name('output_of_net:0')\n",
        "\n",
        "                if args.loss == 'MSELoss':\n",
        "                        loss = tf.reduce_sum(input_tensor=tf.pow(outputs-y, 2))\n",
        "                else:\n",
        "                        loss = tf.reduce_sum(input_tensor=\n",
        "                            tf.nn.softmax_cross_entropy_with_logits(logits=outputs, labels=tf.stop_gradient(y)))\n",
        "                \n",
        "                network = (x, y, loss, outputs)\n",
        "\n",
        "                if args.valid_set is not None:\n",
        "                        valid_batch, num_cls, _ = read_data(args.valid_set, dim=args.dim, label_enum=label_enum)\n",
        "                        valid_batch[0], _ = normalize_and_reshape(valid_batch[0], dim=args.dim, mean_tr=mean_tr)\n",
        "            \n",
        "                        avg_loss_valid, avg_acc_valid, results_valid = predict(sess, network, valid_batch, args.bsize)\n",
        "\n",
        "                        # convert results back to the original labels\n",
        "                        inverse_map = dict(zip(np.arange(num_cls), label_enum))\n",
        "                        results_valid = np.expand_dims(results_valid, axis=1)\n",
        "                        results_valid = np.apply_along_axis(lambda x: inverse_map[x[0]], axis=1, arr=results_valid)\n",
        "                        create_output_pred(results_valid, valid_f, VALID_PRED_FILE)\n",
        "                        print('In valid phase, average loss: {:.3f} | average accuracy: {:.3f}%'.\\\n",
        "                            format(avg_loss_valid, avg_acc_valid*100))\n",
        "                \n",
        "                if args.train_set is not None:\n",
        "                        train_batch, num_cls, _ = read_data(args.train_set, dim=args.dim, label_enum=label_enum)\n",
        "                        train_batch[0], _ = normalize_and_reshape(train_batch[0], dim=args.dim, mean_tr=mean_tr)\n",
        "\n",
        "                        avg_loss_train, avg_acc_train, results_train = predict(sess, network, train_batch, args.bsize)\n",
        "                        # convert results back to the original labels\n",
        "                        inverse_map = dict(zip(np.arange(num_cls), label_enum))\n",
        "                        results_train = np.expand_dims(results_train, axis=1)\n",
        "                        results_train = np.apply_along_axis(lambda x: inverse_map[x[0]], axis=1, arr=results_train)\n",
        "                        # create_output_pred(results, results_train)\n",
        "\n",
        "                        create_output_pred(results_train, train_f, TRAIN_PRED_FILE)\n",
        "                        print('In train phase, average loss: {:.3f} | average accuracy: {:.3f}%'.\\\n",
        "                            format(avg_loss_train, avg_acc_train*100))\n",
        "\n",
        "                if args.test_set is not None:\n",
        "                        test_batch, num_cls, _ = read_data(args.test_set, dim=args.dim, label_enum=label_enum)\n",
        "                        test_batch[0], _ = normalize_and_reshape(test_batch[0], dim=args.dim, mean_tr=mean_tr)\n",
        "\n",
        "                        avg_loss_test, avg_acc_test, results_test = predict(sess, network, test_batch, args.bsize)\n",
        "                        # convert results back to the original labels\n",
        "                        inverse_map = dict(zip(np.arange(num_cls), label_enum))\n",
        "                        results_test = np.expand_dims(results_test, axis=1)\n",
        "                        results_test = np.apply_along_axis(lambda x: inverse_map[x[0]], axis=1, arr=results_test)\n",
        "                        # create_output_pred(results, results_train)\n",
        "\n",
        "                        create_output_pred(results_test, test_f, TEST_PRED_FILE)\n",
        "                        print('In test phase, average loss: {:.3f} | average accuracy: {:.3f}%'.\\\n",
        "                            format(avg_loss_test, avg_acc_test*100))\n",
        "            "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN8BTASh6eSL"
      },
      "source": [
        "##Run Predict and Display output##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCInY5uB6Y3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090cb5f3-b2c7-4850-c8b1-7dcfba3ec573"
      },
      "source": [
        "predict_model()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./saved_model/model.ckpt\n",
            "Normalize images according to the provided mean.\n",
            "In valid phase, average loss: 0.341 | average accuracy: 78.131%\n",
            "Normalize images according to the provided mean.\n",
            "In train phase, average loss: 0.328 | average accuracy: 79.307%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loR25EiOE4cQ"
      },
      "source": [
        "# !head \"$VALID_PRED_FILE\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOnpS-N3DwhK"
      },
      "source": [
        "# !head \"$TRAIN_PRED_FILE\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exgdCTXb68Vl"
      },
      "source": [
        "## Check Test score on CASP13 ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lda3hrM4dmWk"
      },
      "source": [
        "# Arguments for prediction PSSP dataset\n",
        "pred_args = (\"--bsize 1024 --test_set \" + TEST_FILE + \n",
        "\t\t\t\t\t\t \" --model ./saved_model/model.ckpt --dim \" +\n",
        "             str(HEIGHT) + \" \" + str(WIDTH) + \" \" + str(DEPTH)).split()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JCC5-2mk0rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7185a7d9-1092-4644-d3ff-6537dea97d45"
      },
      "source": [
        "predict_model()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./saved_model/model.ckpt\n",
            "Normalize images according to the provided mean.\n",
            "In test phase, average loss: 0.341 | average accuracy: 77.765%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMY6ihMjG1iO"
      },
      "source": [
        "# !head \"$TEST_PRED_FILE\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H93cFHmTH1su",
        "outputId": "d6f69b04-53b0-40ed-ea08-b6bc131ec152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!zip -r saved_model"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "zip error: Nothing to do! (saved_model.zip)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}